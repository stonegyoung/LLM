{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTUwI89pJ0d6"
      },
      "source": [
        "라이브러리 임포트 -> 언어 모델, llm 모델 선정 -> 프롬프트 템플릿 만들기 -> 결과값 포맷 만들기(llms만), 결과값 형태 정하기 ->\n",
        "\n",
        "RAG\n",
        "문서 불러오기 -> document transformer(쪼개기) -> 벡터로 바꾸기 -> DB에 넣기\n",
        "\n",
        "질문 -> 나온 텍스트 llm에 넣기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2frdaqX_1Wy",
        "outputId": "bde15a0d-c107-4946-9e03-052fc32d7207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ollama in c:\\nlp\\nlp\\lib\\site-packages (0.3.1)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\nlp\\nlp\\lib\\site-packages (from ollama) (0.27.0)\n",
            "Requirement already satisfied: anyio in c:\\nlp\\nlp\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
            "Requirement already satisfied: certifi in c:\\nlp\\nlp\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\nlp\\nlp\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\nlp\\nlp\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
            "Requirement already satisfied: sniffio in c:\\nlp\\nlp\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\nlp\\nlp\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# ollama로 llm을 로컬에서 실행할 수 있다\n",
        "!pip install ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d4eMfpAJBALk"
      },
      "outputs": [],
      "source": [
        "import ollama\n",
        "\n",
        "# ollama.pull('llama3.1')\n",
        "# response = ollama.chat(model='llama3.1', messages=[{'role':'user', 'content': 'LLM이 뭐야?'}], stream=True) # 질문\n",
        "\n",
        "# for chunk in response:\n",
        "#     print(chunk['message']['content'], end='', flush=True) # 답"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxGAtrZcBwzN"
      },
      "source": [
        "# LLM을 지원하는 LangChain\n",
        "LLM  기반 오픈 소스 프레임워크"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lOh4rOXBKyz",
        "outputId": "cc03adff-cefb-4add-d31a-a2b7db648062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in c:\\nlp\\nlp\\lib\\site-packages (0.2.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (3.10.2)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (0.2.30)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (0.1.98)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\nlp\\nlp\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\nlp\\nlp\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\nlp\\nlp\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\nlp\\nlp\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\nlp\\nlp\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain) (3.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in c:\\nlp\\nlp\\lib\\site-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\nlp\\nlp\\lib\\site-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\nlp\\nlp\\lib\\site-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in c:\\nlp\\nlp\\lib\\site-packages (from openai) (3.10.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nlp\\nlp\\lib\\site-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\nlp\\nlp\\lib\\site-packages (from requests>=2.20->openai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nlp\\nlp\\lib\\site-packages (from requests>=2.20->openai) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\nlp\\nlp\\lib\\site-packages (from requests>=2.20->openai) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp->openai) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp->openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp->openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: colorama in c:\\nlp\\nlp\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mihfode9B2Qo",
        "outputId": "3b46e385-c323-442b-8852-486fb8d98c44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_community) (3.10.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_community) (0.2.12)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_community) (0.2.29)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_community) (0.1.98)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Using cached marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in c:\\nlp\\nlp\\lib\\site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\nlp\\nlp\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\nlp\\nlp\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\nlp\\nlp\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\nlp\\nlp\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\nlp\\nlp\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.2.11-py3-none-any.whl (2.3 MB)\n",
            "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.0/2.3 MB 1.9 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 0.5/2.3 MB 6.6 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 1.2/2.3 MB 9.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.3/2.3 MB 14.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.3/2.3 MB 13.3 MB/s eta 0:00:00\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Using cached marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.11 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZqun4vOxXEe"
      },
      "source": [
        "# 랭체인 언어 모델\n",
        "1. LLMs: 검색 엔진처럼 알려주는 용도로\n",
        "2. chat models: 대화 용도로(비싼)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9SJEOtFCWoa"
      },
      "source": [
        "# LLMs\n",
        "검색 엔진처럼"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ollama(model=\"원하는 모델\")  \n",
        "predict(\"질문\"), invoke(\"질문\"), 그냥 바로 질문 등"
      ],
      "metadata": {
        "id": "qxdV4m6Z7Gwd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQSHBNAVCMVP",
        "outputId": "52ab4585-8829-4788-955b-118c88fa396f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain은, Open-source AI 프레임워크의 개발자로 알려진 James Champlin과 Will Stern에 의해 만들어진 오픈 소스 플랫폼입니다. LangChain은 언어 모델, transformer, LLM(Pretrained Language Model)과 같은 AI 모델을 개발하기 위한 프로그래밍 스택으로, AI developer를 위해 사용할 수 있습니다.\\n\\nLangChain에는, 다양한 AI 모델들을 만드는 데 필요한 도구들이 포함되어 있으며, 개발자들은 LangChain을 이용하여, 기존의 다른 AI 프레임워크에 비해 더 빠르게 AI 모델을 개발하고 테스트할 수 있습니다.'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from langchain.llms import Ollama\n",
        "\n",
        "# llms 모델 만들기\n",
        "llm = Ollama(model='llama3.1')\n",
        "\n",
        "# 질문\n",
        "llm.predict('langchain이 뭐야?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUuPfcAQC9K3",
        "outputId": "3f7da759-1743-419e-b0a4-2171248c49c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LangChain은 2022년 11월에 출시된 인공지능 플랫폼입니다. LangChain은 OpenAI의 LLM(Large Language Model)과 같은 모델을 사용하여 자연어 처리 및 텍스트 생성과 관련한 작업을 자동화할 수 있는 프레임워크입니다.\\n\\nLangChain은 Open Source로 개발되어 있으며, GitHub에 공개된 소스 코드를 통해 사용자의 커스터마이징이 가능합니다. LangChain에는 다양한 기능들이 탑재되어 있습니다.\\n\\n1.  **텍스트 생성**: LangChain은 OpenAI의 LLM과 유사한 모델을 사용하여 텍스트를 생성할 수 있습니다.\\n2.  **질문 답변**: LangChain은 사용자에게 질문에 대한 답변을 제공할 수 있습니다.\\n3.  **번역**: LangChain은 자연어 처리 기술을 사용하여 언어 번역도 가능합니다.\\n\\nLangChain은 다양한 플랫폼에서 사용할 수 있으며, Node.js와 Python과 같은 프로그래밍 언어를 지원하고 있습니다.\\n\\n2022년 11월에 출시된 후, 많은 개발자들이 LangChain을 통해 다양한 프로젝트를 진행하고 있고, 현재 LangChain은 Open Source로 개발되어 있기 때문에 지속적으로 업데이트되고 개선될 예정입니다.'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 답변이 조금씩 바뀜\n",
        "llm.predict('langchain이 뭐야?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z74P8XsyDoh5"
      },
      "source": [
        "# 파라미터 temperature이 0이면 답변이 일관됨\n",
        "1로 갈수록 무작위성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HKrZXn1DXS9",
        "outputId": "4ce44617-277b-4f01-ac80-0f2aaf82c079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LangChain은 AI 모델을 위한 프레임워크입니다. LangChain은 Open-Source로 개발되어 있으며, 다양한 AI 모델과 통합할 수 있습니다.\\n\\nLangChain의 주요 특징은 다음과 같습니다.\\n\\n1. **Modular Design**: LangChain은 모듈화된 아키텍처를 제공하여 개발자가 쉽게 AI 모델을 구성하고 확장할 수 있도록 해줍니다.\\n2. **Multi-Model Support**: LangChain은 다양한 AI 모델(예: BERT, RoBERTa, XLNet 등)을 지원하며, 개발자는 원하는 모델을 선택하여 사용할 수 있습니다.\\n3. **Customizable**: LangChain은 개발자가 자신의 요구에 맞게 커스터마이즈할 수 있도록 해줍니다. 예를 들어, 개발자는 모델의 파라미터를 조정하거나, 새로운 기능을 추가할 수 있습니다.\\n4. **Scalability**: LangChain은 대용량 데이터 처리 및 병렬처리를 지원하여 빠른 성능과 효율성을 제공합니다.\\n\\nLangChain은 자연어 처리(NLP), 컴퓨터 비전(CV), 시계열 분석(TS) 등 다양한 분야에서 사용할 수 있습니다. 개발자는 LangChain을 이용하여 AI 모델을 구축하고, 이를 다양한 애플리케이션에 적용할 수 있습니다.'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "llm = Ollama(model='llama3.1', temperature=0)\n",
        "llm.predict('langchain이 뭐야?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2-827JUDhmA",
        "outputId": "db401fcd-b323-4366-f1cf-d2842ad5653d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LangChain은 AI 개발을 위한 오픈 소스 프레임워크입니다. LangChain은 자연어 처리(NLP)와 인공지능(AI)을 위한 프로그래밍 언어를 제공하며, 사용자는 LangChain API를 통해 다양한 NLP 기능을 활용할 수 있습니다.\\n\\nLangChain의 주요 특징은 다음과 같습니다.\\n\\n1. **오픈 소스**: LangChain은 오픈 소스 프레임워크로 누구나 무료로 다운로드 및 사용할 수 있습니다.\\n2. **NLP 기능**: LangChain은 다양한 NLP 기능을 제공합니다. 예를 들어, 텍스트 분류, 문법 분석, 자연어 생성, 번역 등이 가능합니다.\\n3. **프로그래밍 언어**: LangChain은 프로그래밍 언어로 작성되어 있어, 사용자는 LangChain API를 통해 프로그램을 작성할 수 있습니다.\\n4. **AI 개발**: LangChain은 AI 개발을 위한 프레임워크로, 사용자는 LangChain을 통해 AI 모델을 개발하고 학습할 수 있습니다.\\n\\nLangChain의 주요 목적은 AI 개발을 쉽고 편리하게 하여, 사용자가 다양한 NLP 기능을 활용하여 AI 모델을 개발하고 학습할 수 있도록 하는 것입니다.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.predict('langchain이 뭐야?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z10dJdoEGieN"
      },
      "source": [
        "# 프롬프트 템플릿\n",
        "## AI에게 들어갈 질문 포맷을 만든다  \n",
        "https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "템플릿 형식 만들기  \n",
        "PromptTemplate.from_template('{}')  \n",
        "\n",
        "질문 확인  \n",
        "format()"
      ],
      "metadata": {
        "id": "8R2UrGGX7RiT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OOzyiJNkHk4u"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG-MoJT4GVWY",
        "outputId": "522b686d-415a-447b-a147-3891bbe4ad28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is a good name for a company that makes colorful socks?\n"
          ]
        }
      ],
      "source": [
        "llm_prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
        "\n",
        "prompt_result = llm_prompt.format(product=\"colorful socks\")\n",
        "print(prompt_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcXyu30KxXEf"
      },
      "source": [
        "위 아래 동일"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHNXCqDUFbf7",
        "outputId": "6f0f6467-e111-474b-c75c-7b2856893f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What is a good name for a company that makes colorful socks?\n"
          ]
        }
      ],
      "source": [
        "llm_prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"], # 들어오는 값\n",
        "    template=\"What is a good name for a company that makes {product}?\", # 보낼 값\n",
        ")\n",
        "\n",
        "prompt_result = llm_prompt.format(product=\"colorful socks\")\n",
        "print(prompt_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFvmfeXUITbE"
      },
      "source": [
        "# 결과값"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NGQrTsdIZ11"
      },
      "source": [
        "1. 퓨샷  \n",
        "https://python.langchain.com/v0.1/docs/modules/model_io/prompts/few_shot_examples_chat/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7oSw3_0Gj9V",
        "outputId": "8714c23c-c63f-4bba-e3fb-b6aaf439ce3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문: Recommend  food for dinner tonight\n",
            "답변: steak\n",
            "\n",
            "질문: Recommend  food for launch\n",
            "답변: apple and banana\n",
            "\n",
            "질문: Recommend snack for launch tomorrow\n",
            "답변:\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# examples: 예시 목록\n",
        "ex_ques = [\n",
        "    {'question': 'Recommend  food for dinner tonight', 'answer': 'steak'},\n",
        "    {'question': 'Recommend  food for launch', 'answer': 'apple and banana'},\n",
        "]\n",
        "\n",
        "# example_prompt: 각 예제를 메세지로 변환\n",
        "ex_prompt= PromptTemplate(\n",
        "    input_variables=['question', 'answer'],\n",
        "    template = '질문: {question}\\n답변: {answer}'\n",
        ")\n",
        "\n",
        "prompt = FewShotPromptTemplate(\n",
        "    examples = ex_ques,\n",
        "    example_prompt = ex_prompt,\n",
        "    input_variables = ['input'], # template 없음..\n",
        "    suffix = '질문: {input}\\n답변:',\n",
        ")\n",
        "\n",
        "prompt_result = prompt.format(input='Recommend snack for launch tomorrow')\n",
        "print(prompt_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAMnDQqiJjo3",
        "outputId": "a2ec2e6b-225d-4583-ced5-0b680d3adbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'd recommend a sandwich or a salad for lunch tomorrow.\n"
          ]
        }
      ],
      "source": [
        "result = llm(prompt_result)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9DxCul2LHvI"
      },
      "source": [
        "2. 아웃풋 파서  \n",
        "\n",
        "\n",
        "내가 원하는 형태로 출력\n",
        "- List\n",
        "- DateTime\n",
        "- Enum\n",
        "- Json\n",
        "등.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grwG9aLBKxV2"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvbtZrK3LPAT",
        "outputId": "f727676d-47c1-42b8-f3b4-3fca788d703c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
          ]
        }
      ],
      "source": [
        "# 리스트로 결과 받기\n",
        "output_parsers = CommaSeparatedListOutputParser()\n",
        "\n",
        "format_instructions = output_parsers.get_format_instructions()\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhPau83lL7oX"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=['food'],\n",
        "    template='List five {food}.\\n{format_instructions}',\n",
        "    partial_variables={'format_instructions': format_instructions}\n",
        ")\n",
        "\n",
        "prompt_result = prompt.format(food='hamburger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_aqWnkbMueE",
        "outputId": "47ae1c2c-6ee1-4483-fc03-c65fca8c2651"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Here are the five hamburgers:\\n\\nBacon Cheeseburger, Whopper, Big Mac, Hamburger, Quarter Pounder'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = llm.predict(prompt_result)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZileaAGOZMH",
        "outputId": "42105eb5-afce-4025-ebdb-7b68f7e455e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Here are the five hamburgers:\\n\\nBacon Cheeseburger',\n",
              " 'Whopper',\n",
              " 'Big Mac',\n",
              " 'Hamburger',\n",
              " 'Quarter Pounder']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_parsers.parse(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R-W-zajxXEg"
      },
      "source": [
        "# Chat models\n",
        "대화\n",
        "- SystemMessage: 해야 할 역할 설정\n",
        "- HumanMessage: 유저가 입력한 채팅\n",
        "- AIMessage: 응답한 채팅"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChatOllama(model='원하는 모델')  "
      ],
      "metadata": {
        "id": "jq-x1AQ87vhk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fCTfhN-uxXEg"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOllama\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage # 3가지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IXKCXp_UxXEg"
      },
      "outputs": [],
      "source": [
        "# chat 모델 만들기\n",
        "chat_model = ChatOllama(model='llama3.1', temperature=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7YbFHySOsEw"
      },
      "outputs": [],
      "source": [
        "messages = [SystemMessage(content='당신은 대전 여행 관광 가이드입니다.'),\n",
        "            HumanMessage(content='여행시 꼭 가야 할 곳은?')]\n",
        "\n",
        "result = chat_model(messages)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4c0xeCXxXEg"
      },
      "source": [
        "# 프롬프트 템플릿"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Message -> {} 없이  \n",
        "MessagePromptTemplate -> {} 넣어야 함  \n",
        "\n",
        "여러 메시지 템플릿을 하나로 결합해주는  \n",
        "ChatPromptTemplate.from_messages([메세지/메세지 프롬프트 넣어줌])\n",
        "\n",
        "format_messages()"
      ],
      "metadata": {
        "id": "e9dLz0zR8LkN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTF-_02hxXEg",
        "outputId": "b5ab6bee-5630-4a84-951b-0fa729ea8820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='대전 여행시 꼭 가야 할 곳은 다음과 같습니다.\\n\\n1. **한밭대로**: 대전의 대표적인 주택가로, 아름다운 자연경관과 함께 다양한 문화예술 공간이 있습니다.\\n2. **국립중앙박물관**: 한국 최초의 국립 박물관으로, 역사와 문화를 체험할 수 있는 곳입니다.\\n3. **대전시립미술관**: 대전의 대표적인 미술관으로, 현대 미술 작품을 감상할 수 있습니다.\\n4. **한밭공원**: 대전의 대표적인 공원으로, 아름다운 자연 경관과 함께 다양한 문화행사가 열립니다.\\n5. **대전역**: 대전의 대표적인 교통 기지로, 다양한 지역에 연결되어 있습니다.\\n\\n이 외에도, 대전 여행시 방문할 수 있는 곳에는 다음과 같은 곳도 있습니다.\\n\\n* **대전세계문화엑스포박물관**\\n* **대전자연사박물관**\\n* **대전미술관**\\n* **대전역주변 쇼핑몰**\\n\\n대전 여행시 꼭 방문해야 할 곳은 이와 같습니다.' response_metadata={'model': 'llama3.1', 'created_at': '2024-09-29T08:07:30.8814462Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 5866013300, 'load_duration': 15221100, 'prompt_eval_count': 36, 'prompt_eval_duration': 319846000, 'eval_count': 246, 'eval_duration': 5527844000} id='run-44d9358e-58b0-4ae2-a75e-d8e33e390b8f-0'\n"
          ]
        }
      ],
      "source": [
        "llm_prompt = PromptTemplate.from_template(\"당신은 {city} 여행 관광 가이드입니다.\")\n",
        "prom_result = llm_prompt.format(city='대전')\n",
        "\n",
        "messages = [SystemMessage(content=prom_result),\n",
        "            HumanMessage(content='여행시 꼭 가야 할 곳은?')]\n",
        "\n",
        "result = chat_model(messages)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat 프롬프트 템플릿 이용하기"
      ],
      "metadata": {
        "id": "HjM68xda0PMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate"
      ],
      "metadata": {
        "id": "jbmTblze0OxC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = SystemMessagePromptTemplate.from_template('당신은 {city}에 살고 있는 관광 가이드입니다.')\n",
        "human_prompt = HumanMessagePromptTemplate.from_template('{text}')"
      ],
      "metadata": {
        "id": "k4MFZuEA0Ufd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = ChatPromptTemplate.from_messages(\n",
        "    [system_prompt, human_prompt]\n",
        ")\n",
        "\n",
        "messages = chat_template.format_messages(city='서울', text='맛집 한 곳만 추천해줘')\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrFkxYNL0UaG",
        "outputId": "fbe359b4-88f1-441d-bf40-b7410eadd598"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='당신은 서울에 살고 있는 관광 가이드입니다.'),\n",
              " HumanMessage(content='맛집 한 곳만 추천해줘')]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chat_model(messages)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g48MmJ1c1K21",
        "outputId": "d829daab-58fb-40cd-8756-f365e5d1396a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"서울에는 다양한 맛집이 많지만, 저는 '명동 삼계탕'을 추천합니다.\\n\\n명동 삼계탕은 1970년대부터 명동에 위치한 한식당으로, 전통적인 삼계탕을 전문적으로 판매하고 있습니다. 삼계탕은 고기를 끓여서 국물과 함께 먹는 한국의 대표적인 국수料理입니다. 이 곳에서는 고기와 국물을 따로 파는 것이 아니라, 고기가 있는 국물과 함께 제공됩니다.\\n\\n명동 삼계탕은 고기의 질이 좋고, 국물도 깔끔하고 맛있게 끓여져 있습니다. 또한, 가격도 저렴하여 많은 고객들이 찾는 곳입니다.\" response_metadata={'model': 'llama3.1', 'created_at': '2024-09-29T08:26:12.0193387Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 5460134000, 'load_duration': 2144052000, 'prompt_eval_count': 38, 'prompt_eval_duration': 43266000, 'eval_count': 152, 'eval_duration': 3268983000} id='run-82c5f50a-8e33-47fc-a250-94f628fdf5ef-0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 결과값"
      ],
      "metadata": {
        "id": "PHDT1U0q3MxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate"
      ],
      "metadata": {
        "id": "m9TVhBl43Oro"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
        "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
        "]\n",
        "\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"ai\", \"{output}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples,\n",
        ")\n",
        "\n",
        "print(few_shot_prompt.format())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr8A_dzy3XL0",
        "outputId": "5df677ef-641f-4734-eaf6-5491f8824c89"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: 2+2\n",
            "AI: 4\n",
            "Human: 2+3\n",
            "AI: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 프롬프트 템플릿\n",
        "chat_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"You are a math teacher.\"),\n",
        "        few_shot_prompt,\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 똑같\n",
        "# chat_template = ChatPromptTemplate.from_messages(\n",
        "#     [\n",
        "#         SystemMessage(content='You are a math teacher.'),\n",
        "#         few_shot_prompt,\n",
        "#         HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "messages = chat_template.format_messages(input='2+4')\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebbyrjFB3qek",
        "outputId": "59e28360-1e23-4bf7-f6e9-79aab35f4952"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='You are a math teacher.'),\n",
              " HumanMessage(content='2+2'),\n",
              " AIMessage(content='4'),\n",
              " HumanMessage(content='2+3'),\n",
              " AIMessage(content='5'),\n",
              " HumanMessage(content='2+4')]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = chat_model(messages)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ete4Hvr4YVL",
        "outputId": "b4e18356-8db2-44d1-f1cf-231e30f3bf41"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='6' response_metadata={'model': 'llama3.1', 'created_at': '2024-09-29T08:45:18.5787066Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2267224400, 'load_duration': 2187193700, 'prompt_eval_count': 47, 'prompt_eval_duration': 44610000, 'eval_count': 2, 'eval_duration': 28589000} id='run-8a15fc9c-2f22-456f-9f88-85f4e24805b7-0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 메모리\n",
        "챗봇을 하기 위해서 앞의 대화를 기억할 메모리가 필요  \n",
        "- ConversationBufferMemory\n",
        "- ConversationBufferWindowMemmory: 앞의 몇 개의 대화를 기억할 것인지\n",
        "- ConversationTokenBufferMemory\n",
        "- ConversationSummaryBufferMemory: 앞의 대화를 요약해서 기억"
      ],
      "metadata": {
        "id": "hdtRD2nhB4k1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://python.langchain.com/v0.1/docs/modules/memory/types/buffer/"
      ],
      "metadata": {
        "id": "jEslGK7CCWz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "XbM3TpcLCn8_"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory()\n",
        "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})"
      ],
      "metadata": {
        "id": "ToBS_xOnCsdw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBTZoHHmC1oG",
        "outputId": "e15f6e48-5b6f-4e71-987e-fc88b3bb8d42"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': 'Human: hi\\nAI: whats up'}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwB4w0NauOiB",
        "outputId": "e780b3ad-b791-4443-d590-cc9a6b92fb72"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
            "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
            "     ----------------- -------------------- 20.5/44.4 kB 682.7 kB/s eta 0:00:01\n",
            "     -------------------------------------- 44.4/44.4 kB 726.3 kB/s eta 0:00:00\n",
            "Requirement already satisfied: filelock in c:\\nlp\\nlp\\lib\\site-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\nlp\\nlp\\lib\\site-packages (from transformers) (0.24.5)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\nlp\\nlp\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\nlp\\nlp\\lib\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\nlp\\nlp\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\nlp\\nlp\\lib\\site-packages (from transformers) (2024.7.24)\n",
            "Requirement already satisfied: requests in c:\\nlp\\nlp\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\nlp\\nlp\\lib\\site-packages (from transformers) (0.20.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\nlp\\nlp\\lib\\site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\nlp\\nlp\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\nlp\\nlp\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: colorama in c:\\nlp\\nlp\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nlp\\nlp\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\nlp\\nlp\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nlp\\nlp\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\nlp\\nlp\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
            "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
            "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.3/9.9 MB 7.9 MB/s eta 0:00:02\n",
            "   --- ------------------------------------ 0.8/9.9 MB 9.7 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 1.6/9.9 MB 12.4 MB/s eta 0:00:01\n",
            "   --------- ------------------------------ 2.4/9.9 MB 14.1 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 3.6/9.9 MB 16.2 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 4.8/9.9 MB 18.0 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 5.9/9.9 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 6.9/9.9 MB 19.2 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 8.5/9.9 MB 21.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  9.9/9.9 MB 22.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.9/9.9 MB 21.8 MB/s eta 0:00:00\n",
            "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
            "   ---------------------------------------- 0.0/286.3 kB ? eta -:--:--\n",
            "   ---------------------------------------- 286.3/286.3 kB ? eta 0:00:00\n",
            "Installing collected packages: safetensors, transformers\n",
            "Successfully installed safetensors-0.4.5 transformers-4.45.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "\n",
        "llm = Ollama(model='llama3.1')\n",
        "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=10)\n",
        "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
        "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})"
      ],
      "metadata": {
        "id": "0q5e8pQ5tUbx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAOJh9_yuat8",
        "outputId": "c98e9030-edb8-4ce9-ab2f-c17081634790"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': 'System: Here are the new summaries:\\n\\nInitial summary:\\nNone (this is the first line of conversation)\\n\\nFirst summary:\\nThe human says \"hi\" to the AI.\\n\\nSecond summary:\\nThe human says \"hi\". The AI responds with a casual greeting, asking \"what\\'s up\".\\n\\nLet me know when you\\'re ready to add more lines!\\nHuman: not much you\\nAI: not much'}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# chain 만들기\n",
        "모델, 프롬프트, 메모리를 연결"
      ],
      "metadata": {
        "id": "3ARGdutKBzYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델\n",
        "from langchain.chat_models import ChatOllama\n",
        "\n",
        "# 프롬프트\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# 메모리\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "# 체인\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "fhxkmqlgC-66"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델\n",
        "chat_model = ChatOllama(model='llama3.1', temperature=0.3)\n",
        "\n",
        "# 프롬프트\n",
        "prompts = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        ('system', '당신은 나의 친구입니다.'),\n",
        "        ('human', '{history}'),\n",
        "        ('human', '{input}')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 메모리\n",
        "memory = ConversationBufferWindowMemory()\n",
        "\n",
        "# 체인\n",
        "conversation = ConversationChain(\n",
        "    memory=memory,\n",
        "    prompt=prompts,\n",
        "    llm=chat_model\n",
        ")"
      ],
      "metadata": {
        "id": "X2tbyPh3ETag"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.invoke(input='안녕 난 오늘 10시에 약속이 있어')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT6W9JHCETWh",
        "outputId": "df6a9257-1120-4bbb-e718-16560c7d2372"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '안녕 난 오늘 10시에 약속이 있어',\n",
              " 'history': 'Human: 안녕\\nAI: 안녕하세요! 오늘 어떻게 지내고 있어요?',\n",
              " 'response': '그럼 잘 지내고 싶어! 10시까지 시간이 남았으니, 뭐하나 하러 갈 생각은 없니?'}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.invoke(input='나 오늘 몇시에 약속이게')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG3eWI7lFQhC",
        "outputId": "add4b733-b558-48eb-a99b-b0d92062f5ff"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '나 오늘 몇시에 약속이게',\n",
              " 'history': 'Human: 안녕\\nAI: 안녕하세요! 오늘 어떻게 지내고 있어요?\\nHuman: 안녕 난 오늘 10시에 약속이 있어\\nAI: 그럼 잘 지내고 싶어! 10시까지 시간이 남았으니, 뭐하나 하러 갈 생각은 없니?',\n",
              " 'response': '10시에 약속이 있습니다.'}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.invoke(input='약속 때 뭐하는 게 좋을까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyqb_dobF3TR",
        "outputId": "107ec49c-107f-49af-d05a-e9ecff4b198e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '약속 때 뭐하는 게 좋을까?',\n",
              " 'history': 'Human: 안녕\\nAI: 안녕하세요! 오늘 어떻게 지내고 있어요?\\nHuman: 안녕 난 오늘 10시에 약속이 있어\\nAI: 그럼 잘 지내고 싶어! 10시까지 시간이 남았으니, 뭐하나 하러 갈 생각은 없니?\\nHuman: 나 오늘 몇시에 약속이게\\nAI: 10시에 약속이 있습니다.',\n",
              " 'response': '그럼 잘 지내고 싶어! 10시까지 시간이 남았으니, 뭐하나 하러 갈 생각은 없니?\\n\\n1. 커피숍에 가서 커피 한잔하기\\n2. 도서관에서 책 읽기\\n3. 공원에 가서 산책하기\\n4. 친구들과 게임하기\\n5. 집에서 영화 xem하기\\n\\n어떤 활동이 좋을까요?'}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "대화 내용을 담고 있음"
      ],
      "metadata": {
        "id": "ROhGwO-VGDez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6UO9MN3F9kq",
        "outputId": "969bda7a-6205-457f-f15c-2780674db8ea"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': 'Human: 안녕\\nAI: 안녕하세요! 오늘 어떻게 지내고 있어요?\\nHuman: 안녕 난 오늘 10시에 약속이 있어\\nAI: 그럼 잘 지내고 싶어! 10시까지 시간이 남았으니, 뭐하나 하러 갈 생각은 없니?\\nHuman: 나 오늘 몇시에 약속이게\\nAI: 10시에 약속이 있습니다.\\nHuman: 약속 때 뭐하는 게 좋을까?\\nAI: 그럼 잘 지내고 싶어! 10시까지 시간이 남았으니, 뭐하나 하러 갈 생각은 없니?\\n\\n1. 커피숍에 가서 커피 한잔하기\\n2. 도서관에서 책 읽기\\n3. 공원에 가서 산책하기\\n4. 친구들과 게임하기\\n5. 집에서 영화 xem하기\\n\\n어떤 활동이 좋을까요?'}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.buffer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY1eaYJzGAb3",
        "outputId": "a771c449-5691-4ab5-a906-c521d46a6605"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: 안녕\\nAI: 안녕하세요! 오늘 어떻게 지내고 있어요?\\nHuman: 안녕 난 오늘 10시에 약속이 있어\\nAI: 그럼 잘 지내고 싶어! 10시까지 시간이 남았으니, 뭐하나 하러 갈 생각은 없니?\\nHuman: 나 오늘 몇시에 약속이게\\nAI: 10시에 약속이 있습니다.\\nHuman: 약속 때 뭐하는 게 좋을까?\\nAI: 그럼 잘 지내고 싶어! 10시까지 시간이 남았으니, 뭐하나 하러 갈 생각은 없니?\\n\\n1. 커피숍에 가서 커피 한잔하기\\n2. 도서관에서 책 읽기\\n3. 공원에 가서 산책하기\\n4. 친구들과 게임하기\\n5. 집에서 영화 xem하기\\n\\n어떤 활동이 좋을까요?'"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC6xUNYOPAyT"
      },
      "source": [
        "# RAG\n",
        "https://modulabs.co.kr/blog/retrieval-augmented-generation/  \n",
        "https://www.ncloud-forums.com/topic/277/\n",
        "\n",
        "LLM의 한계: 학습 데이터에 없는 최신 정보나 특정 도메인 지식은 제공하기 어렵다\n",
        "\n",
        "보완\n",
        "1. 외부 지식을 활용\n",
        "2. 검색된 지식 기반 답변 생성\n",
        "3. 외부 지식을 통해 맥락 이해 향상  \n",
        "\n",
        "\n",
        "RAG가 모든 데이터를 벡터로 만들어(임베딩) Vector DB에 저장\n",
        "\n",
        "사용자가 질문 -> 코사인 유사도로 db안의 모든 데이터 검색해서 비슷한 차원에 있는 데이터 찾음 ->\n",
        "비슷한 데이터 여러 개 찾아서 다시 text로 바꿈 -> 이를 토대로 llm이 답변\n",
        "\n",
        "\n",
        "RAG를 langchain에서 지원"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문서 불러오기 -> document transformer(쪼개기) -> 벡터로 바꾸기 -> DB에 넣기"
      ],
      "metadata": {
        "id": "V3abChmxvoBi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeYv3Qn6Sn9U"
      },
      "source": [
        "# 문서 불러오기\n",
        "Document Loading  \n",
        "https://python.langchain.com/v0.2/docs/integrations/document_loaders/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://blog.naver.com/htk1019/223442628204"
      ],
      "metadata": {
        "id": "_OCi8yaF0JkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSV"
      ],
      "metadata": {
        "id": "chjQhXlvvbtL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdxOsdIrPjgX"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import CSVLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a85APombS0Ox"
      },
      "outputs": [],
      "source": [
        "loader = CSVLoader(file_path='review.csv', encoding='utf-8')\n",
        "document = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xSS6jz1TCPP",
        "outputId": "0a86ba28-7fa3-49e7-a80e-b4162c7e23b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL4r68aCTbv4",
        "outputId": "4583702e-d76f-4e9d-a900-01b21a7e924b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'review.csv', 'row': 0}, page_content='\\ufeff식당: 정식당\\n리뷰: 저의 개인적 취향을 두고 볼 때에는\\n소스가 전체적으로 오일리하고 무거운\\n느낌이 있습니다만, 모든 코스의 식재료 선도,\\n조리된 정도는 무척 좋았으며 특히 디저트는\\n흠잡을 곳이 없을만큼 맛있었고 메인의 굽기도\\n아주 훌륭했습니다. (오리, 소 모두)\\n\\n딱 하나, 자가제면을 하신다는 \"냉면\"코스는\\n조금 더 산뜻함이 있었으면 좋겠다는 생각을\\n해봅니다. 원인이 육수인지, 면인지, 식초류인지..그릇인지 모르겠으나\\n묘한 쿰쿰함이 있었어요.\\n\\n새큼한 맛+쿰쿰한 냄새+트러플오일향+\\n입안을 미끌거리게 만드는 (육수 위에 뜬)\\n식물성 기름같은 무엇이 중구난방으로 느껴져\\n조화롭지 못하다는 기분이었습니다.\\n(비전문가의 개인적 감상입니다.)'),\n",
              " Document(metadata={'source': 'review.csv', 'row': 1}, page_content='\\ufeff식당: 정식당\\n리뷰: 이정도 가격대의 식당을 방문하시는분이라면\\n식사에 대한 기준이 높을꺼라 생각합니다.\\n\\n분위기나 위치 모두 좋고 데이트나 접대하기\\n좋은 자리로 느껴집니다.\\n\\n서버분들 친절하고 설명도 잘해주시고\\n케어도 적재 적소에 해주십니다.\\n\\n식사는 창의성이 돋보이는 음식들이\\n많은 편이고 맛도 좋았습니다.\\n\\n음식은 분명 맛있고 재로도 좋은것들로\\n식사가 제공되었지만 나쁘다기 보다는\\n창의성이라는 놀라움에 비해서는\\n최고의 맛이다 라는 점에서는 아주 살짝\\n아쉬움이 있지 않았나 하는 점 정도 입니다.\\n맛 4점으로 올렸지만 4.5점은 된다고 생각합니다.'),\n",
              " Document(metadata={'source': 'review.csv', 'row': 2}, page_content='\\ufeff식당: 정식당\\n리뷰: 맛만 보면 4.5, 모든걸 더하면 5\\n\\n배를 채우러 가기 보다는 음식이라는 하나의 주제를 즐기기 위해 가는 곳. 분위기 좋은 공간에 동행한 사람과 이야기를 나누면서 맛있는 음식을 즐기면 좋은 추억 하나 적립\\n\\n맛\\n한식 재료를 기반으로 다양하고 새로운 음식을 선보인다. 계절에 따라 메뉴의 변동이 있긴 하지만 이제 우리나라에서도 다양한 한식 다이닝이 생겨서 그런지 신선함은 이제 초기보다는 부족해 보인다.\\n전체적인 음식 맛이야 훌륭하다. 하지만 오히려 메인이라고 볼 수 있는 한우 스테이크가 큰 감흥을 주지못해서 아쉬웠다.\\n\\n응대\\n직원들의 응대는 만점\\n\\n가격\\n2인 디너 기준 와인페어링(5 glass)하면 100만원 조금 넘는 가격'),\n",
              " Document(metadata={'source': 'review.csv', 'row': 3}, page_content='\\ufeff식당: 정식당\\n리뷰: 금액이 좀 비싸지만 미슐렝가이드 레스토랑을 제대로 즐길 수 있어요. 모든 음식은 한식을 베이스로 되어 있지만 다른 곳에서는 한번도 먹어본 적이 없는 음식들이에요. 대부분 맛있고 독특해요.\\n\\n전체 코스를 즐기는데 2시간이 훌쩍 넘게 걸리는데도 마지막 음식이 나올때는 아쉬웠어요. 뷰까지 멋있으면 더 완벽했겠지만 뷰는 거의 없어요. 주차는 발렛주차하면 5천원입니다.'),\n",
              " Document(metadata={'source': 'review.csv', 'row': 4}, page_content='\\ufeff식당: 정식당\\n리뷰: 정말 세상에서 제일 맛있는 음식과 친절한 직원들 ❤️\\n파인다이닝인데 큰 기교를 부리기보다 정말 맛있는 음식을 내온다는 인상을 받았습니다\\n맛있는 김밥과 당근은 꼭 드셔보세요 🥕')]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 행 단위로 불러온다\n",
        "document[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## web"
      ],
      "metadata": {
        "id": "r4nJ0BIp0uZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://namu.wiki/w/NewJeans\")\n",
        "document = loader.load()\n",
        "document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaEup4Mj0vox",
        "outputId": "02fb1b29-8da7-43a8-e501-0aaf50793b19"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://namu.wiki/w/NewJeans', 'title': 'NewJeans - 나무위키', 'language': 'ko'}, page_content='\\n\\n\\nNewJeans - 나무위키\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n최근 변경최근 토론특수 기능NewJeans 최근 수정 시각: 2024-09-28 10:15:02797편집편집편집 권한이 부족합니다. 가입한지 15일 지난 사용자(이)여야 합니다. 해당 문서의 ACL 탭을 확인하시기 바랍니다.닫기토론역사분류NewJeans \\xa0 ACL 규칙으로 일부 이용자의 편집이 제한된 문서입니다. \\xa0 NewJeans 멤버들의 9월 11일자 라이브 방송 등 각종 이슈에 대한 내용은 민희진-HYBE 간 ADOR 경영권 분쟁/전개/2024년 9월 문서를의 번 문단을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을 참고하십시오. \\xa0 은(는) 여기로 연결됩니다. 본 그룹의 데뷔 음반에 대한 내용은 New Jeans(음반) 문서를의 번 문단을의  부분을, 본 그룹이 발매한 동명인 노래에 대한 내용은 New Jeans(노래) 문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을, 에 대한 내용은  문서를의 번 문단을의 번 문단을의  부분을의  부분을 참고하십시오.민지하니다니엘해린혜인 [ 한국 음반 ]New Jeans1st EP2022. 08. 01.Ditto선공개 싱글2022. 12. 19.OMG싱글 1집2023. 01. 02.Super Shy선공개 싱글2023. 07. 07.Get Up2nd EP2023. 07. 21.NJWMX리믹스 앨범2023. 12. 19.How Sweet더블 싱글2024. 05. 24. [ 일본 음반 ]Supernatural더블 싱글2024. 06. 21. [ 참여 음반 ]Zero콜라보 싱글2023. 04. 03.Be Who You Are콜라보 싱글2023. 05. 31.Zero (J.I.D Remix)리믹스 싱글2023. 06. 21.아름다운 구속OST2023. 09. 01.GODS주제곡2023. 10. 04.우리의 밤은 당신의 낮보다 아름답다OST2023. 11. 24. [ 관련 문서 ]활동음반활동공연 및 행사노래광고 및 화보음악 방송 직캠노래방 수록곡콘텐츠유튜브PhoningLIVE팬덤Bunnies응원법굿즈갤러리ⓜ밈뉴진스의 하입보이요우리 엄마엄마가나 XX인데 개추 눌렀다뉴진스럽다기타무대의상수상 경력Rhythm Hive뮤직비디오 등장인물뉴진스 코드 in 부산멤버 간 케미반희수(채널)논란 및 사건 사고 관련 둘러보기 틀 [ 펼치기 · 접기 ]의 소속 [ 펼치기 · 접기 ] [ 소속 / 매니지먼트 아티스트 ]빅히트 뮤직방탄소년단 · 투모로우바이투게더 · 이현플레디스세븐틴 · 프로미스나인 · TWS · BUMZU · 백호 · 황민현KOZ지코 · BOYNEXTDOOR빌리프랩ENHYPEN · ILLIT쏘스뮤직LE SSERAFIMADORNewJeansHYBE LABELS JAPAN&TEAM · 24kumiNAECOHYBE IMMIDNATT하이브 유니버설KATSEYESB Projects애슐리 그레이엄 · 에이바 맥스 · 블랙 아이드 피스 · 칼리 레이 젭슨 · DAN + SHAY · 데이비드 게타 · 데미 로바토 · EDEN · 힐러리 더프 · 저스틴 비버 · kaliii · Ozuna · 켈리 롤랜드 · 스티브 안젤로 · 더 낙스 · PUSH BABY · The Kid LAROI · YG · Lil Dicky · ASHER ROTH · THE SPENCER LEE BAND · THE WANTED Schoolboy Records칼리 레이 젭슨 · CL · 싸이 · 릭스턴 · Sheppard · 토리 켈리 SANDBOX SUCCESSIONDAN + SHAY · DEVIN DAWSON ·FAITH HILL · KACEY MUSGRAVES · KELSEA BALLERINI · LITTLE BIG TOWN · MIDLAND Big Machine RecordsBRIAN KELLEY · CALLISTA CLARK · CARLY PEARCE · DANIELLE BRADBERY · 도트리 · GARY LEVOX · GLEN CAMPBELL · JACKSON DEAN · JAY DEMARCUS · JENNIFER NETTLES · JOHN 5 · KRISTIAN BUSH · MIDLAND · RASCAL FLATTS · RAY WYLIE HUBBARD · STARCRAWLER · SUGARLAND · THE CADILLAC THREE · TIM MCGRAW · WANDA JACKSONValory MusicAARON LEWIS · AVENUE BEAT · BRANTLEY GILBERT · ELI YOUNG BAND · CONNER SMITH · JUSTIN MOORE · KIDD G · MACKENZIE CARPENTER · SHERYL CROW · THOMAS RHETT · TIERA KENNEDY · TYLER RICHBMLG RecordsBRETT YOUNG · CHRIS JANSON · FLORIDA GEORGIA LINE · LADY A · RILEY GREEN · SHANE PROFITTBig Machine John Varvatos Records AYRON JONES · BADFLOWER · THE STRUTS · VIOLET SATURNQuality Control Music미고스 · 퀘이보 · 오프셋 · 릴 베이비 · City Girls · Lil Yachty · Marlo · 24Heavy · Bankroll Freddie · Duke Deuce · Jayy Fox · Jordan Hollywood · Kollision · Layton Greene · Stefflon Don · Wavy Navy Pooh · Lakeyah DanaeeExile Music [ 펼치기 · 접기 ]아티스트CEO김주영사내이사민희진 · 이도경 · 이경준프로듀서250Jinsu Park퍼포먼스 디렉터김은주BLACK.Q관련 문서 : 논란 및 사건 사고 [ 소속 아티스트 ]2PAC6LACKAlessoAnymaAviciiBen Plattbenny blancoBillie EilishBLACKPINKBOYNEXTDOORCamila CabelloCashmere CatCucod4vdDaveDestroy LonelyDJ SnakeDr. Dreeasy lifeElbowElla MaiEllie GouldingElton JohnEminemENHYPENFinneasfromis_9Gracie AbramsGuns N\\' RosesGwen Stefani황민현Imagine DragonsInhalerJ. ColeJacob CollierJay RockJazmin BeanJessie WareJIDJuice WRLDKacey MusgravesKarol GKeaneKen CarsonKendrick LamarLady GagaLana Del ReyLE SSERAFIMLouis the ChildMachine Gun KellyAnymaMIDNATTMoneyBagg YoNewJeansOlivia RodrigoOneRepublicPi\\'erre BournePlayboi CartiRae SremmurROLE MODELThe Rolling StonesScHoolboy QSelena GomezSEVENTEENSheck Wesstill woozyStingStormzySummer WalkerTame ImpalaU2Years & YearsYUNGBLUDZedd [ 관련 문서 ]게펜 레코드The SuperStar의 주요 수상 이력 [ 펼치기 · 접기 ]올해의 아티스트임영웅(2022년)→NewJeans(2023년)→-(2024년)올해의 베스트송IVE〈LOVE DIVE〉(2022년)→NewJeans〈Ditto〉(2023년)→-(2024년)올해의 가수상방탄소년단(2022년)→NewJeans(2023년)→(2024년) 올해의 노래상IVE〈LOVE DIVE〉(2022년)→NewJeans〈Ditto〉(2023년)→(2024년) 디지털 음원 대상IVE〈LOVE DIVE〉(2023년)→NewJeans〈Ditto〉(2024년)→(2025년)올해의 노래윤하<사건의 지평선>(2023년)→NewJeans<Ditto>(2024년)→미정<미정>(2025년)올해의 신인aespa(2022년)→NewJeans(2023년)→KISS OF LIFE(2024년)의 주요 선정 이력 [ 펼치기 · 접기 ]올해를 빛낸 가수 1위 [ 펼치기 · 접기 ]※ 2007년부터 매년 한국갤럽에서 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'올해를 빛낸 가수\\'를 선정한다. 그중 1위만 기록한다.※ 2020년부터 여론조사 대상 연령층이 13~59세에서 60대 이상까지로 확대되었고, 결과 집계는 30대 이하 / 40대 이상으로 이원화되었다. [ 2000년대 ]200720082009원더걸스소녀시대 [ 2010년대 ]20102011201220132014소녀시대싸이조용필아이유20152016201720182019BIGBANG임창정아이유방탄소년단 [ 2020년대 - 30대 이하 ]20202021202220232024방탄소년단NewJeans20252026202720282029 [ 2020년대 - 40대 이상 ]20202021202220232024임영웅20252026202720282029한국인이 좋아하는 가수 [ 펼치기 · 접기 ]※ 2004년 한국갤럽이 창립 30주년을 맞이하여, 다양한 분야에서 한국인이 좋아하는 것들에 대해 알아보는 한국인이 좋아하는 조사 시리즈를 기획해 2004년부터 5년 주기로 발표하고 있다.2004년※ 2004년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위공동 2위4위5위이미자나훈아비조용필현철6위7위8위9위10위태진아신승훈송대관김건모설운도2009년※ 2009년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위2위3위4위5위장윤정BIGBANG태진아이미자소녀시대6위7위공동 8위공동 10위나훈아조용필현철손담비이승철송대관2014년※ 2014년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위2위3위4위5위조용필이선희장윤정아이유태진아6위공동 7위9위10위EXO이승철이미자나훈아소녀시대2019년※ 2019년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위2위3위4위5위방탄소년단장윤정나훈아아이유조용필6위공동 7위9위공동 10위이선희태진아이미자이승철김연자공동 10위15위이문세홍진영TWICE박효신남진16위17위공동 18위임창정송가인김건모설운도진성21위공동 22위성시경거미BLACKPINK잔나비2024년※ 2024년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위2위3위4위5위임영웅아이유방탄소년단나훈아NewJeans6위7위8위9위10위장윤정진성영탁송가인BLACKPINK11위12위13위공동 14위이찬원성시경김연자김호중조용필16위17위공동 18위공동 20위이효리린전유진IVE이문세공동 20위이미자이승철장민호같이 보기: 한국인이 존경하는 인물, 좋아하는 스포츠선수, 좋아하는 소설가, 좋아하는 탤런트, 좋아하는 영화배우, 좋아하는 가수, 좋아하는 노래, 좋아하는 예능인, 좋아하는 유튜버멜론의 전당 - 아티스트 부문 (빌리언스 클럽)  NewJeans혜인 · 하니 · 다니엘 · 민지 · 해린Japan Double Single SupernaturalNewJeans뉴진스 · ニュージーンズ데뷔일 대한민국 행정구 속령2022년 7월 22일[1](데뷔일로부터 +800일, 2주년) 일본 행정구 속령2024년 6월 21일(데뷔일로부터 +100일, 0주년)데뷔 음반 대한민국 행정구 속령EP 1집 New JeansNew JeansNew Jeans 일본 행정구 속령더블 싱글 Supernatural장르K-POP, 댄스 팝, 일렉트로팝, 뭄바톤, R&B, 힙합, 저지 클럽, 뉴 잭 스윙소속사ADOR레이블HYBE LABELS에이전시 미국 행정구 속령인터스코프 레코드유통사 대한민국 행정구 속령YG PLUS 일본 행정구 속령 미국 행정구 속령유니버설 뮤직 그룹 중국 행정구 속령텐센트 뮤직 엔터테인먼트팬덤Bunnies(버니즈)Bunnies(버니즈)Bunnies(버니즈)응원봉빙키봉공식사이트 대한민국 행정구 속령 일본 행정구 속령링크 ⠀[ 펼치기 · 접기 ] 대한민국 행정구 속령공식｜멤버｜｜｜｜｜｜ 일본 행정구 속령 중국 행정구 속령1. 개요2. 멤버2.1. 멤버 간 케미3. 특징3.1. 로고3.2. 그룹명3.3. 콘셉트3.4. 실력3.4.1. 보컬3.4.2. 댄스3.5. 비주얼3.6. 연혁 및 입지3.7. 인기 및 기록4. 수상 경력5. 빌보드5.1. 빌보드 HOT 1005.2. 빌보드 2005.3. 빌보드 글로벌 2005.4. 빌보드 글로벌 200 (미국 제외)6. 음반7. 뮤직비디오7.1. 등장인물8. 활동8.1. Phoning8.1.1. LIVE8.2. YouTube8.3. 음악 방송 직캠8.4. 광고 및 화보8.5. 공연 및 행사9. 팬덤9.1. 응원법9.2. 굿즈10. 여담10.1. 데뷔 전10.2. 브랜드 평판11. 논란 및 사건 사고12. 역대 프로필 사진1. 개요[편집]\"둘, 셋! 안녕하세요, NewJeans입니다!\"2022년 7월 22일에 데뷔한 ADOR 소속의 5인조 다국적 걸그룹.2. 멤버[편집]민지하니다니엘해린혜인2004. 05. 07. (20세) 대한민국 행정구 속령2004. 10. 06. (19세)  호주 행정구 속령 |  베트남 행정구 속령2005. 04. 11. (19세)  호주 행정구 속령 |  대한민국 행정구 속령2006. 05. 15. (18세) 대한민국 행정구 속령2008. 04. 21. (16세) 대한민국 행정구 속령2.1. 멤버 간 케미[편집] \\xa0 자세한 내용은 NewJeans/멤버 간 케미 문서를의 번 문단을의  부분을 참고하십시오.3. 특징[편집]3.1. 로고[편집]음반 발매와 함께 프로모 형식으로 여러 가지 새로운 로고가 올라온다. 뉴진스만의 \\'뉴트로 감성\\'을 살리며 틀에 박히지 않은 다양한 디자인을 선보이고 있다.[2]3.2. 그룹명[편집]대중음악은 일상과 초근접해 있는 문화이기 때문에 마치 매일 입는 옷과 같다. 특히 진(Jean)은 시대를 불문해 남녀노소 모두에게 사랑받아 온 아이템이다. 뉴진스(NewJeans)에는 매일 찾게 되고 언제 입어도 질리지 않는 진처럼 시대의 아이콘이 되겠다는 포부와 New Genes, 즉 새로운 시대를 열겠다는 각오도 동시에 담겨 있다.[3][4]3.3. 콘셉트[편집]5명의 멤버가 모여 어딘가 자유분방하면서도 결합력 있는 독특한 퍼포먼스를 선보인다. 소녀들이 \\'재밌게 즐긴다\\'란 표현이 어울리는 뉴진스만의 청춘 하이틴스러운 컨셉은 \\'자연스럽다\\'라는 느낌을 주어, 뉴진스가 많은 대중들에게 사랑 받는 데에 크게 기여한다. 데뷔곡 Attention과 Hype Boy에서부터 대중들의 눈길을 사로잡는 참신한 군무로 \"자칫하면 어려보이기만 할 수 있는 십대들을 데리고 최적의 컨셉으로 밀고나갔다\"라는 평을 받으며 그룹의 이미지를 확실하게 각인시켰다. 이후 발매된 Ditto와 Super Shy 등 여러 곡에서 역시 무대를 순수하게 즐기며 뛰노는듯한 멤버들의 모습으로 좋은 평가를 받았다.레트로와 힙합을 적절히 섞은 음악적 퀄리티 역시 호평받는 부분이다. 레트로 관련 작업물로 한국 음악계에서 호평받은 프로듀서 250이 뉴진스의 색깔에 걸맞게 호화로운 프로듀싱을 하고, 각 멤버들의 편안한 음색이 조화를 이루어 뉴진스를 한 층 더 뉴진스답게 만들어준다. FRNK 프로듀서의 손에서 나온 Cookie나 OMG 등의 노래에선 통통 튀는 특유의 비트로 뉴진스의 트렌디하고 힙한 면모를 부각시켰으며, 해외에서 특히 사랑받는다.3.4. 실력[편집]3.4.1. 보컬[편집]멤버 전원이 그룹이 추구하는 음악에 맞는 음색과 기술을 가지고 있다고 평가받는다. 곡을 녹음할 때 가이드 보컬을 사용하지 않아 \\'뉴진스\\'만의 음악 스타일을 형성하는 데에 있어 큰 기여를 하고 있으며, 모든 멤버들의 음색이 예쁘면서도 다른 개성이 느껴져 스타일의 폭이 넓다.[5]특이한 점은 여타 그룹과 달리 \"강한 메인보컬\", \"강한 메인래퍼\"의 존재가 없다는 점이다. 기존의 K-POP 그룹들이 벨팅 계열의 파워풀한 메인보컬 혹은 메인래퍼를 넣어 임팩트를 주는 것과는 다르다고 볼 수 있다. 오히려, 의도적으로 보컬의 힘을 빼고 있다는 게 느껴질 만큼 중저음을 내세우고 있다. 이는 90년대 Urban R&B의 영향이 강하게 느껴지는 부분이라 할 수 있는데, 과거 TLC나 토니 브랙스턴처럼 고음보다는 중저음의 바이브가 그대로 뉴진스에도 적용되고 있는 것. 음악평론가 임희윤은 기존의 K-POP 씬에서 볼 수 있던 \\'한국식 마라맛\\'과 다른 \\'한국식 버터맛\\' 이라고 평하기도 했다.#3.4.2. 댄스[편집]2023 TMA Dance Practice2024 SBS 가요대전 Summer Dance Practice멤버들의 전체적인 춤 실력이 매우 뛰어난 편이며, 난이도로 보나 실력으로 보나 4세대 최상위권에 속한다. NewJeans의 곡들이 대부분 힙합 기반의 안무이기에 힘과 유연성을 모두 고려하면서 춰야하는 데다가 넓은 무대에서 돋보이기 위해서는 춤선 또한 부드러워야 한다. 하지만 모든 멤버들이 뒤쳐지지 않고 이를 잘 갖추었기에 담당 안무가가 멤버 개개인의 춤의 개성을 중요시함에도 군무가 전혀 어색하게 느껴지지 않는다.[6]유튜버로 활동하는 한 댄스 트레이너에 의하면 NewJeans 멤버들은 단순히 기계적으로 칼군무와 짜여진 안무를 수행하는 것이 아니라, 각 멤버마다 힙합 댄스의 기본기가 탄탄하고 리듬감이 뛰어나며 이 부분에 대한 트레이닝이 매우 잘되어 있다고 한다.3.5. 비주얼[편집]멤버 전원이 센터급 비주얼을 가졌다. 멤버들 각각의 매력이 뛰어나고 특색 있으며 그 매력들이 적절하게 어우려져 다른 그룹들과는 차별화된 독특하고 신선한 모습을 보여준다.멤버 전원이 160cm 이상이다. 멤버들의 나이가 전체적으로 어려서 추가적으로 클 가능성도 있다.[7]3.6. 연혁 및 입지[편집]데뷔 전부터 SM엔터테인먼트 출신의 아트디렉터 민희진이 처음으로 제작하는 걸그룹이라는 점에서 큰 주목을 받아왔다. 데뷔 첫 앨범부터 신인으로서는 파격적으로 3개의 타이틀곡을 내세워 국내외 각종 음원 및 음반 차트를 휩쓰는 저력을 보여주었다. 성숙한 관능미를 어필하는 세계관이 주류였던 K-POP 걸그룹씬에서, 10대 소녀의 청초함과 깨끗함을 완성도 있는 음악과 결합시키며 데뷔와 동시에 큰 인기를 얻었다. 이러한 인기에 여러 언론은 앞다투어 신드롬급 인기라고 평하는 기사들을 쏟아내었으며, 어딜 가도 NewJeans를 접할 수 있다는 점에서 \\'온세뉴\\'[8]라는 신조어까지 생기거나, 일명 하입보이 밈이 유행하며 열풍을 이어나갔다. 주요 성공 전략 중 하나는 과거의 향수가 느껴진다는 것인데, 실제로 NewJeans는 10대와 20대 팬층은 물론 다른 4세대 K-POP 걸그룹에 비해 30대와 40대의 중년층으로부터 많은 호감도를 얻고 있다. 데뷔 1년 반 만에 NewJeans는 국내의 주요 음악 시상식의 각종 대상을 휩쓸며 자타공인 4세대를 대표하는 걸그룹의 자리에 올랐다.3.7. 인기 및 기록[편집]올해를 빛낸 가수 1위30대 이하 방탄소년단40대 이상 임영웅(2022년)→30대 이하 NewJeans40대 이상 임영웅(2023년)→(2024년)※ 매해마다 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'올해를 빛낸 가수 1위\\'를 선정.[9]올해의 가요 1위방탄소년단〈Dynamite〉(2022년)→NewJeans〈Super Shy〉(2023년)→〈〉(2024년)※ 매해마다 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'올해의 가요 1위\\'를 선정.[10]한국인이 좋아하는 가수 [ 펼치기 · 접기 ]※ 2004년 한국갤럽이 창립 30주년을 맞이하여, 다양한 분야에서 한국인이 좋아하는 것들에 대해 알아보는 한국인이 좋아하는 조사 시리즈를 기획해 2004년부터 5년 주기로 발표하고 있다.2004년※ 2004년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위공동 2위4위5위이미자나훈아비조용필현철6위7위8위9위10위태진아신승훈송대관김건모설운도2009년※ 2009년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위2위3위4위5위장윤정BIGBANG태진아이미자소녀시대6위7위공동 8위공동 10위나훈아조용필현철손담비이승철송대관2014년※ 2014년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위2위3위4위5위조용필이선희장윤정아이유태진아6위공동 7위9위10위EXO이승철이미자나훈아소녀시대2019년※ 2019년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위2위3위4위5위방탄소년단장윤정나훈아아이유조용필6위공동 7위9위공동 10위이선희태진아이미자이승철김연자공동 10위15위이문세홍진영TWICE박효신남진16위17위공동 18위임창정송가인김건모설운도진성21위공동 22위성시경거미BLACKPINK잔나비2024년※ 2024년 한국갤럽이 한국인을 대상으로 실시한 여론조사를 바탕으로 \\'한국인이 좋아하는 가수\\'를 선정.1위2위3위4위5위임영웅아이유방탄소년단나훈아NewJeans6위7위8위9위10위장윤정진성영탁송가인BLACKPINK11위12위13위공동 14위이찬원성시경김연자김호중조용필16위17위공동 18위공동 20위이효리린전유진IVE이문세공동 20위이미자이승철장민호같이 보기: 한국인이 존경하는 인물, 좋아하는 스포츠선수, 좋아하는 소설가, 좋아하는 탤런트, 좋아하는 영화배우, 좋아하는 가수, 좋아하는 노래, 좋아하는 예능인, 좋아하는 유튜버 멜론의 전당 - 아티스트 부문 (빌리언스 클럽)  NewJeans대중성 뿐만 아니라 음악성까지도 높은 평가를 받는 아이돌 그룹으로, 데뷔 앨범부터 좋은 평가를 받아왔다. 덕분에 한국대중음악상[11]에 데뷔 앨범으로 올해의 앨범, 음악인에 노미네이트 되는 성과를 거뒀다.[12]데뷔 9개월 만에 멤버 전원이 글로벌 럭셔리 명품 브랜드의 엠버서더가 되었다. GUCCI와 아르마니 뷰티의 글로벌 엠버서더 하니, Louis Vuitton의 글로벌 엠버서더 혜인, BURBERRY 글로벌 엠버서더와 입생로랑 뷰티의 엠버서더 다니엘, CHANEL의 코리아 엠버서더 민지, DIOR의 글로벌 및 하우스 엠버서더 해린.NewJeans의 데뷔 앨범 두 번째 타이틀곡인 Hype Boy를 주제로 한 뉴진스의 하입보이요 밈은 인스타그램 릴스, 유튜브 쇼츠, 틱톡 등을 중심으로  크게 유행했다. 해당 밈을 인용한 기사까지 있을 정도.#아래는 NewJeans의 대표적인 기록들이다.2NE1, 미쓰에이, aespa, IVE와 함께 신인상과 대상을 동시에 수상한 5번째 그룹이다.NewJeans의 타이틀곡 중 제일 먼저 공개되었던 Attention이 데뷔하자마자 미국 차트쇼에서 1위를 했고, 2022년 8월 9일 23시에 멜론 차트 개편 이후 최초로 데뷔곡으로 1위를 달성했으며 멜론 차트 개편전으로 봐도 예능 방송 음원이 아닌 아이돌 데뷔곡의 경우 2017년 Wanna One의 에너제틱 이후 무려 5년만이며, 걸그룹으로는 2016년 BLACKPINK의 휘파람 이후 6년만에 달성한 대기록이다. 심지어 이용자 수가 폭증하여 2022년 역대 일간 이용자 수가 BIGBANG의 \\'봄여름가을겨울\\'에 이어 2위를 달성했다. Spotify에서는 \\'누적 재생 수\\', \\'누적 청취자 수\\', \\'누적 팔로워 수\\' 3개 부문 모두 2022년에 데뷔한 K팝 걸그룹으로서 최고 기록을 달성했고 한국 스포티파이에서 주간 차트 진입과 동시에 1위를 달성했다. 그리고 대한민국 최초로 데뷔곡 Attention으로 미국 스포티파이 차트에 183위로 진\\'에 성공했으며, 빌보드 Global 200 차트에서 Attention 82위, Hype Boy 116위로 진입했고, 빌보드 Global 200 (미국제외) 차트에서는 Attention 51위, Hype Boy 64위로 각각 진입했다.멜론 역사상 데뷔곡으로 일간차트 1위를 한 걸그룹은 2NE1 (Fire), 미쓰에이 (Bad Girl Good Girl), BLACKPINK (휘파람), NewJeans (Attention) 4팀 뿐이고 데뷔곡으로 월간차트 1위까지 한 걸그룹은 2NE1, BLACKPINK, NewJeans 단 3팀 뿐이다.데뷔 음반 New Jeans는 사흘 만에 선주문 44만 장을 돌파해 걸그룹 역대 데뷔 음반 선주문 최고 신기록을 경신했고, 8월 8일 단 하루만에 26만 2,8**장을 팔아서 역대 걸그룹 데뷔 음반 1일차 최다 판매량을 기록했다. 걸그룹 데뷔 앨범 중 유일하게 발매 당일 판매량 20만 장 돌파, 일주일만에 311,2**장 판매로 대한민국 역대 걸그룹 데뷔 초동 신기록을 경신했다.[13] 또한 2023년을 기준으로 누적 판매량이 100만장을 돌파했으며, 데뷔 앨범의 판매량이 100만장을 돌파한 경우는 그룹으로서 1997년 젝스키스 이후 약 26년만의 기록이다.2022년 12월 31일, 데뷔 약 5개월 만에 스포티파이 한국 \\'주간 톱 아티스트\\'(집계 기간 12월 23~29일) 1위에 올랐다. 이로써 뉴진스는 2016년 이후에 데뷔한 K-POP 그룹 중 유일하게 해당 차트에서 1위에 등극했다.데뷔 앨범에 수록된 4개의 곡 중 3개가 각종 음원 차트 10위권 이내에 랭크되었다.2022년 12월 19일, 발매된 Ditto는 현재 각종 음원 차트에서 14주 연속 1위의 기록을 세웠으며, 역대 걸그룹 최다 일간 1위 횟수를 기록했다.[14] 또한 공개하자마자 일간차트 1위를 달성했으며, 멜론차트 역사상 4번째로 발매 후 바로 일간차트 1위로 진입한 아이돌 그룹 곡이 되었다. 싱글 1집 OMG의 초동 기록은 약 70만장으로, 활동 단 두 번만에 역대 걸그룹 초동 4위에 해당하는 기록을 달성했다.2023년 1월 4일, 국내 음원 차트 점유율 1위인 멜론의 실시간 차트 1, 2, 3위를 석권했으며 일간 차트, 주간 차트는 물론 월간 차트까지 1, 2, 3위를 석권했다.[15]2023년 1월 16일, 국내 음원 차트 점유율 1위인 멜론의 주간 차트에서 1, 2, 3, 7위를 기록하며 10위 내에 4곡 ( Ditto, OMG, Hype Boy, 그리고 Attention)을 포진시킨 역대 두 번째 그룹이 되었다 (2023년 1월 9일~ 1월 15일).[16]2023년 2월 1일, 멜론 월간 (2023년 1월) 1위 Ditto , 2위 OMG , 3위 Hype Boy로 2012년 버스커 버스커, 2014년 MC몽에 이어 약 9년만에 역대 3번째로 멜론 월간 1, 2, 3위를 한 가수가 독차지하는 대기록을 달성했다. 이 기록은 앞선 기록들과 비교해보면 더 대단한데, 세 곡의 발매일자가 각기 다를 뿐만 아니라 3위를 차지한 Hype Boy의 경우 2022년 7월에 발표된 이미 6개월이 넘은 곡이라는 점이다. 앞선 두 기록은 모두 같은 앨범에서 나온 곡들이었다. 뿐만 아니라, 월간 10위권까지 넓히면 7위에 데뷔곡인 Attention이, 20위권안에는 역시 2022년 7월에 발표된 Cookie가 16위에 포진되어 있어 데뷔이래 거의 모든 곡이 20위권안에 포함되는 성적을 보여주었다.국내뿐 아니라 해외 인기도 심상치 않다. 2023년 1월 18일, \\'Ditto\\'가 빌보드 핫 100에 96위로 진입했다.[17] 다른 아이돌그룹들이 보통 데뷔 후 수년간 쌓아온 팬덤을 기반으로 빌보드에 입성한데 비해, NewJeans의 기록은 이례적인 것으로 평가받고 있다. 또한 \\'OMG\\'가 빌보드 핫 100에 91위로 진입한 동시에 \\'Ditto\\'는 85위로 순위가 상승, 핫 100 주간차트에 두 곡을 올려놓았다. K-Pop 역사상 이 차트에 두 곡 이상을 진입시킨 아티스트는 방탄소년단과 BLACKPINK가 유일하다. \\'Ditto\\'는 1월 셋째주 기준, 빌보드뿐만 아니라 영국 오피셜 싱글 차트 \\'톱 100\\'에 2주 연속 진입하기도 했다.▲ 2023년 2월 20일 현재 멜론차트 역대 여성아티스트 주간차트 연속 1위 기록▲ 2023년 2월 20일 현재 멜론차트 역대 1위 사진2023년 2월 2일, 전 음원 사이트에서 Ditto가 1위를 기록한 횟수가 방탄소년단의 히트곡 Dynamite가 세운 종전 최다 기록인 610회를 돌파하며, PAK(Perfect All-Kill)횟수 1위를 기록했다. 총 655회로 현재 걸그룹 및 국내 가수 역대 최다기록이다.2023년 2월 21일, 스트리밍업체 Spotify에서 역대 K-POP 여성 아티스트 중 최다 미국 스포티파이 스트리밍 1위를 Ditto가 2위를 OMG가 차지하는 신기록을 세웠다. (현재 진행 중)▲ 2023년 2월 21일 현재 스포티파이 역대 K-POP 여성아티스트 스트리밍횟수 1, 2위 기록2023년 3월 25일, 멜론 차트에서 1위 Ditto, 2위 OMG, 3위 Hype Boy가 14주 연속 1, 2, 3위를 지키면서 멜론 차트 역대 최장기이자 연속 기간인 14주 연속 1위를 차지한 곡이 되었다. 뿐만 아니라 Attention이 6위로 계속 10위권에 네 곡을 진입시키고 있는 진기록을 썼다.2023년 2월 27일, 벅스 차트에서 Ditto가 벅스 차트 역대 최장기이자 연속 기간인 14주 연속 1위를 차지한 곡이 되었다.2023년 3월 1일, 멜론 차트에서 역대 최초로 월간 top3를 두 달 연속으로 기록(Ditto, OMG, Hype Boy)했고 데뷔 이래 최단 기간 만에 2달 연속 월간 top3를 차지했다.2023년 3월 6일, Ditto가 멜론 차트 역사상 일간 차트에서 가장 많이 1위를 차지한 곡이 되었다. 77회 연속 1위를 차지해 방탄소년단의 히트곡 \\'다이너마이트\\'(Dynamite)가 세운 종전 최다 기록인 75회를 넘어섰다. 이 기록은 2023년 3월 27일까지 계속되어 99일 연속 (2022년 12월19일~ 2023년 3월27일) 일간차트 1위를 차지한 역대 최장기 1위 기록을 남겼다.2023년 3월 19일, 써클차트(구 가온차트) 차트에서 역대 최초로 월간 TOP 3를 두 달 연속으로 기록(Ditto, OMG, Hype Boy)했고 데뷔 이래 최단기간만에 2달 연속 월간 top3를 차지했다. 한국음악콘텐츠협회 측에 따르면 이는 써클차트의 전신인 가온차트가 데이터를 집계한 2010년 이래 최초의 기록이다. (1월은 Ditto가, 2월은 OMG가 1위를 차지했다.)2023년 4월 2일, 멜론 차트에서 역대 최초로 월간 TOP 3를 세 달 연속 (1, 2, 3월)으로 기록(Ditto, OMG, Hype Boy)했다. 한 아티스트가 신곡과 전작 구분 없이 차트 최상위권을 3개월 동안 휩쓴 것은 2004년 11월 멜론 음원 서비스가 시작된 이래 처음이며 이로써 NewJeans는 멜론의 2023년 1분기를 장악했다.2023년 4월 2일, SBS 인기가요에서 전해인 2022년 7월 23일 발매된 Hype Boy가 1위를 차지했다. 발매후 8개월이 지난 곡이 공중파 1위를 차지한 것이다. 이 기록이 대단한 이유는 이 정도로 발매일과 차트성적의 갭이 클 경우 어떤 긍정적인 사건의 발생에 힘입어 잊혀졌던 곡이 차트에 재진입하는 속칭 음원차트 역주행의 형태가 대부분인데 비해, 하입보이의 경우 발매당시에는 자신들의 또다른 히트곡인 Attention, 그리고 2023년에는 신곡인 Ditto와 OMG 때문에 1위에 못 올랐을 뿐, 꾸준히 차트 2~5위내에 거의 8개월간 머무르고 있다가 1위를 차지한 경우라 매우 드문 현상이라 할 수 있다.2023년 4월 4일, 코카콜라와 협업한 광고음악(CM송)인 Zero가 지니 실시간차트 1위, 벅스 실시간 차트 3위, 멜론 \\'톱 100\\' 차트에서 4위, 한국 유튜브 \\'인기 급상승 동영상\\' 1위 등을 차지하는 등 CM송으로서는 이례적인 음원성적을 거두었다.2023년 4월 23일, NewJeans가 중국 QQ뮤직 2023년 1분기 피크 차트 톱10 아티스트에 선정됐다. 또 이들의 싱글 앨범 OMG의 수록곡 Ditto가 톱10 노래로 꼽혔다고 밝혔다. 피크 차트 톱10 아티스트와 노래 부문에 이름을 올린 K팝 가수는 NewJeans가 유일하다.2023년 4월 26일, Ditto가 발매 126일만에 세계 최대 음원 플랫폼 스포티파이에서 스트리밍 횟수 3억 건을 돌파했다. 이로써 NewJeans는 4세대 K-POP 걸그룹 최초로 스포티파이에서 3억 스트리밍 곡을 보유하게 됐다. 스포티파이에 공개된 NewJeans의 노래는 누적 스트리밍 횟수가 13억 건을 돌파했다.2023년 4월 27일, OMG가 발매 115일만에 세계 최대 음원 플랫폼 스포티파이에서 스트리밍 횟수 3억 건을 돌파했다. 선공개곡이었던 Ditto보다 11일 단축시킨 기록이다.2023년 5월 1일, NewJeans가 미국 비영리단체 골드하우스가 발표한 2023년 \\'미국에서 가장 영향력 있는 아시아인 100인\\'에 선정됐다. 골든하우스는 NewJeans를 두고 \"솔직하고 독창적인 음악으로 K-POP의 지평을 넓힌 그룹\"이라며 \"최근 글로벌 히트곡 \\'Ditto\\'와 \\'OMG\\'로 빌보드 \\'핫100\\' 차트에 진입하는 등 여러 기록을 세우고 있다\"고 선정 이유를 밝혔다.2023년 5월 2일, \\'포브스코리아 파워 셀러브리티 40\\' 차트에 27위로 신규 진입했다.2023년 5월 3일, NewJeans의 Ditto가 공개된 지 19주 만에 일본 오리콘 차트에서 1억 스트리밍을 달성했다. 해외 여성 아티스트로서는 최단 기록이며, 남녀 통틀어서는 역대 4위이다.2023년 5월 3일, Hype Boy가 세계 최대 음원 플랫폼 스포티파이에서 스트리밍 횟수 3억 건을 돌파했다. 세 번째 3억 스트리밍 곡이다.2023년 5월 9일, K-POP 가수 중 219일만에 최단 기간으로 스포티파이 합산 누적 10억 스트리밍을 달성해 기네스 세계 기록에 등재되었다. 이는 다른 어떤 K-POP 가수(솔로 남성, 솔로 여성, 그룹)보다 빠른 속도였으며, 기네스 월드 레코드는 당시 NewJeans가 단 6곡으로 낸 성과임을 강조했다.2023년 5월 19일, 미국 포브스가 선정한 \\'아시아에서 영향력 있는 30세 이하 30인\\'에 선정됐다. NewJeans에 대해서는 \"K-POP의 또 다른 센세이션을 일으키기 위한 길목에 놓여있는 그룹. 멤버들이 루이비통, 구찌, 버버리 등 명품 브랜드의 엠버서더로 잇따라 계약을 맺으며 인기를 증명하고 있다\"라고 평가했다.2023년 5월 23일, 미국 타임 \\'2023 차세대 리더\\'로 선정되었다. 미국 시사주간지 TIME은 매년 트렌드 세터들과 선구자들을 발표하고 있다. NewJeans는 23일 공개된 올해 차세대 리더 명단에서 K-POP 아티스트로는 유일하게 이름을 올렸다.2023년 5월 26일, 데뷔 10개월만에 세계 최대 음원 플랫폼 스포티파이에서 누적 스트리밍 횟수 15억회를 돌파했다. 26일 기준 7곡 중 5곡을 스포티파이 억대 스트리밍 반열에 올렸다.2023년 6월 29일, OMG가 세계 최대 음원 플랫폼 스포티파이에서 NewJeans의 곡 중 가장 먼저 스트리밍 횟수 4억 건을 돌파했다. 이어서 7월 27일 Ditto가 스트리밍 횟수 4억 건을 돌파했다.2023년 7월 14일, 써클차트 상반기 총 리뷰에서 Ditto가 디지털 차트 정상에 올랐다. 이어 OMG가 2위, Hype Boy가 3위를 차지했다. 뉴진스의 또 다른 데뷔곡 Attention은 7위를 기록했다. 이로써 뉴진스는 2023 상반기 디지털 차트 부문 톱10 에 4곡이나 올려놓는 저력을 발휘했다. 음원뿐만이 아닌 음반 부문에서도 뉴진스는 강세를 보였다. 2023년 상반기 가수별 피지컬 앨범 판매량 점유율을 살펴보면 뉴진스가 걸그룹 가운데 1위를 차지했다. 데뷔 앨범 \\'New Jeans\\' 2종과 싱글 앨범 \\'OMG\\' 2종이 올해 상반기에만 도합 220만 3,778장 판매됐다. 7월 7일 발매된 선공개 싱글 Super Shy가 24시간 스트리밍 1,468,200회를 기록하여 멜론의 전당에 올랐다. 또한 7월 21일에 발매한 미니 2집 Get Up이 멜론 24시간 스트리밍 4,114,400회를 기록했다. 이는 역대 24시간 스트리밍 10위에 달하는 기록이다.2023년 8월 1일, 데뷔 1년만에 세계 최대 음원 플랫폼 스포티파이에서 누적 스트리밍 횟수 20억회를 돌파했다. 지금까지 발표한 총 15곡 중 6곡을 스포티파이 억대 스트리밍 반열에 올렸다.2023년 8월 2일, 빌보드가 2일(현지 시간) 발표한 최신 차트(7월30일~8월5일)에서 뉴진스의 미니 2집 \\'겟 업\\'(Get Up)이 메인 앨범차트인 \\'빌보드 200\\'에서 1위를 차지했다. 이로써 뉴진스는 BLACKPINK에 이어 \\'빌보드 200\\' 1위를 달성한 역대 두 번째 K-POP 걸그룹이 되었다. 또한 메인 싱글차트인 빌보드 Hot 100에 타이틀곡 전곡인 세 곡을 올려놓았다. \\'슈퍼 샤이\\'(Super Shy)는 \\'핫100\\' 48위에 올랐으며 \\'ETA\\'와 \\'쿨 위드 유\\'(Cool With You)는 각각 81위, 93위를 차지했다. 빌보드 핫 100에 3곡 이상 동시에 진입한 최초의 K팝 여성 아티스트가 되었으며 남녀 K-POP 아티스트를 통틀어도 방탄소년단(BTS)이 유일하다. 또한 전세계 걸그룹을 모두 합쳐서도 역대 4번째 기록이다.2023년, 영국의 유력 패션 매체인 더 비즈니스 오브 패션(The Business of Fashion)이 매년 발표하는 패션계에서 가장 영향력 있는 500인(BoF 500) 리스트에 선정되었다.[18] 2023년 명단에서 유일한 K-POP 여성 아티스트로 이름을 올렸으며[19], \"대세 그룹 뉴진스는 한국 팝스타를 따르는 강력한 팬덤을 활용하려는 패션 브랜드들에게 높은 잠재력을 갖고 있다\"라며 패션계에서의 뉴진스의 위상과 영향력을 집중 조명했다. 또한 \"뉴진스의 빠른 성장세는 K-POP 업계에서는 이례적\"이라고 평가하기도 했다.2023년 10월 25일, 스포티파이에 따르면 Super Shy가 10월 23일 기준 3억 106만 5169회 재생되었다고 밝혔다. 이로써 Super Shy는 역대 뉴진스 곡 가운데 최단 기간에 스포티파이 3억 스트리밍을 돌파했다.뉴진스는 데뷔 1년 만에 빌보드 뮤직 어워드(BBMA) 수상 후보로 지명되는 동시에 K-POP 아티스트 최다 노미네이트라는 쾌거를 이루었다. 뉴진스는 \\'톱 빌보드 글로벌 (미국 제외) 아티스트\\'(Top Billboard Global (Excl. U. S.) Artist, \\'톱 글로벌 K-POP 아티스트\\', \\'톱 K-POP 앨범\\'(\\'겟 업\\'(Get Up)), \\'톱 K-POP 송\\'(\\'디토\\'(Ditto), OMG) 등 4개 부문, 총 5개의 후보로 지명됐다.싱글 앨범 \\'OMG\\'가 발매 297일 만에 세계 최대 음원 플랫폼 스포티파이에서 합산 누적 10억 스트리밍을 기록했다. 2023년 10월 26일 동명의 타이틀곡 \\'OMG\\'는 5억2천558만4천886회, 수록곡 \\'디토\\'(Ditto)는 4억7천525만2천716회 재생됐다. 이로써 두 곡의 합산 누적 재생 수는 10억83만7천602회로 집계됐다.2023년 11월 9일, 세계 최대 스트리밍 플랫폼 스포티파이에 따르면, 뉴진스가 지금까지 발표한 곡의 총 스트리밍 횟수는 지난 7일 기준 30억 657만 3,564회로 집계됐다. 이에 따라 뉴진스는 데뷔 후 약 1년 3개월 만에 초고속으로 누적 30억 스트리밍 고지를 밟게 됐다.2023년 11월 20일, K팝 걸그룹 최초로 빌보드 뮤직 어워드에서 공연했다. \\'BBMAs\\'에서 공연한 K팝 그룹은 방탄소년단이 유일하다. 뉴진스는 K팝 걸그룹 최초이자, 남녀 통틀어 K팝 그룹으로는 데뷔 후 최단기간(1년 3개월)에 \\'BBMAs\\' 퍼포머로 선정됐다. 이러한 성과를 바탕으로 뉴진스는 \\'2023 BBMAs\\'에서 \\'톱 빌보드 글로벌(미국 제외) 아티스트(Top Billboard Global(Excl. U.S.) Artist\\', \\'톱 글로벌 K팝 아티스트(Top Global K-pop Artist)\\', \\'톱 글로벌 K팝 송(Top Global K-pop Song)\\', \\'톱 K팝 앨범(Top K-pop Album)\\' 등 총 4개 부문(톱 글로벌 K팝 송 복수 노미네이트 포함 총 5개) 수상 후보에 오르며, 최다 노미네이트 K팝 아티스트가 됐다. \\'글로벌 K팝 아티스트(Top Global K-pop Artist)\\'상을 수상했다.2023년 11월 22일, 일본에서 정식으로 데뷔하기도 전에 뉴진스의 Ditto가 일본 최고 권위의 음악 시상식인 \\'일본 레코드 대상\\'에서 \\'우수작품상\\'과 \\'특별상\\'에서 2관왕과 동시에 대상 후보에 올랐다. 특히 1959년 시작된 유서깊은 이 상의 역사에서 외국가수의 싱글곡이 그 해 일본내의 최고의 싱글 10곡인 \\'우수작품상\\'에 선정된 것은 첫 사례이다. \\'우수작품상\\'은 그해 발표된 곡 중 대중에게 큰 인기를 얻고 예술성, 독창성, 기획성이 뛰어난 곡에 주어지는 상으로 이 부분에 선정된 싱글 10곡은 \\'일본 레코드 대상\\'의 대상 후보가 되는데, 이에 따라 \\'Ditto\\'는 12월 30일 생중계되는 시상식에서 대상 수상을 노리게 됐다.2023년 11월 29일, 발표된 애플 뮤직 연말 차트(집계 기간 : 2022년 11월 1일 ~ 2023년 10월 31일)의 \\'2023년 TOP 100: 대한민국\\'에서 Ditto가 1위를 한 것을 포함해 OMG, Hype Boy가 2, 3위를 하는 등 Top 10에 5곡(Attention, Super Shy 포함)을 올리는 저력을 발휘했다. 더 놀라운 것은 해당 차트에 그동안 발표한 모든 곡이 100위 안에 차트인 했다는 점이다(Get Up은 짧은 곡이라 제외). 또한 \\'2023년 TOP 100: 글로벌\\'에는 Ditto가 19위를 차지해 이 차트에서 K-Pop 작품 중 가장 높은 성적을 기록했고, OMG 37위, Hype Boy 64위 등 3곡을 \\'2023년 TOP 100: 글로벌\\' 차트에 올렸다. 그 외에도 중국, 일본, 싱가포르, 말레이시아, 사우디아라비아, 인도네시아 등 여러 국가 연말 차트에 차트인 해 그 인기를 확인시켰다.2023년 12월 2일, 세계 최대 음원 스트리밍 플랫폼 스포티파이에서 뉴진스의 Ditto가 OMG에 이어 뉴진스 통산 두 번째 5억 스트리밍 곡이 됐다. 특히 공개 1주년이자 겨울이 다가오면서 Ditto의 일간 스트리밍 횟수가 급증하여 평상 시 대비 1.7배 정도의 증가를 보이고 있다고 분석하고 있다.2023년 12월 4일, 영국의 유명 음악 매체 NME에서 발표한 \\'The 50 Best Songs of 2023\\'에서 Super Shy가 전체 2위로 K-Pop 아티스트 가운데 가장 높은 순위를 기록했다. 해당 매체의 기사에서는 뉴진스에 대해 \\'흠잡을 데 없는 싱글 및 댄스루틴을 선보인 뉴진스의 노래 중 가장 좋은 노래를 고르는 일은 매우 어려운 일\\'이라고 전제하면서 그럼에도 불구하고 Jersey Club에서 영감을 받은 Super Shy는 \\'공기처럼 가볍고 통통 튀며 달콤한 태도를 완벽하게 요약하여 2분 30초를 인생에서 가장 아찔한 팝 라이드로 만들었다\\'고 평가했다.2023년 12월 19일, 한국갤럽이 발표한 올해의 가수와 가요 조사에서 30대 이하(39세 이하) 부문에서 전체 조사 대상(2489명) 중 25.7%의 선택을 받아 \"2023년 올해를 빛낸 가수\"에 선정되었다. 한국갤럽은 2022년에 데뷔하자마자 공동 5위를 한 뉴진스가 이번에 1위로 약진하여 돌풍의 주인공이 되었다고 평가했다. 또한 \"2023년 올해의 가요\"에서 Super Shy가 6.8%의 선택을 받아 올해의 가요로 선정되었다. 특히 이 부문에서 뉴진스는 Super Shy 1위, Hype Boy 5위, ETA 6위로 10위 안에 3곡을 올려놓았다.2024년 1월 5일, 세계 최대 음원 스트리밍 플랫폼 스포티파이에 따르면 뉴진스의 두 번째 EP Get Up이 합산 누적 10억 스트리밍을 달성했다고 발표했다. 이로써 뉴진스는 앞서 데뷔 앨범 New Jeans, 싱글 앨범 OMG에 이어 Get Up까지 \\'스포티파이 재생 수 10억 회\\'를 넘긴 세 개의 앨범을 보유하게 됐다.2024년 1월 9일, 발표된 멜론 연간차트에서 Ditto와 Hype Boy가 연간 1, 2위에 올랐으며 TOP 10에 4곡, TOP 100에 8곡이 차트인했다. 멜론 연간차트 1, 2위를 동시에 차지한 것은 역대 최초이고 TOP10에 네 곡을 넣은 것은 역대 최다 기록이다.[20]2024년 1월 23일, 2nd EP \\'Get Up\\'이 빌보드 200에 26주 연속으로 차트인했다. 이는 4세대 K-Pop 그룹 중 최장 기록이며, BLACKPINK의 THE ALBUM과 함께 역대 K-Pop 걸그룹 최장 기록 타이틀을 가지게 되었다.빅뱅과 더불어 한해에 갤럽 1위(가수, 노래), 멜론 뮤직 어워드 대상, 마마 어워즈 대상, 골든디스크어워즈 대상, 한국대중음악상 대상을 모두 수상한 유이한 가수이다.2024년 5월 21일 진행된 2024 코리아 온 스테이지에서 한국 걸그룹 최초로 근정전에서의 무대를 선보였다.2024년 5월 31일, 빌보드가 선정한 21세 이하 가장 영향력 있는 아티스트 21인 \\'21 언더 21\\'에 뉴진스가 포함되었다. K-POP 아티스트 중 유일하게 이 명단에 이름을 올렸다. #2024년 6월 26일, 27일 진행된 팬미팅 Bunnies Camp 2024 Tokyo Dome으로 해외 아티스트 중 데뷔 이후 최단 기간인 1년 11개월만의 도쿄 돔 입성 기록을 세웠다.다음은 2022년 7월 22일 데뷔 이후 뉴진스의 \\'아이돌 차트\\' 순위이다. 아이돌 차트월순위2022년8월1위 (2위 IVE, 3위 BLACKPINK)9월3위 (1위 BLACKPINK, 2위 IVE )10월1위 (2위 IVE, 3위 (여자)아이들)11월2위 (1위 윤하, 3위 IVE)12월1위 (2위 윤하, 3위 LE SSERAFIM)2023년1월1위 (2위 LE SSERAFIM, 3위 윤하)2월1위 (2위 방탄소년단, 3위 BLACKPINK)3월1위 (2위 방탄소년단, 3위 BLACKPINK)4월2위 (1위 IVE, 3위 지수)5월3위 (1위 IVE, 2위 LE SSERAFIM)6월4위 (1위 IVE, 2위 LE SSERAFIM, 3위 (여자)아이들)7월1위 (2위 IVE, 3위 LE SSERAFIM)8월1위 (2위 IVE, 3위 정국)9월1위 (2위 AKMU, 3위 IVE)10월2위 (1위 IVE, 3위 AKMU)11월2위 (1위 IVE, 3위 정국)12월1위 (2위 IVE, 3위 LE SSERAFIM)2024년1월1위 (2위 IVE, 3위 RIIZE)2월6위3월7위4월1위 (2위 LE SSERAFIM, 3위 ILLIT)5월1위 (2위 aespa, 3위 IVE)6월1위 (2위 aespa, 3위 QWER)7월1위 (2위 aespa, 3위 (여자)아이들)4. 수상 경력[편집] \\xa0 자세한 내용은 NewJeans/수상 문서를의 번 문단을의  부분을 참고하십시오.5. 빌보드[편집]5.1. 빌보드 HOT 100[편집]발매일이 빠를수록 위에 기재하며, 발매일이 같으면 순위가 높을수록 위에 기재함. HOT 100 최고 순위#연도제목최고 순위차트인비고12023Ditto82위5주[21]2OMG74위6주[22]3Super Shy48위8주[23]4ETA81위5Cool With You93위빌보드 Hot 100에 3곡 이상 동시에 진입한 최초의 K팝 여성 아티스트이자, 전세계 걸그룹 중 역대 4번째 기록이다.5.2. 빌보드 200[편집] 200 최고 순위#연도제목최고 순위차트인비고12023Get Up1위26주커리어 하이최장 기간 차트인4세대 K-POP 그룹 최장 기록K-POP 걸그룹 최장 기록[24]5.3. 빌보드 글로벌 200[편집]빌보드 200 최고 순위 #연도제목최고 순위비고12022Attention54위2Hype Boy52위[25]31주 연속 차트인해당 부문 K-POP 여성 아티스트 최장 기간[26]32023Ditto8위첫 톱 10 진입4OMG30위5Super Shy2위진입 순위 커리어 하이6New Jeans32위진입 순위72024How Sweet15위8Bubble Gum30위5.4. 빌보드 글로벌 200 (미국 제외)[편집]빌보드 글로벌 최고 순위 #연도제목최고 순위비고12022Attention69위음원 발매 8일 만에 빌보드 차트 진입2Hype Boy40위32023Ditto4위4OMG19위5Super Shy2위진입 순위  커리어 하이6ETA10위72024 How Sweet7위8Bubble Gum18위6. 음반[편집] \\xa0 자세한 내용은 NewJeans/음반 문서를의 번 문단을의  부분을 참고하십시오.7. 뮤직비디오[편집]Music Video2024년 8월 2일 16시 00분 기준 (KST)NewJeans 실시간 뮤직비디오 조회수 추이[27] [ 펼치기 · 접기 ]목록곡명조회수 / 게시일링크1Attention수록 앨범 New Jeans67,554,0822022. 7. 22.2Attention (Performance ver.)수록 앨범 New Jeans61,257,0472022. 7. 22.3Hype boy (MINJI ver.)수록 앨범 New Jeans25,695,0112022. 7. 23.4Hype boy (DANIELLE&HAERIN ver.)수록 앨범 New Jeans27,966,9222022. 7. 23.5Hype boy (HYEIN ver.)수록 앨범 New Jeans6,259,6562022. 7. 23.6Hype boy (HANNI ver.)수록 앨범 New Jeans10,418,8752022. 7. 23.7Hurt수록 앨범 New Jeans39,940,7632022. 7. 25.8Cookie수록 앨범 New Jeans100,871,409[28]2022. 8. 1.9Hype boy (Performance ver.1)수록 앨범 New Jeans188,139,665[29]2022. 8. 18.10Hype boy (Performance ver.2)수록 앨범 New Jeans29,766,0322022. 8. 24.11Ditto (side A)수록 앨범 OMG46,210,2972022. 12. 19.12Ditto (side B)수록 앨범 OMG22,351,2692022. 12. 19.13OMG 수록 앨범 OMG36,624,7312023. 1. 2.14OMG (Performance ver.1)수록 앨범 OMG266,354,354[30]2023. 1. 3.15OMG (Performance ver.2)수록 앨범 OMG6,655,9692023. 1. 3.16OMG (Performance ver.3)수록 앨범 OMG3,655,8202023. 1. 4.17Zero 수록 앨범 Zero20,705,2322023. 4. 3.18New Jeans 수록 앨범 Get Up31,452,5542023. 7. 7.19Super Shy 수록 앨범 Get Up202,064,326[31]2023. 7. 7.20Cool With You (side A)수록 앨범 Get Up17,924,1912023. 7. 20.21Cool With You & Get Up (side B)수록 앨범 Get Up11,193,2572023. 7. 20.22Cool With You (Performance ver.)수록 앨범 Get Up19,286,7252023. 7. 21.23ETA수록 앨범 Get Up79,803,7682023. 7. 21.24ETA (Performance ver.)수록 앨범 Get Up51,025,6062023. 7. 25.25ASAP수록 앨범 Get Up27,756,5912023. 7. 26.26Bubble Gum수록 앨범 How Sweet53,930,7792024. 4. 27.27How Sweet수록 앨범 How Sweet30,811,1212024. 5. 24.28Right Now수록 앨범 Supernatural15,665,1872024. 6. 17.29Supernatural (Part. 1)수록 앨범 Supernatural20,827,6162024. 6. 21.30Supernatural (Part. 2)수록 앨범 Supernatural5,995,2482024. 7. 5.7.1. 등장인물[편집] \\xa0 자세한 내용은 NewJeans/뮤직비디오 등장인물 문서를의 번 문단을의  부분을 참고하십시오.8. 활동[편집] \\xa0 자세한 내용은 NewJeans/활동 문서를의 번 문단을의  부분을 참고하십시오.8.1. Phoning[편집] \\xa0 자세한 내용은 Phoning 문서를의 번 문단을의  부분을 참고하십시오.8.1.1. LIVE[편집] \\xa0 자세한 내용은 NewJeans/Phoning LIVE 문서를의 번 문단을의  부분을 참고하십시오.8.2. YouTube[편집] \\xa0 자세한 내용은 NewJeans/유튜브 문서를의 번 문단을의  부분을 참고하십시오.8.3. 음악 방송 직캠[편집]음악 방송 직캠 모아보기민지/직캠하니/직캠다니엘/직캠해린/직캠혜인/직캠 \\xa0 자세한 내용은 NewJeans/음악 방송 직캠 문서를의 번 문단을의  부분을 참고하십시오.8.4. 광고 및 화보[편집] \\xa0 자세한 내용은 NewJeans/광고 및 화보 문서를의 번 문단을의  부분을 참고하십시오.8.5. 공연 및 행사[편집]단독 공연 문서 모아보기 [ 펼치기 · 접기 ]BunniesCampFAN MEETING2023/07/01 ~ 07/02Bunnies Camp 2024 Tokyo DomeFAN MEETING2024/06/26 ~ 06/27 \\xa0 자세한 내용은 NewJeans/공연 및 행사 문서를의 번 문단을의  부분을 참고하십시오.9. 팬덤[편집] \\xa0 자세한 내용은 Bunnies 문서를의 번 문단을의  부분을 참고하십시오.9.1. 응원법[편집] \\xa0 자세한 내용은 NewJeans/응원법 문서를의 번 문단을의  부분을 참고하십시오.9.2. 굿즈[편집] \\xa0 자세한 내용은 NewJeans/굿즈 문서를의 번 문단을의  부분을 참고하십시오.10. 여담[편집]2022년에 가장 기대되는 K-POP 걸그룹 1위로 선정되었다. ADOR 대표인 민희진이 제작 총괄해서 그룹명이 공개되기 전까진 민희진 걸그룹으로도 불렸다.데뷔일인 2022년 7월 22일 기준, 멤버들의 평균 나이는 16.4세다.[32][33][34]멤버 전원이 한국어와 영어, 일본어를 할 수 있다. 데뷔 직전 민희진이 뉴진스 데뷔조에 대해 \\'모든 멤버가 한국어와 영어를 할 수 있다\\'고 언급했다.[35] 실제로 하니와 다니엘은 영어 원어민이고, 민지는 약간의 캐나다 거주 경험이 있어 영어를 잘한다. 해린과 혜인도 영어로 소통할 수 있다.7월 1일에 멤버 수를 의미하는 하트 눈의 다섯 마리의 토끼가 각각 초록색, 흰색, 분홍색, 하늘색, 노란색 등의 색상들을 가지고 순서대로 같은 방향을 향해 롤러스케이트를 타고 있으며, 그중에 센터에 있는 분홍색 토끼와 마지막 노란색 토끼 두 마리만 불꽃 같은 아우라를 내뿜고 있는 영상이 공개되었다.#2022년 8월 1일, 공개된 New Jeans의 멤버별 앨범을 통해 초록색 토끼는 다니엘, 흰색 토끼는 해린, 분홍색 토끼는 하니, 하늘색 토끼는 혜인, 노란색 토끼는 민지로 확인되었다. 2022년 11월 12일자에 공개된 NewZips 에피소드에서 불꽃 아우라를 내는 토끼들은 민지와 하니에 대응되는데 이는 데뷔 전 먼저 공개되었던 멤버들을 의미하는 것으로 민희진의 아이디어라고 한다.멤버들의 평균 키는 166.1cm이며[36], 멤버 전원이 160cm 이상이다. 멤버들 간의 키 차이가 그리 크지 않은 편이라 전체적으로 조화를 이룬다.멤버 모두 자매가 있으며[37] 남동생은 없다.[38]하니를 제외한 모든 멤버가 4, 5월생이다.[39][40]모든 ABO식 혈액형이 존재하는 걸그룹이다.[41]한국 국적 멤버 전원이 수도권 광역전철이 운행되는 지역 출신이다.[42][43]데뷔조에 가장 먼저 합류한 멤버는 민지이고, 가장 마지막에 합류한 멤버는 막내인 혜인이라고 밝혔다.뉴진스에는 정해진 포지션이 없지만 엠넷 엠 카운트다운에서 각 팀의 메인보컬들만 참가한 엠카 보컬 챌린지에서 하니와 다니엘이 보컬 대표로 참가했다.멤버 전원이 숙소에서 생활한다. 2023년 12월 17일 현재 모두 각방을 쓴다고 밝혔으며 이전까지는 룸메이트를 주기적으로 제비뽑기를 통해 바꾸어왔었다.다른 HYBE LABELS 소속 아티스트들과 달리 소통 어플로 Weverse를 쓰지 않고 WEVERSE COMPANY에서 새로 제작한 Phoning이라는 어플을 사용한다.뉴진스의 각종 로고 이미지, 일부 의상이나 공식 홈페이지와 전용 소통 어플인 Phoning의 화면 구성 등은 뉴트로 스타일로 구성되었다.2022년 8월 6일, Phoning 라이브 콜에서 리더가 없다고 했으며, 멤버들이 모든 면에서 다 잘하고 싶어서 정해진 포지션은 없다고 밝혔다.NewJeans의 총괄 프로듀서는 민희진이고, 메인 프로듀서는 250과 Jinsu Park이며, 믹싱 담당은 그래미 어워드 사운드 엔지니어 부문 수상자이자 해외에서도 탑 클래스로 유명한 토니 마세라티이다.처음부터 티저를 생략하고[44] 뮤직 비디오부터 공개한 이유는 민희진이 공식을 싫어하는 편이며[45], 이미 많은 관심 속에서 데뷔하는 것이기 때문에 티저가 필요 없다고 생각했다고 한다. 대신 호기심 때문에라도 최초 공개 콘텐츠를 봤을 때 뉴진스의 음악을 무조건 청취하게 만들 수 있는 기회라고 생각했고[46], 오래 기다려준 팬들을 애태우게 하고 싶지도 않았다고 밝혔다.2022년 9월 9일, 스타뉴스 창간 18주년을 맞아 대중음악계 영향력 있는 전문가 18인을 대상으로 \\'앞으로 활약이 가장 기대되는 4세대 아이돌\\'에서 걸그룹 부문 1위를 달성했다.2022년 10월 12일, 코스모폴리탄은 뉴진스가 시대의 새 얼굴이 된 이유에 대해 보도했다.2022년 10월 12일, 기사에 따르면 100여 개 기업으로부터 광고 러브콜을 받았다고 한다.뉴진스를 만든 민희진 대표는 유퀴즈에 출연해 뉴진스는 데뷔하고 2개월만에 수익 정산을 받았다고 밝혔다. 아이돌이 데뷔 2개월만에 수익 정산을 받는 것은 이례적인 일이기 때문에 화제가 되었다.#2022년 12월 29일, 청각장애인 지원을 위해 음반 판매 수익금을 기부했고 매년 음반 판매 수익의 일정 부분을 지속적으로 기부할 예정이라고 밝혔다.2023년 1월 23일, 뉴스1과의 신년 인터뷰를 통해 민희진 대표가 뉴진스 멤버들에게 강조하는 점은 \\'솔직함\\'이라고 밝혔다. 혜인은 \"민희진 대표님께서 평소에 사람이 솔직해야 그 사람의 매력이 느껴진다고 얘기를 해주셨다.\"라고 인터뷰 했다.#2023년 2월 17일, 튀르키예·시리아 대지진 사태에 소속사 ADOR와 함께 2억 원을 기부했다.#걸그룹 브랜드 평판에서 2022년 12월부터 2023년 3월까지 4달간 연속 1위를 달성했다.무대에 오르기 전 멤버들이 만든 파이팅 구호인 일명 샌드위치를 한다. 보통 손을 모으고 파이팅을 외치며 손을 들어올리거나 내리는 형식이지만, 뉴진스만의 파이팅 구호, 일명 샌드위치는 서로의 양손을 모두 겹친 채 눈을 마주치며 꾹 누른다. 안하고 무대에 오르면 약간의 아쉬움이 남는다고.2023년 7월 22일, 데뷔 1주년 을 맞아 \\'NewJeans Day\\'라는 이름으로 여러 행사를 진행했다.NewJeans의 실제 발음은 [njuːdʒiːnz]로 \\'뉴진스\\'가 아닌 \\'뉴진즈\\'에 가깝다.2023년 9월 19일, KBS 뉴스 9에 역대 최연소의 나이로 출연했다.[47]2023년 12월 기점으로 참여한 드라마 OST가 모두 리메이크곡이다.[48]2024년 5월 14일부터 대영박물관의 한국실 내 주요 전시 작품의 공식 오디오 가이드를 뉴진스의 목소리로 들을 수 있게 되었다. 이는 뉴진스의 재능기부로 알려졌다.2024년 5월 27일, 버니즈프로덕션에서 주관한 싱글 앨범 How Sweet 컴백 기념 카페에 멤버들이 직접 방문했다. 멤버들이 작성한 메모 #2024년 5월 대학축제에서 벌어들인 수익 전액을 한국장학재단에 기부했다.#얼굴도 예쁘지만 스탭들 말에 따르면 마음씨도 예쁘다고.10.1. 데뷔 전[편집]민희진은 빅히트 엔터테인먼트, 쏘스뮤직과 합작해 2019년 10월부터 전 세계 7개국의 16개 도시를 돌며 5만 명이 넘게 지원한 플러스 글로벌 오디션을 진행했다. 2019년 말 오디션 및 캐스팅으로 선발된 데뷔조 멤버들은 2020년 초부터 연습을 시작했으며, 처음에는 합작 프로젝트로 시작해서 2021년 론칭 예정이었지만 코로나19 이슈로 늦춰졌고, 그 사이에 민희진의 레이블인 ADOR 론칭이 예정보다 앞당겨지며 민희진이 직접 발탁한 데뷔조 멤버들은 모두 ADOR에서 뉴진스로 데뷔하게 되었다.하지만 원래 쏘스뮤직 연습생이었던 민지와 다른 뉴진스 멤버를 모집한 뒤 뉴진스를 HYBE 1호 걸그룹으로 데뷔시킬 예정이었으나 코로나로 인해 미뤄졌고 그 사이에 HYBE에서 LE SSERAFIM을 HYBE 1호 걸그룹으로 데뷔 시킬 준비를 마친 상태에서 뉴진스를  2호 걸그룹으로 데뷔 시켰다고 한다. 이에 분한 민희진이 따로 소속사를 만들어 줄 것을 요구해서 지금의 상황이 된 것이다.[49][50]처음부터 5인조 걸그룹으로 기획 되었다. 민희진이 기획한 2019년 오디션 홍보 영상의 마차에서 5명이 내리는 장면이 나온다.[51]2021년 7월 9일, 방탄소년단의 Permission to Dance MV에 멤버 민지, 하니 두 명이 출연했었고, 민지는 2017년부터 연습생이었어서 2019년 플러스 글로벌 오디션 홍보 영상에도 출연했으며, 해당 오디션 및 캐스팅을 통해 선발되어 멤버 전원이 10대인 소녀들을 중심으로 기획되었다.민희진은 데뷔팀 지향점을 \\'숙련\\'보다는 \\'즐기기\\'에 두고 있고, 진심으로 즐기는 사람에게서 나오는 에너지는 엄청나게 강력해서 보는 사람까지도 춤추게 만든다고 한다고 말했다. 그리고 업계에서 (내가 아닌) 남이 말해줬을 때 듣기 좋았던 말 중 가장 기분 좋은 두 단어가 \\'세계관\\'과 \\'아티스트\\'라고 말했는데, 대신 인위적으로 만들어낸 설정보다 자연스러운 흐름과 복선을 좋아한다고 밝혔다.2021년 12월 1일, 민희진이 유 퀴즈 온 더 블럭에 출연해 HYBE에 입사한 2019년부터 너무 잘하는 프로듀서와 이미 타이틀 곡을 준비해놨다고 하고, \"분명히 굉장히 새로운 반향을 불러일으키지 않을까 심히 기대하고 있다\"라고 말하며 2022년에 데뷔 시킬 것이라고 밝혔다.[52]민희진 대표는 멤버들 부모님들과 나이가 비슷해서 너무 신기했고, 좋은 이모가 되고 싶고 좋은 엄마가 돼주고 싶다며 한 명씩 주말마다 집에 불러서 요리도 해주고 산책도 하며 친해지는 시간을 가졌으며, 멤버들이 자연스럽게 아티스트가 되는 과정을 만들어주고 싶었다고 한다.멤버들이 미숙한데 진짜 노력을 많이 해서 막 병아리 같고 예뻐보였다고 한다. 그래서 \\'즐겁게 해보자, 그러면 굉장히 다른 바이브가 나올거다\\'라고 말했다고 한다.2022년 1월 7일, 다른 인물을 통해 New Jeans라는 상표가 우회 등록되었다.2022년 3월 11일, 민희진은 미국의 세계적인 엔터테인먼트 전문 매체 \\'버라이어티\\'에서 글로벌 엔터테인먼트 업계에 영향을 미친 여성 리스트에 선정되었으며, 소감으로 \"감사하다. 어도어 신규 걸그룹 기획·제작에 올인(All-in)하고 있다. 올해 3분기, 전 세계 팬들에게 새로운 취향과 화두를 제시할 수 있는 차별화된 걸그룹을 선보이겠다.\"라고 포부를 밝히면서 2022년 3분기에 ADOR의 첫 번째 걸그룹 데뷔가 확정되었다.2022년 7월 1일, 3분기가 시작되자마자 ADOR 걸그룹 관련 자료가 공식 인스타그램에 올라왔고 7월 22일에 ADOR 걸그룹 첫 콘텐츠 공개를 예고했다.민희진의 집에서 청음회를 했는데 뉴진스 멤버들과 ADOR 구성원들은 너무 좋아했지만, HYBE 내부에서는 \\'밋밋하다\\', \\'대중성 없는 스타일\\' 등 기존의 K-POP 아이돌 문법이 아니라서 히트가 어려울 것이라는 의견도 꽤 있었다고 한다. 이런 반응에 불안하지 않았던 건 아니지만[53], 자신감이 있었기 때문에 크게 개의치 않았다고 한다. 뉴진스의 보컬, 안무에 대한 지향점은 자연스러움을 최대로 표현하는 것과[54] 기존 방식에서 탈피한 의외성에 있다고 밝혔다. 데뷔 전부터 이미 다음 음반을 구상하고 있으며, 아주 엉뚱한 앨범이 될 것이라고 한다.10.2. 브랜드 평판[편집]월걸그룹 브랜드 순위가수 브랜드 순위2022년8월12위8위9월6위5위10월5위6위11월2위5위12월1위3위2023년1월1위1위2월1위1위3월1위2위4월2위1위5월3위5위6월3위3위7월1위3위8월1위1위9월1위2위10월1위4위11월1위1위12월2위2위2024년1월2위9위2월7위11위3월5위13위4월7위23위5월20위30위6월23위90위7월21위 조사 대상 제외8월25위48위9월34위50위브랜드평판 순위11. 논란 및 사건 사고[편집] \\xa0 자세한 내용은 NewJeans/논란 및 사건 사고 문서를의 번 문단을의  부분을 참고하십시오.12. 역대 프로필 사진[편집]New JeansDittoOMGGet UpNJWMXHow SweetSupernatural[1] 데뷔 앨범 발매일이나 음악방송 첫 출연 일자가 아닌 \\'Attention\\' 뮤직비디오 공개일을 정식 데뷔일로 기념하고 있다.[2] [3] New Jeans, New Genes. 2019년에 민희진이 플러스 글로벌 오디션을 기획할 때부터 5명 멤버로 미리 정해둔 것처럼 NewJeans 팀명도 미리 확정되어 있었다고 한다. #[4] 민희진의 \\'진\\'이 아니라고 밝혔다. #[5] 그 중에서도 팝이나 R&B 스타일에서 두각을 나타낸다.[6] 본인들의 안무는 물론 멤버들이 타 아이돌의 안무나 틱톡 춤을 춘 영상들에서도 이 점이 잘 드러난다.[7] 참고로 하니의 경우 성인이 되어서도 0.3cm가 더 성장했다.[8] 온 세상이 뉴진스의 줄임말.[9] 틀:한국갤럽 선정 올해를 빛낸 가수 1위 참고.[10] 틀:올해를 빛낸 가수 · 노래 1위 참고.[11] 소녀시대, aespa, BTS, EXO, 태양 정도만 한국대중음악상에서 K-POP 부문을 제외하고 수상을 했을 정도로 아이돌의 대중성과 인지도보다는 음악적인 완성도를 중점적으로 놓고 보는 곳이다.[12] 이 두개의 상은 전부 뉴진스의 작곡가인 250에게 돌아갔다.[13] 1997년 S.E.S. 이후 약 25년만에 서바이벌 프로그램 출신 멤버가 한 명도 없는 걸그룹이 데뷔 초동 1위를 달성했다.[14] 종전 기록은 소녀시대의 Gee[15] 단순히 일간 차트로만 쳐도 1, 2, 3위를 전부 석권한 걸그룹은 2NE1이 마지막이다.[16] 최초로 주간차트 10위권에 4곡을 진입시킨 그룹은 2NE1이며, 공교롭게도 똑같이 1, 2, 3, 7위를 차지했다. (2010년 9월 12일~ 9월 18일자 기록. Can\\'t Nobody, Go Away, 박수쳐, 아파(Slow)[17] 이는 당시 K-pop 역사상 데뷔 후 최단 빌보드 Hot 100 차트 입성 기록이었으나 이후 FIFTY FIFTY의 싱글 1집 The Beginning: Cupid가 데뷔 130일 만에 빌보드 Hot 100 차트에 입성하며 깨졌다.[18] BoF 500에는 매년 전세계의 경영자, 언론인, 셀러브리티, 모델 등을 대상으로 빅데이터를 조사하고 분석하여 패션계에서 가장 영향력 있는 500인이 선정된다. 2023년에 선정된 한국인으로는 뉴진스 외에 그룹 방탄소년단, 롯데쇼핑 CEO 정준호, 보그 코리아 편집장 신광호가 있다.[19] 한국 여성 아티스트로는 CL(2016), 페기 구(2019), BLACKPINK(2022)에 이어 역대 네번째로 BoF 500에 선정되었다.[20] 이전 기록은 2005년의 SG워너비, 2008년과 2015년의 빅뱅, 2009년의 2NE1, 2012년의 버스커버스커, 2014년과 2021년의 아이유가 기록한 3곡이었다.[21] 뉴진스의 빌보드 HOT 100 첫 진입 곡. 96위로 진입 후 순위가 상승했다.[22] 91위로 진입 후 순위가 상승했다.[23] 커리어 하이[24] BLACKPINK의 THE ALBUM과 타이 기록[25] 161위로 진입 후, 순위가 상승했다.[26] FIFTY FIFTY와 공동 최장기간[27] 뉴진스는 인기에 비해 뮤직비디오 조회수가 적다고 느낄 수 있는데, 이는 버전별로 나눠진 뮤비가 많고, 스토리텔링 주를 이루는 뮤비도 많으며(이런 경우 보통 퍼포먼스 비디오의 조회수가 더 많다.) 대다수의 타 아이돌과 달리 광고로 뮤직비디오를 송출하는 등 뮤직비디오 프로모션을 돌리지 않은 결과이다. 또한 유튜브 음원 조회수가 독보적으로 많다.[28] 네 번째 1억뷰 달성[29] 첫 1억 뷰 달성[30] 두 번째 1억뷰 달성, 첫 번째 2억뷰 달성[31] 세 번째 1억뷰 달성, 두 번째 2억뷰 달성[32] 민지: 18세, 하니/다니엘: 17세, 해린: 16세, 혜인: 14세[33] APRIL및 YOUNG POSSE보다 낮은 평균 연령으로 로틴/차이돌 근접 연령권 아이돌중 하나에 해당했다.[34] 또한 혜인은 로틴/차이돌 유쏘걸 (U.SSO Girls) 활동을 한 바 있다. 혜인/데뷔 전 활동의 3번 항목참조.[35] 한국 걸그룹인데 굳이 \\'모든 멤버가 한국어와 영어를 할 수 있다\\'고 했으므로 외국인 멤버가 포함되어 있는 다국적 걸그룹으로 추정되었고, 실제로 호주-베트남의 이중국적인 하니, 호주-한국의 이중국적인 다니엘이 공개되었다.[36] 혜인: 170cm, 민지: 169cm, 다니엘: 165cm, 해린: 164.5cm, 하니: 162cm[37] 민지, 하니, 해린: 여동생 / 다니엘, 혜인: 언니[38] 민지는 오빠와 여동생이 있고, 하니와 해린은 여동생, 다니엘은 언니, 혜인은 언니와 오빠가 있다.[39] 다니엘, 혜인: 4월 / 민지, 해린: 5월[40] 하니는 10월생으로 유일하게 하반기에 태어났다.[41] A형: 민지, B형: 해린, AB형: 다니엘, O형: 하니, 혜인[42] 민지 : 강원특별자치도 춘천시 (경춘선), 해린 : 경기도 안양시 (1호선, 4호선), 다니엘 : 경기도 파주시 (경의·중앙선, GTX-A), 혜인 : 인천광역시 미추홀구 (1호선, 수인·분당선)[43] 수도권 전철이 운행하는 지역들이라고 기술한 이유는 민지가 비수도권인 강원도 춘천 출신이기 때문이다.[44] 이는 혜인의 아이디어였다고 한다.[45] 티저의 본래 역할은 궁금증 유발인데, 어느 순간부터 관성처럼 느껴져 필요성을 느끼지 못했다고 한다.[46] 뉴진스의 곡들이 기존 K팝 아이돌 음악 스타일이 아니기 때문에 더욱이 좋은 곡이라 하더라도 학습의 시간이 필요할 것이라 생각했다고 한다.[47] 당시 혜인은 만 15세.[48] 너의 시간 속으로의 OST인 <아름다운 구속>은 김종서, 마이데몬의 OST인 <우리의 밤은 당신의 낮보다 아름답다>는 코나의 노래를 리메이크한 것. 원곡 모두 1996년에 발매되었다는 공통점도 있다.[49] 자세한 내용은 이 영상의 민희진 쏘스 걸그룹 런칭 참여하기로 함으로 시작하는 댓글 참조.[50] 일부는 틀린 정보일 수 있지만 이미 민희진이 다 말한 내용들이다.[51] 밑의 영상은 민지를 포함한 다른 멤버들을 모집하는 오디션 영상이고 나머지 1개인 더 걸 1 영상을 봐도 민지로 추정되는 인물만 나온다.[52] 엔터업계에 일하면서 \"이건 될 거다라고 생각해서 했는데 안 된 경우는 한 번도 없었다!\"라고 자신있게 말했다.[53] 민희진은 \"정말 이해 못하려나\"라며 걱정도 했지만 생각대로 밀어붙이니 결국 좋은 성과를 이뤘다.[54] 그래서 신곡의 보컬 가이드를 안 받는다고 밝혔다. 일단 가이드를 받으면 따라 부르기가 쉽지만, 영향을 받을 수밖에 없기 때문에 완전히 멤버들의 자연스러운 스타일로 녹음하기 위해 가이드를 일절 안 받는다고 한다.이 저작물은 CC BY-NC-SA 2.0 KR에 따라 이용할 수 있습니다. (단, 라이선스가 명시된 일부 문서 및 삽화 제외)기여하신 문서의 저작권은 각 기여자에게 있으며, 각 기여자는 기여하신 부분의 저작권을 갖습니다.나무위키는 백과사전이 아니며 검증되지 않았거나, 편향적이거나, 잘못된 서술이 있을 수 있습니다.나무위키는 위키위키입니다. 여러분이 직접 문서를 고칠 수 있으며, 다른 사람의 의견을 원할 경우 직접 토론을 발제할 수 있습니다. \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0  \\xa0 더 보기namu.wikiContáctenosTérminos de usoOperado por umanle S.R.L.Hecho con ❤️ en Asunción, República del Paraguay Su zona horaria es GMTImpulsado por the seed engine This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. This site is protected by hCaptcha and its Privacy Policy and Terms of Service apply. ')]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWvAD5WJ0vhR",
        "outputId": "deab9b70-cf0c-4d96-94a9-bc91bda75246"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pdf"
      ],
      "metadata": {
        "id": "aaAiKqqo0Ca_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 설치(다양함)\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clwEjzxk0Do3",
        "outputId": "98f6454c-cb2b-426c-d66f-6e35e5062a4c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Downloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n",
            "   ---------------------------------------- 0.0/294.5 kB ? eta -:--:--\n",
            "   -------- ------------------------------- 61.4/294.5 kB 1.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 294.5/294.5 kB 4.5 MB/s eta 0:00:00\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-5.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader('./소나기.pdf')\n",
        "document = loader.load()\n",
        "document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nxUzgcH0PEv",
        "outputId": "fac64630-c98f-4a07-8bc9-594bca4e45e0"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './소나기.pdf', 'page': 0}, page_content='- 1 -소나기\\n황순원\\n소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀 (曾孫女 )딸이라는 걸 알 수 있었다 . \\n소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다 . 서울서는 이런 개울물을 보지 \\n못하기나 한 듯이.\\n벌써 며칠째 소녀는 , 학교에서 돌아오는 길에 물장난이었다 . 그런데 , 어제까지 개울 기슭에\\n서 하더니 , 오늘은 징검다리 한가운데 앉아서 하고 있다.\\n소년은 개울둑에 앉아 버렸다 . 소녀가 비키기를 기다리자는 것이다 .\\n요행 지나가는 사람이 있어, 소녀가 길을 비켜 주었다 .\\n다음 날은 좀 늦게 개울가로 나왔다 .\\n이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다 . 분홍 스웨터 소매를 걷어올\\n린 목덜미가 마냥 희었다 .\\n한참 세수를 하고 나더니 , 이번에는 물 속을 빤히 들여다 본다. 얼굴이라도 비추어 보는 \\n것이리라 . 갑자기 물을 움켜 낸다. 고기 새끼라도 지나가는 듯.\\n소녀는 소년이 개울둑에 앉아 있는 걸 아는지 모르는지 그냥 날쌔게 물만 움켜 낸다. 그러\\n나, 번번이 허탕이다 . 그대로 재미있는 양, 자꾸 물만 움킨다 . 어제처럼 개울을 건너는 사\\n람이 있어야 길을 비킬 모양이다 .\\n그러다가 소녀가 물 속에서 무엇을 하나 집어 낸다. 하얀 조약돌이었다 . 그리고는 벌떡 일\\n어나 팔짝팔짝 징검다리를 뛰어 건너간다 .\\n다 건너가더니만 홱 이리로 돌아서며 ,\\n“이 바보.”\\n조약돌이 날아왔다 .\\n소년은 저도 모르게 벌떡 일어섰다 .\\n단발 머리를 나풀거리며 소녀가 막 달린다 . 갈밭 사잇길로 들어섰다 . 뒤에는 청량한 가을 \\n햇살 아래 빛나는 갈꽃뿐 .\\n이제 저쯤 갈밭머리로 소녀가 나타나리라 . 꽤 오랜 시간이 지났다고 생각됐다 . 그런데도 \\n소녀는 나타나지 않는다 . 발돋움을 했다. 그러고도 상당한 시간이 지났다고 생각됐다 .\\n저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다 . 소녀가 갈꽃을 안고 있었다 . 그리고 , 이제는 \\n천천한 걸음이었다 . 유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다 . 소녀 아닌 \\n갈꽃이 들길을 걸어가는 것만 같았다 .\\n소년은 이 갈꽃이 아주 뵈지 않게 되기까지 그대로 서 있었다 . 문득, 소녀가 던지 조약돌\\n을 내려다보았다 . 물기가 걷혀 있었다 . 소년은 조약돌을 집어 주머니에 넣었다 .\\n다음 날부터 좀더 늦게 개울가로 나왔다 . 소녀의 그림자가 뵈지 않았다 . 다행이었다 .\\n그러나 , 이상한 일이었다 . 소녀의 그림자가 뵈지 않는 날이 계속될수록 소년의 가슴 한 구\\n석에는 어딘가 허전함이 자리 잡는 것이었다 . 주머니 속 조약돌을 주무르는 버릇이 생겼\\n다.\\n그러한 어떤 날, 소년은 전에 소녀가 앉아 물장난을 하던 징검다리 한가운데에 앉아 보았\\n다. 물 속에 손을 잠갔다 . 세수를 하였다 . 물 속을 들여다보았다 . 검게 탄 얼굴이 그대로 \\n비치었다 . 싫었다 .'),\n",
              " Document(metadata={'source': './소나기.pdf', 'page': 1}, page_content='- 2 -소년은 두 손으로 물 속의 얼굴을 움키었다 . 몇 번이고 움키었다 . 그러다가 깜짝 놀라 일\\n어나고 말았다 . 소녀가 이리로 건너오고 있지 않느냐 .\\n‘숨어서 내가 하는 일을 엿보고 있었구나 .’ 소년은 달리기를 시작했다 . 디딤돌을 헛디뎠다 . \\n한 발이 물 속에 빠졌다 . 더 달렸다 .\\n몸을 가릴 데가 있어 줬으면 좋겠다 . 이 쪽 길에는 갈밭도 없다. 메밀밭이다 . 전에 없이 메\\n밀꽃 냄새가 짜릿하게 코를 찌른다고 생각됐다 . 미간이 아찔했다 . 찝찔한 액체가 입술에 \\n흘러들었다 . 코피였다 .\\n소년은 한 손으로 코피를 훔쳐내면서 그냥 달렸다 . 어디선가 ‘바보, 바보’ 하는 소리가 자\\n꾸만 뒤따라오는 것 같았다 .\\n토요일이었다 .\\n개울가에 이르니 , 며칠째 보이지 않던 소녀가 건너편 가에 앉아 물장난을 하고 있었다 . 모\\n르는 체 징검다리를 건너기 시작했다 . 얼마 전에 소녀 앞에서 한 번 실수를 했을 뿐, 여태 \\n큰길 가듯이 건너던 징검다리를 오늘은 조심스럽게 건넌다 .\\n“얘.”\\n못 들은 체했다 . 둑 위로 올라섰다 .\\n“얘, 이게 무슨 조개지 ?”\\n자기도 모르게 돌아섰다 . 소녀의 맑고 검은 눈과 마주쳤다 . 얼른 소녀의 손바닥으로 눈을 \\n떨구었다 .\\n“비단조개 .”\\n“이름도 참 곱다.”\\n갈림길에 왔다. 여기서 소녀는 아래편으로 한 삼 마장쯤 , 소년은 우대로 한 십 리 가까운 \\n길을 가야 한다.\\n소녀가 걸음을 멈추며 ,\\n“너, 저 산 너머에 가 본 일 있니?”\\n벌 끝을 가리켰다 .\\n“없다.”\\n“우리, 가 보지 않으련 ? 시골 오니까 혼자서 심심해 못 견디겠다 .”\\n“저래 봬도 멀다.”\\n“멀면 얼마나 멀기에 ? 서울 있을 땐 사뭇 먼 데까지 소풍 갔었다 .”\\n소녀의 눈이 금새 ‘바보,바보,’할 것만 같았다 .\\n논 사잇길로 들어섰다 . 벼 가을걷이하는 곁을 지났다 .\\n허수아비가 서 있었다 . 소년이 새끼줄을 흔들었다 . 참새가 몇 마리 날아간다 . ‘참, 오늘은 \\n일찍 집으로 돌아가 텃논의 참새를 봐야 할걸.’ 하는 생각이 든다.\\n“야, 재밌다 !”\\n소녀가 허수아비 줄을 잡더니 흔들어 댄다. 허수아비가 자꾸 우쭐거리며 춤을 춘다. 소녀\\n의 왼쪽 볼에 살포시 보조개가 패었다 .\\n저만큼 허수아비가 또 서 있다. 소녀가 그리로 달려간다 . 그 뒤를 소년도 달렸다 . 오늘 같\\n은 날은 일찍 집으로 돌아가 집안일을 도와야 한다는 생각을 잊어버리기라도 하려는 듯이.\\n소녀의 곁을 스쳐 그냥 달린다 . 메뚜기가 따끔따끔 얼굴에 와 부딪친다 . 쪽빛으로 한껏 갠 가을 \\n하늘이 소년의 눈앞에서 맴을 돈다. 어지럽다 . 저놈의 독수리 , 저놈의 독수리 , 저놈의 독수리가 \\n맴을 돌고 있기 때문이다 .'),\n",
              " Document(metadata={'source': './소나기.pdf', 'page': 2}, page_content='- 3 -돌아다보니 , 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다. 좀 전 허수아비보다 \\n더 우쭐거린다 .\\n논이 끝난 곳에 도랑이 하나 있었다 . 소녀가 먼저 뛰어 건넜다 .\\n거기서부터 산 밑까지는 밭이었다 .\\n수숫단을 세워 놓은 밭머리를 지났다 .\\n“저게 뭐니?”\\n“원두막 .”\\n“여기 참외, 맛있니 ?”\\n“그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.”\\n“하나 먹어 봤으면 .”\\n소년이 참외 그루에 심은 무우밭으로 들어가 , 무우 두 밑을 뽑아 왔다. 아직 밑이 덜 들어 \\n있었다 . 잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다 . 그리고는 이렇게 먹어야 한다는 듯\\n이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다 .\\n소녀도 따라 했다. 그러나 , 세 입도 못 먹고,\\n“아, 맵고 지려.”\\n하며 집어던지고 만다.\\n“참, 맛 없어 못 먹겠다 .”\\n소년이 더 멀리 팽개쳐 버렸다 .\\n산이 가까워졌다 .\\n단풍이 눈에 따가웠다 .\\n“야아!”\\n소녀가 산을 향해 달려갔다 . 이번은 소년이 뒤따라 달리지 않았다 . 그러고도 곧 소녀보다 \\n더 많은 꽃을 꺾었다 .\\n“이게 들국화 , 이게 싸리꽃 , 이게 도라지꽃 ,…….”\\n“도라지꽃이 이렇게 예쁜 줄은 몰랐네 . 난 보랏빛이 좋아!…… 그런데 , 이 양산 같이 생긴 \\n노란 꽃이 뭐지?”\\n“마타리꽃 .”\\n소녀는 마타리꽃을 양산 받듯이 해 보인다 . 약간 상기된 얼굴에 살포시 보조개를 떠올리\\n며.\\n다시 소년은 꽃 한 옴큼을 꺾어 왔다. 싱싱한 꽃가지만 골라 소녀에게 건넨다 .\\n그러나 소녀는\\n“하나도 버리지 마라.”\\n산마루께로 올라갔다 .\\n맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다 .\\n누가 말할 것도 아닌데 , 바위에 나란히 걸터앉았다 . 유달리 주위가 조용해진 것 같았다 . 따\\n가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다 .\\n“저건 또 무슨 꽃이지 ?”\\n적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다 .\\n“꼭 등꽃 같네. 서울 우리 학교에 큰 등나무가 있었단다 . 저 꽃을 보니까 등나무 밑에서 \\n놀던 동무들 생각이 난다.”\\n소녀가 조용히 일어나 비탈진 곳으로 간다. 꽃송이가 많이 달린 줄기를 잡고 끊기 시작한'),\n",
              " Document(metadata={'source': './소나기.pdf', 'page': 3}, page_content='- 4 -다. 좀처럼 끊어지지 않는다 . 안간힘을 쓰다가 그만 미끄러지고 만다. 칡덩굴을 그러쥐었\\n다.\\n소년이 놀라 달려갔다 . 소녀가 손을 내밀었다 . 손을 잡아 이끌어 올리며 , 소년은 제가 꺾어\\n다 줄 것을 잘못했다고 뉘우친다 . 소녀의 오른쪽 무릎에 핏방울이 내맺혔다 . 소년은 저도 \\n모르게 생채기에 입술을 가져다 대고 빨기 시작했다 . 그러다가 , 무슨 생각을 했는지 홱 일\\n어나 저 쪽으로 달려간다 .\\n좀 만에 숨이 차 돌아온 소년은\\n“이걸 바르면 낫는다 .”\\n송진을 생채기에다 문질러 바르고는 그 달음으로 칡덩굴 있는 데로 내려가 , 꽃 많이 달린 \\n몇 줄기를 이빨로 끊어 가지고 올라온다 . 그리고는 ,\\n“저기 송아지가 있다. 그리 가 보자.”\\n누렁송아지였다 . 아직 코뚜레도 꿰지 않았다 .\\n소년이 고삐를 바투 잡아 쥐고 등을 긁어 주는 체 훌쩍 올라탔다 . 송아지가 껑충거리며 돌\\n아간다 .\\n소녀의 흰 얼굴이 , 분홍 스웨터가 , 남색 스커트가 , 안고 있는 꽃과 함께 범벅이 된다. 모두\\n가 하나의 큰 꽃묶음 같다. 어지럽다 . 그러나 , 내리지 않으리라 . 자랑스러웠다 . 이것만은 \\n소녀가 흉내 내지 못할, 자기 혼자만이 할 수 있는 일인 것이다 .\\n“너희, 예서 뭣들 하느냐 ?”\\n농부(農夫)하나가 억새풀 사이로 올라왔다 .\\n송아지 등에서 뛰어내렸다 . 어린 송아지를 타서 허리가 상하면 어쩌느냐고 꾸지람을 들을 \\n것만 같다.\\n그런데 , 나룻이 긴 농부는 소녀 편을 한 번 훑어보고는 그저 송아지 고삐를 풀어 내면서 ,\\n“어서들 집으로 가거라 . 소나기가 올라.”\\n참, 먹장구름 한 장이 머리 위에 와 있다. 갑자기 사면이 소란스러워진 것 같다. 바람이 우\\n수수 소리를 내며 지나간다 . 삽시간에 주위가 보랏빛으로 변했다 .\\n산을 내려오는데 , 떡갈나무 잎에서 빗방울 듣는 소리가 난다. 굵은 빗방울이었다 . 목덜미가 \\n선뜻선뜻했다 . 그러자 , 대번에 눈앞을 가로막는 빗줄기 .\\n비안개 속에 원두막이 보였다 . 그리로 가 비를 그을 수밖에 .\\n그러나 , 원두막은 기둥이 기울고 지붕도 갈래갈래 찢어져 있었다 . 그런 대로 비가 덜 새는 \\n곳을 가려 소녀를 들어서게 했다.\\n소녀의 입술이 파아랗게 질렸다 . 어깨를 자꾸 떨었다 .\\n무명 겹저고리를 벗어 소녀의 어깨를 싸 주었다 . 소녀는 비에 젖은 눈을 들어 한 번 쳐다\\n보았을 뿐, 소년이 하는 대로 잠자코 있었다 . 그리고는 , 안고 온 꽃묶음 속에서 가지가 꺾\\n이고 꽃이 일그러진 송이를 골라 발 밑에 버린다 . 소녀가 들어선 곳도 비가 새기 시작했\\n다. 더 거기서 비를 그을 수 없었다 .\\n밖을 내다보던 소년이 무엇을 생각했는지 수수밭 쪽으로 달려간다 . 세워 놓은 수숫단 속을 \\n비집어 보더니 , 옆의 수숫단을 날라다 덧세운다 . 다시 속을 비집어 본다. 그리고는 이쪽을 \\n향해 손짓을 한다.\\n수숫단 속은 비는 안 새었다 . 그저 어둡고 좁은 게 안 됐다. 앞에 나앉은 소년은 그냥 비\\n를 맞아야만 했다. 그런 소년의 어깨에서 김이 올랐다 .\\n소녀가 속삭이듯이 , 이리 들어와 앉으라고 했다. 괜찮다고 했다. 소녀가 다시, 들어와 앉으'),\n",
              " Document(metadata={'source': './소나기.pdf', 'page': 4}, page_content='- 5 -라고 했다. 할 수 없이 뒷걸음질을 쳤다. 그 바람에 , 소녀가 안고 있는 꽃묶음이 망그러졌\\n다. 그러나 , 소녀는 상관없다고 생각했다 . 비에 젖은 소년의 몸 내음새가 확 코에 끼얹혀졌\\n다. 그러나 , 고개를 돌리지 않았다 . 도리어 소년의 몸기운으로 해서 떨리던 몸이 적이 누그\\n러지는 느낌이었다 .\\n소란하던 수숫잎 소리가 뚝 그쳤다 . 밖이 멀개졌다 .\\n수숫단 속을 벗어 나왔다 . 멀지 않은 앞쪽에 햇빛이 눈부시게 내리붓고 있었다 . 도랑 있는 \\n곳까지 와 보니, 엄청나게 물이 불어 있었다 . 빛마저 제법 붉은 흙탕물이었다 . 뛰어 건널 \\n수가 없었다 .\\n소년이 등을 돌려 댔다. 소녀가 순순히 업히었다 . 걷어올린 소년의 잠방이까지 물이 올라\\n왔다. 소녀는 ‘어머나 ’소리를 지르며 소년의 목을 끌어안았다 .\\n개울가에 다다르기 전에, 가을 하늘이 언제 그랬는가 싶게 구름 한 점 없이 쪽빛으로 개어 \\n있었다 .\\n그 뒤로 소녀의 모습은 뵈지 않았다 . 매일같이 개울가로 달려와 봐도 뵈지 않았다 .\\n학교에서 쉬는 시간에 운동장을 살피기도 했다. 남 몰래 5학년 여자 반을 엿보기도 했다. \\n그러나 , 뵈지 않았다 .\\n그날도 소년은 주머니 속 흰 조약돌만 만지작거리며 개울가로 나왔다 . 그랬더니 , 이 쪽 개\\n울둑에 소녀가 앉아 있는 게 아닌가 .\\n소년은 가슴부터 두근거렸다 .\\n“그 동안 앓았다 .”\\n어쩐지 소녀의 얼굴이 해쓱해져 있었다 .\\n“그 날, 소나기 맞은 탓 아냐?”\\n소녀가 가만히 고개를 끄덕이었다 .\\n“인제 다 났냐?”\\n“아직도 …….”\\n“그럼, 누워 있어야지 .”\\n“하도 갑갑해서 나왔다 . ……참, 그 날 재밌었어 ……. 그런데그 날 어디서 이런 물이 들었\\n는지 잘 지지 않는다 .”\\n소녀가 분홍 스웨터 앞자락을 내려다본다 . 거기에 검붉은 진흙물 같은 게 들어 있었다 .\\n소녀가 가만히 보조개를 떠올리며 ,\\n“그래 이게 무슨 물 같니?”\\n소년은 스웨터 앞자락만 바라보고 있었다 .\\n“내, 생각해 냈다. 그 날, 도랑을 건너면서 내가 업힌 일이 있지? 그 때, 네 등에서 옮은 \\n물이다 .”\\n소년은 얼굴이 확 달아오름을 느꼈다 .\\n갈림길에서 소녀는\\n“저, 오늘 아침에 우리 집에서 대추를 땄다. 낼 제사 지내려고 …….”\\n대추 한 줌을 내준다 . 소년은 주춤한다 .\\n“맛봐라 . 우리 증조(曾祖)할아버지가 심었다는데 , 아주 달다.”\\n소년은 두 손을 오그려 내밀며 ,\\n“참, 알도 굵다!”\\n“그리고 저, 우리 이번에 제사 지내고 나서 좀 있다. 집을 내주게 됐다.”'),\n",
              " Document(metadata={'source': './소나기.pdf', 'page': 5}, page_content='- 6 -소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서 , 윤 초시 손자(孫子)가 \\n서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다 . 그\\n것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다 .\\n“왜 그런지 난 이사 가는 게 싫어졌다 . 어른들이 하는 일이니 어쩔 수 없지만 …….”\\n전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다 .\\n소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로 , 소녀가 이사를 간다는 말을 수없이 되\\n뇌어 보았다 . 무어 그리 안타까울 것도 서러울 것도 없었다 . 그렇건만 , 소년은 지금 자기가 \\n씹고 있는 대추알의 단맛을 모르고 있었다 .\\n이 날 밤, 소년은 몰래 덕쇠 할아버지네 호두밭으로 갔다.\\n낯에 봐 두었던 나무로 올라갔다 . 그리고 , 봐 두었던 가지를 향해 작대기를 내리쳤다 . 호두\\n송이 떨어지는 소리가 별나게 크게 들렸다 . 가슴이 선뜩했다 . 그러나 다음 순간, 굵은 호두\\n야 많이 떨어져라 , 많이 떨어져라 , 저도 모를 힘에 이끌려 마구 작대기를 내리 치는 것이\\n었다.\\n돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다 . 그늘의 고마움을 처음 느꼈다 .\\n불룩한 주머니를 어루만졌다 . 호두송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아\\n무렇지도 않았다 . 그저 근동에서 제일 가는 이 덕쇠 할아버지네 호두를 어서 소녀에게 맛보여야 \\n한다는 생각만이 앞섰다 .\\n그러다 , 아차 하는 생각이 들었다 . 소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울\\n가로 나와 달라는 말을 못해 둔 것이었다 . 바보 같은것 , 바보 같은것 .\\n이튿날 , 소년이 학교에서 돌아오니 , 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 \\n있었다 .\\n어디 가시느냐고 물었다 .\\n그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서 ,\\n“이만하면 될까?”\\n어머니가 망태기를 내주며 ,\\n“벌써 며칠째 ‘걀걀’하고 알 날 자리를 보던데요 . 크진 않아도살은 쪘을 거여요 .”\\n소년이 이번에는 어머니한테 아버지가 어디 가시느냐고 물어 보았다 .\\n“저, 서당골 윤 초시 댁에 가신다 . 제삿상에라도 놓으시라고 …….”\\n“그럼, 큰 놈으로 하나 가져가지 . 저 얼룩수탉으로 …….”\\n이 말에, 아버지는 허허 웃고 나서,\\n“임마, 그래도 이게 실속이 있다.”\\n소년은 공연히 열적어 , 책보를 집어던지고는 외양간으로가 , 쇠잔등을 한 번 철썩 갈겼다 . \\n쇠파리라도 잡는 체.\\n개울물은 날로 여물어 갔다.\\n소년은 갈림길에서 아래쪽으로 가 보았다 . 갈밭머리에서 바라보는 서당골 마을은 쪽빛 하\\n늘 아래 한결 가까워 보였다 .\\n어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다 . 거기 가서는 조그마한 \\n가겟방을 보게 되리라는 것이었다 .\\n소년은 저도 모르게 주머니 속 호두알을 만지작거리며 , 한 손으로는 수없이 갈꽃을 휘어 \\n꺾고 있었다 .\\n그 날 밤, 소년은 자리에 누워서도 같은 생각뿐이었다 . 내일 소녀네가 이사하는 걸 가 보'),\n",
              " Document(metadata={'source': './소나기.pdf', 'page': 6}, page_content='- 7 -나 어쩌나 . 가면 소녀를 보게 될까 어떨까 .\\n그러다가 까무룩 잠이 들었는가 하는데 ,\\n“허, 참 세상일도 …….”\\n마을 갔던 아버지가 언제 돌아왔는지 ,\\n“윤 초시 댁도 말이 아니야 , 그 많던 전답을 다 팔아 버리고 , 대대로 살아오던 집마저 남\\n의 손에 넘기더니 , 또 악상까지 당하는걸 보면…….”\\n남폿불 밑에서 바느질감을 안고 있던 어머니가 ,\\n“증손(曾孫)이라곤 계집애 그 애 하나뿐이었지요 ?”\\n“그렇지 , 사내 애 둘 있던 건 어려서 잃어버리고 …….”\\n“어쩌면 그렇게 자식복이 없을까 .”\\n“글쎄 말이지 . 이번 앤 꽤 여러 날 앓는 걸 약도 변변히 못써 봤다더군 . 지금 같아서 윤 \\n초시네도 대가 끊긴 셈이지 .……그런데참 , 이번 계집앤 어린 것이 여간 잔망스럽지가 않아. \\n글쎄, 죽기전에 이런 말을 했다지 않아? 자기가 죽거든 자기 입던 옷을 꼭그대로 입혀서 \\n묻어 달라고 …….”')]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWb_AS_m0gob",
        "outputId": "1aa0d40b-6679-4777-ff7f-e6e5ac62ba01"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vpx-b5g0PAe",
        "outputId": "b424bdc5-2b43-4175-94c3-f24713891dc3"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': './소나기.pdf', 'page': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## text"
      ],
      "metadata": {
        "id": "z1p1FhLy1A3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader('./서브웨이.txt', encoding='utf-8')\n",
        "document = loader.load()\n",
        "document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohNg75qC0O6H",
        "outputId": "65444952-3d6d-4174-cf76-75378631dd04"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './서브웨이.txt'}, page_content='▲서브웨이 에그마요 꿀조합\\n\\n-서브웨이 빵: 플랫 브래드\\n\\n-서브웨이 토핑: 베이컨 추가, 더블치즈, 야채 골고루\\n\\n-서브웨이 소스: 어니언+홀스래디쉬+스위트 칠리\\n\\n\\n▲서브웨이 참치 꿀조합\\n\\n-서브웨이 빵: 허니 오트\\n\\n-서브웨이 토핑: 슈레트 치즈, 야채 골고루\\n\\n-서브웨이 소스: 렌치+스위트 칠리\\n\\n\\n▲서브웨이 이탈리안 비엠티 꿀조합\\n\\n-서브웨이 빵: 허니오트\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채 골고루\\n\\n-서브웨이 소스: 스위트 어니언+렌치소스\\n\\n\\n▲서브웨이 치킨 데리야끼 꿀조합\\n\\n-서브웨이 빵: 플랫 브래드 또는 허니오트\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채 골고루\\n\\n-서브웨이 소스: 후추+렌치\\n\\n\\n▲서브웨이 미트볼 꿀조합\\n\\n-서브웨이 빵: 허니오트 또는 플랫브래드\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채는 양파, 피망, 올리브, 할라피뇨\\n\\n-서브웨이 소스: 렌치+후추\\n\\n\\n▲서브웨이 베지 꿀조합\\n\\n-서브웨이 빵: 위트\\n\\n-서브웨이 토핑: 야채 골고루\\n\\n-서브웨이 소스: 소금+후추+올리브 오일\\n\\n\\n▲서브웨이 스테이크 &\\u3000치즈 꿀조합\\n\\n-서브웨이 빵: 플랫브래드\\n\\n-서브웨이 토핑: 더블치즈, 야채 골고루\\n\\n-서브웨이 소스: 랜치+스위트 어니언+후추\\n\\n\\n▲서브웨이 이탈리안 BMT 꿀조합\\n\\n-서브웨이 빵: 플랫브래드\\n\\n-서브웨이 토핑: 더블치즈, 파마산오레가노, 올리브와 할라피뇨 많이\\n\\n-서브웨이 소스: 렌치+스위트 어니언\\n\\n\\n▲서브웨이 클럽 꿀조합\\n\\n-서브웨이 빵: 화이트\\n\\n-서브웨이 토핑: 야채 골고루\\n\\n-서브웨이 소스: 랜치+후추+허니 머스타드\\n\\n\\n▲서브웨이 다이어트, 서브웨이 메뉴 + 서브웨이 샐러드 TOP 3(사진=ⓒ픽사베이)\\n서브웨이 다이어트, 서브웨이 메뉴 + 서브웨이 샐러드 TOP 3\\n서브웨이 다이어트를 하는 사람이 많다. 이에 다이어트 음식으로 제격인 칼로리 낮은 서브웨이 메뉴와 서브웨이 샐러드를 추천하며, 서브웨이 칼로리도 소개한다.\\n\\n먼저, 서브웨이 다이어트로 제격인 서브웨이 메뉴를 추천한다. 서브웨이 15cm 기준으로, ▲참치 샌드위치/서브웨이 칼로리: 480 ▲미트볼 샌드위치/서브웨이 칼로리: 480 ▲햄 샌드위치/서브웨이 칼로리: 290 등이다.\\n\\n다음, 서브웨이 다이어트로 딱인 서브웨이 샐러드는 ▲쉬림프/서브웨이 칼로리: 108 ▲림프 아보카도/서브웨이 칼로리: 163 ▲서브웨이 베지/서브웨이 칼로리: 60 등이다.\\n\\n출처 : 공감신문(https://www.gokorea.kr)\\n\\n\\n서브웨이(써브웨이) 소스 종류 및 칼로리\\n미국에서 넘어온 샌드위치 전문 브랜드인 서브웨이는 국내에서도 많은 인기를 얻고 있습니다.\\n\\n\\n\\n\\n샌드위치 하나를 주문하기 위해 고객이 선택해야 될 것이 많아 조금 번거롭기는 하지만, 조합을 잘 한다면 (또는 이미 잘 많이 알려진 최적의 조합법으로 주문한다면) 정말 맛있는 샌드위치를 먹을 수 있습니다.\\n\\n고객이 선택해야 될 것중에는 빵이나 토핑도 있지만, 맛에 많은 영향을 주는 것중의 하나가 바로 소스입니다. 서브웨이에서 주문을 하면 소스는 가장 마지막에 선택하게 됩니다.\\n\\n보통 2개의 소스를 고르라고 안내하며, 1개의 소스만 선택해도 무방합니다. (설령 소스를 선택하지 않아도 되겠지만, 소스가 없다면 좀 밋밋하겠지요?)\\n\\n서브웨이 샌드위치 소스 종류\\n\\n여기서는 서브웨이에서 선택 가능한 소스의 종류와 각 소스가 가지고 있는 특징 밀 칼로리 정보를 안내해 드리겠습니다.\\n\\n \\n\\n1) 랜치 (Ranch)\\n\\n마요네즈와 레몬즙을 섞어 만든 소스\\n특징 : 고소함\\n칼로리 : 116 kcal\\n \\n\\n2) 스윗 어니언 (Sweet Onion)\\n\\n이름에서 알 수 있듯이 달콤한 양파 소스인데, 서브웨이의 특제 레시피로 만듦.\\n특징 : 달콤한 양파맛 (?)\\n칼로리 : 40.1 kcal\\n \\n\\n3) 사우스 웨스트 치폴레 (Southwest Chipotle)\\n\\n치폴레는 조미료로 일반적으로 할라피뇨 칠리 페퍼를 뜻함. 보통 미국 남서부나 멕시코 쪽 요리에 사용됨.\\n특징 : 매콤하면서도 고소한 마요네즈 맛(?)\\n칼로리 : 96.4 kcal\\n \\n\\n4) 스윗 칠리 (Sweet Chilli)\\n\\n칠리가 이름에 들어가 있는 것에서 알 수 있듯이 매콤한 칠리 고추에 달콤함이 더해진 맛.\\n특징 : 달콤하면서도 약간 매콤한 맛.\\n칼로리 : 40 kcal\\n \\n\\n5) 핫 칠리 (Hot Chilli)\\n\\n매운 칠리 고추…\\n특징: 매움. 맵찔이 주의!\\n칼로리 : 41.8 kcal\\n \\n\\n6) 스모크 바베큐 (Smoke BBQ)\\n\\n스모크 향이 나는 바베큐 맛이 달콤하게 어우러진 소스\\n특징 : 훈제 향이 느껴지는 달콤한 바베큐 맛\\n칼로리 : 32.8 kcal\\n \\n\\n7) 홀스래디쉬 (Horseradish)\\n\\n홀스래디쉬는 우리말로 겨자무(배추과의 식물). 서양 고추냉이라고 생각하면 되는데 보통 매운 향이 강함.\\n특징 : 고추냉이와 마요네즈가 섞여 고소하면서도 매운 맛? 매니아층이 있다고 하네요.\\n칼로리 : 106 kcal\\n8) 머스타드 (Yellow Mustard)\\n\\n이름에서 알 수 있듯이 겨자씨로 만든 오리지널 소스\\n특징 : 그 특유의 겨자 향과 맛. 호불호가 있지 않을까 하는 맛.\\n칼로리 : 15.3 kcal\\n \\n\\n9) 허니 머스타드 (Honey Mustard)\\n\\n머스타드에 달콤함을 더했다고 할까요?\\n특징 : 머스타드 + 달콤함.\\n칼로리 : 38.4 kcal\\n \\n\\n10) 올리브 오일 (Olive Oil)\\n\\n그냥 올리브 오일… 요즘은 올리브 오일을 접할 수 있는 기회가 많을 듯…\\n특징 : 담백하면서도 깔끔한 맛?\\n칼로리 : 124 kcal\\n \\n\\n11) 마요네즈 (Mayonnaise)\\n\\n설명이 필요 없겠지요? 바로 그 마요네즈입니다.\\n특징 : 마요네즈 맛… 약간 고소함…\\n칼로리 : 158 kcal\\n \\n\\n12) 레드 와인 식초 (Red Wine Vinaigrette)\\n\\n레드와인을 발효시켜 만든 식초라고 하네요. 비네그레트는 기름에 식초나 레몬 즙을 섞어 만든 소스입니다.\\n특징 : 식초 맛보다는 상큼한 맛! 칼로리 엄청 낮음!\\n칼로리 : 0.7 kcal\\n \\n\\n13) 소금 (Salt)\\n\\n그냥 소금\\n \\n\\n14) 후추 (Pepper)\\n\\n그냥 후추')]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNcYhMtx1G-D",
        "outputId": "99f5fdb4-45a3-4b52-b078-7226c99c676e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB2NsD7GcrVr"
      },
      "source": [
        "# Document Transformers 텍스트 쪼개기\n",
        "llm이 한꺼번에 읽을 수 없기 때문에 읽을 수 있는 단위로 쪼갠다   \n",
        "텍스트를 일정한 크기로 쪼갠다   \n",
        "**RecursiveCharacterTextSplitter()**  \n",
        "chunk_size : 최대 글자 수(이 수를 넘지 못함)  \n",
        "chunk_overlap : 중첩되는 문자 수\n",
        "\n",
        "**split_documents()**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ko0VKvbaTdLR"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "kXsyWUD6djEP"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200, # token 개수 혹은 문자 개수\n",
        "    chunk_overlap=40, # 문장 단위로 안잘리고 애매하게 잘리는 경우가 있어, 앞을 조금 더 참조 할 수 있게\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdjpmgy-d5tv",
        "outputId": "966c7028-4473-45b8-87f9-86dbf3026ab4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "type(texts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAoX5FiM1KkA",
        "outputId": "ffc13a55-cbd4-4f18-c3a9-ac156193e71e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-HCei2ud6qq",
        "outputId": "3d059e22-edda-4b4f-9090-780c8e5af5df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './서브웨이.txt'}, page_content='▲서브웨이 에그마요 꿀조합\\n\\n-서브웨이 빵: 플랫 브래드\\n\\n-서브웨이 토핑: 베이컨 추가, 더블치즈, 야채 골고루\\n\\n-서브웨이 소스: 어니언+홀스래디쉬+스위트 칠리\\n\\n\\n▲서브웨이 참치 꿀조합\\n\\n-서브웨이 빵: 허니 오트\\n\\n-서브웨이 토핑: 슈레트 치즈, 야채 골고루\\n\\n-서브웨이 소스: 렌치+스위트 칠리\\n\\n\\n▲서브웨이 이탈리안 비엠티 꿀조합'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='▲서브웨이 이탈리안 비엠티 꿀조합\\n\\n-서브웨이 빵: 허니오트\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채 골고루\\n\\n-서브웨이 소스: 스위트 어니언+렌치소스\\n\\n\\n▲서브웨이 치킨 데리야끼 꿀조합\\n\\n-서브웨이 빵: 플랫 브래드 또는 허니오트\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채 골고루\\n\\n-서브웨이 소스: 후추+렌치\\n\\n\\n▲서브웨이 미트볼 꿀조합'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='-서브웨이 소스: 후추+렌치\\n\\n\\n▲서브웨이 미트볼 꿀조합\\n\\n-서브웨이 빵: 허니오트 또는 플랫브래드\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채는 양파, 피망, 올리브, 할라피뇨\\n\\n-서브웨이 소스: 렌치+후추\\n\\n\\n▲서브웨이 베지 꿀조합\\n\\n-서브웨이 빵: 위트\\n\\n-서브웨이 토핑: 야채 골고루\\n\\n-서브웨이 소스: 소금+후추+올리브 오일'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='-서브웨이 소스: 소금+후추+올리브 오일\\n\\n\\n▲서브웨이 스테이크 &\\u3000치즈 꿀조합\\n\\n-서브웨이 빵: 플랫브래드\\n\\n-서브웨이 토핑: 더블치즈, 야채 골고루\\n\\n-서브웨이 소스: 랜치+스위트 어니언+후추\\n\\n\\n▲서브웨이 이탈리안 BMT 꿀조합\\n\\n-서브웨이 빵: 플랫브래드\\n\\n-서브웨이 토핑: 더블치즈, 파마산오레가노, 올리브와 할라피뇨 많이'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='-서브웨이 토핑: 더블치즈, 파마산오레가노, 올리브와 할라피뇨 많이\\n\\n-서브웨이 소스: 렌치+스위트 어니언\\n\\n\\n▲서브웨이 클럽 꿀조합\\n\\n-서브웨이 빵: 화이트\\n\\n-서브웨이 토핑: 야채 골고루\\n\\n-서브웨이 소스: 랜치+후추+허니 머스타드')]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "texts[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiXqjyvFBf76"
      },
      "source": [
        "# DB 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvjUac7VBhor",
        "outputId": "24fbd106-b258-41d7-d1f9-77b5cf6e4869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Using cached chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Using cached build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\nlp\\nlp\\lib\\site-packages (from chromadb) (2.8.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Using cached chroma_hnswlib-0.7.6-cp312-cp312-win_amd64.whl\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.30.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in c:\\nlp\\nlp\\lib\\site-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Using cached posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\nlp\\nlp\\lib\\site-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Using cached onnxruntime-1.18.1-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Using cached opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.20.0-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\nlp\\nlp\\lib\\site-packages (from chromadb) (4.66.5)\n",
            "Requirement already satisfied: overrides>=7.3.1 in c:\\nlp\\nlp\\lib\\site-packages (from chromadb) (7.7.0)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Downloading grpcio-1.65.4-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl.metadata (9.9 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb)\n",
            "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Using cached kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in c:\\nlp\\nlp\\lib\\site-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in c:\\nlp\\nlp\\lib\\site-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Using cached mmh3-4.1.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in c:\\nlp\\nlp\\lib\\site-packages (from chromadb) (3.10.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\nlp\\nlp\\lib\\site-packages (from chromadb) (0.27.0)\n",
            "Requirement already satisfied: packaging>=19.1 in c:\\nlp\\nlp\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Using cached pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: colorama in c:\\nlp\\nlp\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: anyio in c:\\nlp\\nlp\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.4.0)\n",
            "Requirement already satisfied: certifi in c:\\nlp\\nlp\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\nlp\\nlp\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\nlp\\nlp\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
            "Requirement already satisfied: sniffio in c:\\nlp\\nlp\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\nlp\\nlp\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\nlp\\nlp\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\nlp\\nlp\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading google_auth-2.33.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\nlp\\nlp\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in c:\\nlp\\nlp\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in c:\\nlp\\nlp\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.27.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting importlib-metadata<=8.0.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in c:\\nlp\\nlp\\lib\\site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (72.1.0)\n",
            "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\nlp\\nlp\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\nlp\\nlp\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
            "  Using cached huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb)\n",
            "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached httptools-0.6.1-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.23.0-cp312-none-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached websockets-12.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting zipp>=0.5 (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading zipp-3.20.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nlp\\nlp\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\nlp\\nlp\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.18.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
            "Using cached chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
            "Using cached bcrypt-4.2.0-cp39-abi3-win_amd64.whl (151 kB)\n",
            "Using cached build-1.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/93.1 kB ? eta -:--:--\n",
            "   ---- ----------------------------------- 10.2/93.1 kB ? eta -:--:--\n",
            "   ---- ----------------------------------- 10.2/93.1 kB ? eta -:--:--\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   ------------- -------------------------- 30.7/93.1 kB 217.9 kB/s eta 0:00:01\n",
            "   -------------------------- ------------- 61.4/93.1 kB 86.2 kB/s eta 0:00:01\n",
            "   -------------------------- ------------- 61.4/93.1 kB 86.2 kB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 81.9/93.1 kB 99.7 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 93.1/93.1 kB 108.2 kB/s eta 0:00:00\n",
            "Downloading grpcio-1.65.4-cp312-cp312-win_amd64.whl (4.1 MB)\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "   ---------------------------------------- 0.0/4.1 MB 22.3 kB/s eta 0:03:04\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 27.1 kB/s eta 0:02:31\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 23.4 kB/s eta 0:02:54\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "    --------------------------------------- 0.1/4.1 MB 20.9 kB/s eta 0:03:14\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 22.2 kB/s eta 0:03:01\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 19.0 kB/s eta 0:03:31\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.1/4.1 MB 18.6 kB/s eta 0:03:35\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 17.6 kB/s eta 0:03:45\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.5 kB/s eta 0:04:16\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 15.3 kB/s eta 0:04:17\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   - -------------------------------------- 0.2/4.1 MB 14.1 kB/s eta 0:04:39\n",
            "   -- ------------------------------------- 0.2/4.1 MB 11.4 kB/s eta 0:05:44\n",
            "   -- ------------------------------------- 0.2/4.1 MB 11.4 kB/s eta 0:05:44\n",
            "   -- ------------------------------------- 0.2/4.1 MB 11.4 kB/s eta 0:05:44\n",
            "   -- ------------------------------------- 0.2/4.1 MB 11.4 kB/s eta 0:05:44\n",
            "   -- ------------------------------------- 0.2/4.1 MB 11.4 kB/s eta 0:05:44\n",
            "   -- ------------------------------------- 0.2/4.1 MB 11.4 kB/s eta 0:05:44\n",
            "   -- ------------------------------------- 0.2/4.1 MB 11.4 kB/s eta 0:05:44\n",
            "   -- ------------------------------------- 0.2/4.1 MB 11.4 kB/s eta 0:05:44\n",
            "   -- ------------------------------------- 0.2/4.1 MB 11.4 kB/s eta 0:05:44\n",
            "   -- ------------------------------------- 0.2/4.1 MB 12.2 kB/s eta 0:05:20\n",
            "   -- ------------------------------------- 0.2/4.1 MB 12.2 kB/s eta 0:05:20\n",
            "   -- ------------------------------------- 0.2/4.1 MB 12.2 kB/s eta 0:05:20\n",
            "   -- ------------------------------------- 0.2/4.1 MB 12.2 kB/s eta 0:05:20\n",
            "   -- ------------------------------------- 0.2/4.1 MB 12.2 kB/s eta 0:05:20\n",
            "   -- ------------------------------------- 0.3/4.1 MB 12.6 kB/s eta 0:05:09\n",
            "   -- ------------------------------------- 0.3/4.1 MB 12.6 kB/s eta 0:05:09\n",
            "   -- ------------------------------------- 0.3/4.1 MB 13.6 kB/s eta 0:04:45\n",
            "   -- ------------------------------------- 0.3/4.1 MB 15.1 kB/s eta 0:04:14\n",
            "   --- ------------------------------------ 0.3/4.1 MB 16.6 kB/s eta 0:03:49\n",
            "   --- ------------------------------------ 0.3/4.1 MB 16.6 kB/s eta 0:03:49\n",
            "   --- ------------------------------------ 0.3/4.1 MB 16.6 kB/s eta 0:03:49\n",
            "   --- ------------------------------------ 0.3/4.1 MB 16.6 kB/s eta 0:03:49\n",
            "   --- ------------------------------------ 0.3/4.1 MB 16.6 kB/s eta 0:03:49\n",
            "   --- ------------------------------------ 0.4/4.1 MB 17.9 kB/s eta 0:03:30\n",
            "   --- ------------------------------------ 0.4/4.1 MB 18.9 kB/s eta 0:03:18\n",
            "   ---- ----------------------------------- 0.4/4.1 MB 21.4 kB/s eta 0:02:53\n",
            "   ---- ----------------------------------- 0.5/4.1 MB 22.9 kB/s eta 0:02:40\n",
            "   ----- ---------------------------------- 0.5/4.1 MB 25.9 kB/s eta 0:02:20\n",
            "   ----- ---------------------------------- 0.6/4.1 MB 28.4 kB/s eta 0:02:05\n",
            "   ----- ---------------------------------- 0.6/4.1 MB 29.8 kB/s eta 0:01:58\n",
            "   ------ --------------------------------- 0.7/4.1 MB 32.7 kB/s eta 0:01:46\n",
            "   ------ --------------------------------- 0.7/4.1 MB 33.7 kB/s eta 0:01:42\n",
            "   ------- -------------------------------- 0.7/4.1 MB 36.1 kB/s eta 0:01:34\n",
            "   ------- -------------------------------- 0.8/4.1 MB 38.0 kB/s eta 0:01:28\n",
            "   -------- ------------------------------- 0.8/4.1 MB 40.0 kB/s eta 0:01:23\n",
            "   -------- ------------------------------- 0.9/4.1 MB 42.8 kB/s eta 0:01:16\n",
            "   --------- ------------------------------ 1.0/4.1 MB 47.7 kB/s eta 0:01:06\n",
            "   ---------- ----------------------------- 1.1/4.1 MB 53.6 kB/s eta 0:00:57\n",
            "   ----------- ---------------------------- 1.2/4.1 MB 58.9 kB/s eta 0:00:50\n",
            "   ------------- -------------------------- 1.4/4.1 MB 66.2 kB/s eta 0:00:42\n",
            "   -------------- ------------------------- 1.5/4.1 MB 69.9 kB/s eta 0:00:39\n",
            "   ---------------- ----------------------- 1.7/4.1 MB 79.1 kB/s eta 0:00:32\n",
            "   ---------------- ----------------------- 1.7/4.1 MB 82.9 kB/s eta 0:00:29\n",
            "   ------------------ --------------------- 1.9/4.1 MB 91.0 kB/s eta 0:00:25\n",
            "   ------------------- -------------------- 2.0/4.1 MB 94.7 kB/s eta 0:00:23\n",
            "   --------------------- ------------------ 2.2/4.1 MB 104.2 kB/s eta 0:00:19\n",
            "   ---------------------- ----------------- 2.3/4.1 MB 107.8 kB/s eta 0:00:18\n",
            "   ----------------------- ---------------- 2.4/4.1 MB 112.0 kB/s eta 0:00:16\n",
            "   ----------------------- ---------------- 2.4/4.1 MB 115.3 kB/s eta 0:00:15\n",
            "   ------------------------ --------------- 2.5/4.1 MB 117.8 kB/s eta 0:00:14\n",
            "   ------------------------- -------------- 2.6/4.1 MB 122.9 kB/s eta 0:00:13\n",
            "   -------------------------- ------------- 2.8/4.1 MB 128.8 kB/s eta 0:00:11\n",
            "   --------------------------- ------------ 2.9/4.1 MB 133.8 kB/s eta 0:00:10\n",
            "   ---------------------------- ----------- 2.9/4.1 MB 136.8 kB/s eta 0:00:09\n",
            "   ----------------------------- ---------- 3.0/4.1 MB 140.8 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 3.1/4.1 MB 142.9 kB/s eta 0:00:08\n",
            "   ------------------------------- -------- 3.3/4.1 MB 151.1 kB/s eta 0:00:06\n",
            "   -------------------------------- ------- 3.4/4.1 MB 156.5 kB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 3.6/4.1 MB 164.7 kB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 3.7/4.1 MB 168.3 kB/s eta 0:00:03\n",
            "   -------------------------------------- - 3.9/4.1 MB 180.4 kB/s eta 0:00:02\n",
            "   ---------------------------------------  4.0/4.1 MB 185.5 kB/s eta 0:00:01\n",
            "   ---------------------------------------  4.1/4.1 MB 188.7 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.1/4.1 MB 188.8 kB/s eta 0:00:00\n",
            "Using cached kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Using cached mmh3-4.1.0-cp312-cp312-win_amd64.whl (31 kB)\n",
            "Using cached onnxruntime-1.18.1-cp312-cp312-win_amd64.whl (5.6 MB)\n",
            "Using cached opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Using cached opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Using cached opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "Using cached opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
            "Using cached opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
            "Using cached opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "Using cached opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
            "Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "Downloading tokenizers-0.20.0-cp312-none-win_amd64.whl (2.3 MB)\n",
            "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.2/2.3 MB 4.8 MB/s eta 0:00:01\n",
            "   --- ------------------------------------ 0.2/2.3 MB 1.7 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 0.3/2.3 MB 2.3 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 0.5/2.3 MB 2.5 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 0.7/2.3 MB 2.7 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 0.8/2.3 MB 2.7 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 0.9/2.3 MB 2.9 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.0/2.3 MB 3.0 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 1.1/2.3 MB 2.7 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.3/2.3 MB 2.9 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.4/2.3 MB 2.6 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 1.5/2.3 MB 2.7 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 1.6/2.3 MB 2.6 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.6/2.3 MB 2.6 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.6/2.3 MB 2.6 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.7/2.3 MB 2.3 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.7/2.3 MB 2.2 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 1.8/2.3 MB 2.1 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 1.8/2.3 MB 2.1 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 1.9/2.3 MB 2.0 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 1.9/2.3 MB 2.0 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 2.0/2.3 MB 2.0 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.1/2.3 MB 2.0 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 2.2/2.3 MB 1.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.2/2.3 MB 1.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.2/2.3 MB 1.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.3/2.3 MB 1.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.3/2.3 MB 1.8 MB/s eta 0:00:00\n",
            "Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "Downloading uvicorn-0.30.5-py3-none-any.whl (62 kB)\n",
            "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
            "   ------------------- -------------------- 30.7/62.8 kB 445.2 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 62.8/62.8 kB 673.9 kB/s eta 0:00:00\n",
            "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading google_auth-2.33.0-py2.py3-none-any.whl (200 kB)\n",
            "   ---------------------------------------- 0.0/200.5 kB ? eta -:--:--\n",
            "   ------ --------------------------------- 30.7/200.5 kB ? eta -:--:--\n",
            "   ------ --------------------------------- 30.7/200.5 kB ? eta -:--:--\n",
            "   --------------- ----------------------- 81.9/200.5 kB 651.6 kB/s eta 0:00:01\n",
            "   --------------------- ---------------- 112.6/200.5 kB 595.3 kB/s eta 0:00:01\n",
            "   --------------------------- ---------- 143.4/200.5 kB 607.9 kB/s eta 0:00:01\n",
            "   -------------------------------- ----- 174.1/200.5 kB 615.9 kB/s eta 0:00:01\n",
            "   -------------------------------------- 200.5/200.5 kB 608.0 kB/s eta 0:00:00\n",
            "Using cached googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
            "Using cached httptools-0.6.1-cp312-cp312-win_amd64.whl (55 kB)\n",
            "Using cached huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
            "Using cached importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached protobuf-4.25.4-cp310-abi3-win_amd64.whl (413 kB)\n",
            "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "Downloading watchfiles-0.23.0-cp312-none-win_amd64.whl (275 kB)\n",
            "   ---------------------------------------- 0.0/275.5 kB ? eta -:--:--\n",
            "   - -------------------------------------- 10.2/275.5 kB ? eta -:--:--\n",
            "   ----- --------------------------------- 41.0/275.5 kB 393.8 kB/s eta 0:00:01\n",
            "   ------------- ------------------------- 92.2/275.5 kB 585.1 kB/s eta 0:00:01\n",
            "   ------------------- ------------------ 143.4/275.5 kB 774.0 kB/s eta 0:00:01\n",
            "   -------------------------- ----------- 194.6/275.5 kB 908.0 kB/s eta 0:00:01\n",
            "   ------------------------------- ------ 225.3/275.5 kB 860.2 kB/s eta 0:00:01\n",
            "   ----------------------------------- -- 256.0/275.5 kB 827.5 kB/s eta 0:00:01\n",
            "   -------------------------------------- 275.5/275.5 kB 738.9 kB/s eta 0:00:00\n",
            "Using cached websockets-12.0-cp312-cp312-win_amd64.whl (124 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Using cached pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
            "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/6.2 MB 660.6 kB/s eta 0:00:10\n",
            "   ---------------------------------------- 0.0/6.2 MB 660.6 kB/s eta 0:00:10\n",
            "   ---------------------------------------- 0.0/6.2 MB 660.6 kB/s eta 0:00:10\n",
            "   ---------------------------------------- 0.0/6.2 MB 660.6 kB/s eta 0:00:10\n",
            "   ---------------------------------------- 0.0/6.2 MB 122.9 kB/s eta 0:00:51\n",
            "   ---------------------------------------- 0.1/6.2 MB 182.2 kB/s eta 0:00:34\n",
            "    --------------------------------------- 0.1/6.2 MB 238.1 kB/s eta 0:00:26\n",
            "    --------------------------------------- 0.1/6.2 MB 340.5 kB/s eta 0:00:18\n",
            "   - -------------------------------------- 0.2/6.2 MB 378.3 kB/s eta 0:00:16\n",
            "   - -------------------------------------- 0.2/6.2 MB 393.0 kB/s eta 0:00:16\n",
            "   - -------------------------------------- 0.2/6.2 MB 393.0 kB/s eta 0:00:16\n",
            "   - -------------------------------------- 0.2/6.2 MB 393.0 kB/s eta 0:00:16\n",
            "   - -------------------------------------- 0.2/6.2 MB 311.3 kB/s eta 0:00:20\n",
            "   - -------------------------------------- 0.2/6.2 MB 342.8 kB/s eta 0:00:18\n",
            "   - -------------------------------------- 0.3/6.2 MB 356.1 kB/s eta 0:00:17\n",
            "   - -------------------------------------- 0.3/6.2 MB 367.1 kB/s eta 0:00:17\n",
            "   -- ------------------------------------- 0.3/6.2 MB 390.9 kB/s eta 0:00:15\n",
            "   -- ------------------------------------- 0.3/6.2 MB 390.9 kB/s eta 0:00:15\n",
            "   -- ------------------------------------- 0.3/6.2 MB 386.2 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.3/6.2 MB 386.2 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.4/6.2 MB 368.6 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.4/6.2 MB 377.4 kB/s eta 0:00:16\n",
            "   -- ------------------------------------- 0.4/6.2 MB 383.8 kB/s eta 0:00:16\n",
            "   --- ------------------------------------ 0.5/6.2 MB 412.8 kB/s eta 0:00:14\n",
            "   --- ------------------------------------ 0.5/6.2 MB 422.7 kB/s eta 0:00:14\n",
            "   --- ------------------------------------ 0.6/6.2 MB 448.1 kB/s eta 0:00:13\n",
            "   --- ------------------------------------ 0.6/6.2 MB 455.6 kB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 0.7/6.2 MB 501.2 kB/s eta 0:00:12\n",
            "   ---- ----------------------------------- 0.7/6.2 MB 521.3 kB/s eta 0:00:11\n",
            "   ----- ---------------------------------- 0.8/6.2 MB 590.5 kB/s eta 0:00:10\n",
            "   ----- ---------------------------------- 0.9/6.2 MB 606.5 kB/s eta 0:00:09\n",
            "   ------ --------------------------------- 1.0/6.2 MB 641.7 kB/s eta 0:00:09\n",
            "   ------ --------------------------------- 1.0/6.2 MB 648.7 kB/s eta 0:00:08\n",
            "   ------ --------------------------------- 1.1/6.2 MB 655.5 kB/s eta 0:00:08\n",
            "   ------- -------------------------------- 1.2/6.2 MB 692.6 kB/s eta 0:00:08\n",
            "   ------- -------------------------------- 1.2/6.2 MB 715.5 kB/s eta 0:00:07\n",
            "   -------- ------------------------------- 1.3/6.2 MB 749.0 kB/s eta 0:00:07\n",
            "   --------- ------------------------------ 1.4/6.2 MB 775.0 kB/s eta 0:00:07\n",
            "   ---------- ----------------------------- 1.6/6.2 MB 838.5 kB/s eta 0:00:06\n",
            "   ---------- ----------------------------- 1.6/6.2 MB 861.0 kB/s eta 0:00:06\n",
            "   ----------- ---------------------------- 1.8/6.2 MB 941.0 kB/s eta 0:00:05\n",
            "   ------------ --------------------------- 1.9/6.2 MB 975.5 kB/s eta 0:00:05\n",
            "   ------------- -------------------------- 2.1/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 2.2/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 2.2/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 2.3/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 2.3/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 2.4/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 2.4/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 2.5/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 2.5/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 2.5/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 2.5/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 2.5/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 2.6/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 2.6/6.2 MB 998.6 kB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 2.7/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 2.8/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 2.8/6.2 MB 1.0 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 2.8/6.2 MB 990.5 kB/s eta 0:00:04\n",
            "   ------------------ --------------------- 2.8/6.2 MB 985.0 kB/s eta 0:00:04\n",
            "   ------------------ --------------------- 2.8/6.2 MB 983.0 kB/s eta 0:00:04\n",
            "   ------------------ --------------------- 2.9/6.2 MB 964.0 kB/s eta 0:00:04\n",
            "   ------------------ --------------------- 2.9/6.2 MB 959.1 kB/s eta 0:00:04\n",
            "   ------------------ --------------------- 2.9/6.2 MB 946.4 kB/s eta 0:00:04\n",
            "   ------------------ --------------------- 2.9/6.2 MB 942.0 kB/s eta 0:00:04\n",
            "   ------------------- -------------------- 3.0/6.2 MB 953.9 kB/s eta 0:00:04\n",
            "   ------------------- -------------------- 3.1/6.2 MB 968.5 kB/s eta 0:00:04\n",
            "   -------------------- ------------------- 3.1/6.2 MB 965.7 kB/s eta 0:00:04\n",
            "   -------------------- ------------------- 3.2/6.2 MB 967.5 kB/s eta 0:00:04\n",
            "   -------------------- ------------------- 3.2/6.2 MB 967.5 kB/s eta 0:00:04\n",
            "   -------------------- ------------------- 3.2/6.2 MB 945.2 kB/s eta 0:00:04\n",
            "   -------------------- ------------------- 3.2/6.2 MB 942.6 kB/s eta 0:00:04\n",
            "   --------------------- ------------------ 3.3/6.2 MB 944.6 kB/s eta 0:00:04\n",
            "   --------------------- ------------------ 3.3/6.2 MB 949.4 kB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 3.5/6.2 MB 965.9 kB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 3.5/6.2 MB 974.4 kB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 3.6/6.2 MB 985.9 kB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 3.7/6.2 MB 998.3 kB/s eta 0:00:03\n",
            "   ------------------------ --------------- 3.8/6.2 MB 1.0 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 4.0/6.2 MB 1.0 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 4.0/6.2 MB 1.0 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 4.2/6.2 MB 1.1 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 4.4/6.2 MB 1.1 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 4.6/6.2 MB 1.1 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 4.6/6.2 MB 1.2 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 4.8/6.2 MB 1.2 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 4.9/6.2 MB 1.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 5.1/6.2 MB 1.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 5.2/6.2 MB 1.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 5.2/6.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 5.3/6.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 5.3/6.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 5.5/6.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 5.5/6.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 5.7/6.2 MB 1.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 5.7/6.2 MB 1.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 5.8/6.2 MB 1.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 5.9/6.2 MB 1.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 6.0/6.2 MB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.1/6.2 MB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.1/6.2 MB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.2/6.2 MB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.2/6.2 MB 1.3 MB/s eta 0:00:00\n",
            "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Using cached cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
            "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
            "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
            "Downloading zipp-3.20.0-py3-none-any.whl (9.4 kB)\n",
            "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
            "Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
            "Installing collected packages: pyreadline3, pypika, mpmath, monotonic, mmh3, flatbuffers, zipp, wrapt, websockets, sympy, shellingham, python-dotenv, pyproject_hooks, pyasn1, protobuf, opentelemetry-util-http, oauthlib, mdurl, importlib-resources, humanfriendly, httptools, grpcio, fsspec, filelock, click, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, huggingface-hub, googleapis-common-protos, deprecated, coloredlogs, build, tokenizers, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, fastapi, typer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.1 cachetools-5.4.0 chroma-hnswlib-0.7.6 chromadb-0.5.5 click-8.1.7 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.112.0 filelock-3.15.4 flatbuffers-24.3.25 fsspec-2024.6.1 google-auth-2.33.0 googleapis-common-protos-1.63.2 grpcio-1.65.4 httptools-0.6.1 huggingface-hub-0.24.5 humanfriendly-10.0 importlib-metadata-8.0.0 importlib-resources-6.4.0 kubernetes-30.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.18.1 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 posthog-3.5.0 protobuf-4.25.4 pyasn1-0.6.0 pyasn1-modules-0.4.0 pypika-0.48.9 pyproject_hooks-1.1.0 pyreadline3-3.4.1 python-dotenv-1.0.1 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 shellingham-1.5.4 starlette-0.37.2 sympy-1.13.2 tokenizers-0.20.0 typer-0.12.3 uvicorn-0.30.5 watchfiles-0.23.0 websockets-12.0 wrapt-1.16.0 zipp-3.20.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# DB 설치\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnb64MM1eO7m"
      },
      "source": [
        "# 임베딩(벡터로 변환)\n",
        "embed_documents(쪼개놓은 리스트 데이터)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "llm 모델에 따라"
      ],
      "metadata": {
        "id": "iCjASPhMwq79"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "Vdt9FmRtd7sJ"
      },
      "outputs": [],
      "source": [
        "# 모델에 맞는 벡터로 바꾸기\n",
        "from langchain.embeddings import OllamaEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04z2RdJQet70"
      },
      "source": [
        "### 예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh0IN3zKesjl",
        "outputId": "a53dffac-714f-4ebf-bc21-2490acfea1fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[-1.201870083808899,\n",
              "  -1.3496184349060059,\n",
              "  1.9520281553268433,\n",
              "  -0.6904845833778381,\n",
              "  -1.8557628393173218,\n",
              "  1.6630489826202393,\n",
              "  -1.13215970993042,\n",
              "  -1.3470097780227661,\n",
              "  -2.7276809215545654,\n",
              "  0.6771400570869446,\n",
              "  0.08939411491155624,\n",
              "  0.9918240308761597,\n",
              "  -0.40018928050994873,\n",
              "  0.07948622107505798,\n",
              "  -1.4984127283096313,\n",
              "  0.6941771507263184,\n",
              "  -2.468235731124878,\n",
              "  0.3809504508972168,\n",
              "  0.3756946921348572,\n",
              "  1.175871729850769,\n",
              "  -0.020050527527928352,\n",
              "  0.7859618663787842,\n",
              "  1.207483172416687,\n",
              "  2.03973388671875,\n",
              "  -1.2497934103012085,\n",
              "  1.4230222702026367,\n",
              "  2.302495241165161,\n",
              "  1.449194312095642,\n",
              "  -1.3394781351089478,\n",
              "  0.8230024576187134,\n",
              "  -0.8832921385765076,\n",
              "  -1.2530595064163208,\n",
              "  0.8485546708106995,\n",
              "  1.7714552879333496,\n",
              "  -1.5753111839294434,\n",
              "  -1.4062641859054565,\n",
              "  -0.76748126745224,\n",
              "  0.530312180519104,\n",
              "  -0.9603720903396606,\n",
              "  -2.392691135406494,\n",
              "  -0.023035181686282158,\n",
              "  -2.260455846786499,\n",
              "  1.291837215423584,\n",
              "  -0.4137038290500641,\n",
              "  0.5460231304168701,\n",
              "  2.5645740032196045,\n",
              "  3.2710471153259277,\n",
              "  -0.12749770283699036,\n",
              "  0.2948296368122101,\n",
              "  -0.9030899405479431,\n",
              "  0.5571958422660828,\n",
              "  -0.14350217580795288,\n",
              "  -2.3984131813049316,\n",
              "  1.0826845169067383,\n",
              "  0.37578311562538147,\n",
              "  0.6181750893592834,\n",
              "  1.2962589263916016,\n",
              "  -0.24109970033168793,\n",
              "  -1.807395577430725,\n",
              "  0.0571601502597332,\n",
              "  -1.3568147420883179,\n",
              "  3.08129620552063,\n",
              "  -1.2382475137710571,\n",
              "  -0.7875692844390869,\n",
              "  0.394157350063324,\n",
              "  0.3291049003601074,\n",
              "  -0.6525424718856812,\n",
              "  -0.647654116153717,\n",
              "  1.1729247570037842,\n",
              "  2.7942488193511963,\n",
              "  -0.10257454961538315,\n",
              "  -1.7318910360336304,\n",
              "  1.7428045272827148,\n",
              "  -0.7496277093887329,\n",
              "  2.5979106426239014,\n",
              "  0.09826207160949707,\n",
              "  -0.37379223108291626,\n",
              "  1.8175417184829712,\n",
              "  -0.19872190058231354,\n",
              "  -1.0985689163208008,\n",
              "  -0.6207458972930908,\n",
              "  2.604069948196411,\n",
              "  0.6112925410270691,\n",
              "  1.3151401281356812,\n",
              "  0.21301521360874176,\n",
              "  -1.552501916885376,\n",
              "  1.2084167003631592,\n",
              "  -1.5559155941009521,\n",
              "  1.3173935413360596,\n",
              "  0.45019209384918213,\n",
              "  -0.6493409276008606,\n",
              "  -2.047938823699951,\n",
              "  -0.4727369546890259,\n",
              "  -0.23735785484313965,\n",
              "  -0.22688639163970947,\n",
              "  -1.2074875831604004,\n",
              "  0.10060058534145355,\n",
              "  0.7785779237747192,\n",
              "  0.2735899090766907,\n",
              "  2.2428412437438965,\n",
              "  0.38196372985839844,\n",
              "  -1.4762160778045654,\n",
              "  -0.8783845901489258,\n",
              "  1.4152989387512207,\n",
              "  1.6041756868362427,\n",
              "  0.1048639789223671,\n",
              "  -0.5849269032478333,\n",
              "  0.7101543545722961,\n",
              "  -0.8399733304977417,\n",
              "  -0.5728888511657715,\n",
              "  1.314271330833435,\n",
              "  -0.3807719945907593,\n",
              "  0.8589560389518738,\n",
              "  2.6463356018066406,\n",
              "  -3.2146458625793457,\n",
              "  0.46165090799331665,\n",
              "  0.46582651138305664,\n",
              "  -0.1548832207918167,\n",
              "  -0.4203990697860718,\n",
              "  -0.6707451343536377,\n",
              "  -0.14067132771015167,\n",
              "  0.7302431464195251,\n",
              "  0.7950330376625061,\n",
              "  -0.8735466003417969,\n",
              "  0.017373325303196907,\n",
              "  0.016547825187444687,\n",
              "  1.631019949913025,\n",
              "  -0.4041547179222107,\n",
              "  1.353639841079712,\n",
              "  1.8955824375152588,\n",
              "  0.35323718190193176,\n",
              "  0.1366664469242096,\n",
              "  -1.8829494714736938,\n",
              "  3.391920328140259,\n",
              "  0.41522204875946045,\n",
              "  -1.0417286157608032,\n",
              "  1.818837285041809,\n",
              "  1.3864229917526245,\n",
              "  -1.013451337814331,\n",
              "  -0.3539508879184723,\n",
              "  -1.8652201890945435,\n",
              "  -2.216923236846924,\n",
              "  -27.670469284057617,\n",
              "  -0.9025204181671143,\n",
              "  -0.25823619961738586,\n",
              "  0.2211213856935501,\n",
              "  0.7546719312667847,\n",
              "  -1.3578764200210571,\n",
              "  2.1078882217407227,\n",
              "  -1.8430287837982178,\n",
              "  -0.04099351167678833,\n",
              "  1.0560734272003174,\n",
              "  -0.2043015956878662,\n",
              "  -2.080475330352783,\n",
              "  1.9825090169906616,\n",
              "  -1.8204827308654785,\n",
              "  -0.12974892556667328,\n",
              "  -0.14400614798069,\n",
              "  -0.8136557936668396,\n",
              "  1.1827529668807983,\n",
              "  -1.3326084613800049,\n",
              "  -3.424485921859741,\n",
              "  -0.21321742236614227,\n",
              "  2.7055232524871826,\n",
              "  0.20062437653541565,\n",
              "  0.3466804027557373,\n",
              "  -1.0560978651046753,\n",
              "  -1.1398922204971313,\n",
              "  -2.3576881885528564,\n",
              "  0.21493257582187653,\n",
              "  -1.1013472080230713,\n",
              "  2.344353437423706,\n",
              "  0.05526799336075783,\n",
              "  1.2700722217559814,\n",
              "  0.64090895652771,\n",
              "  -2.270291566848755,\n",
              "  -0.5736281871795654,\n",
              "  0.6023962497711182,\n",
              "  0.8431265354156494,\n",
              "  0.318471759557724,\n",
              "  0.6526334881782532,\n",
              "  1.1237671375274658,\n",
              "  0.2300470471382141,\n",
              "  -1.7004960775375366,\n",
              "  -4.755683898925781,\n",
              "  0.6090610027313232,\n",
              "  -1.2026573419570923,\n",
              "  0.38578614592552185,\n",
              "  1.1895675659179688,\n",
              "  0.41424432396888733,\n",
              "  2.480581283569336,\n",
              "  0.10011526197195053,\n",
              "  0.2347840517759323,\n",
              "  0.16655956208705902,\n",
              "  -1.954395055770874,\n",
              "  -2.977224588394165,\n",
              "  0.5112771987915039,\n",
              "  0.1185675859451294,\n",
              "  0.4813150465488434,\n",
              "  -0.22501704096794128,\n",
              "  0.40567269921302795,\n",
              "  -0.06291654706001282,\n",
              "  0.6677217483520508,\n",
              "  -2.415931463241577,\n",
              "  -0.240804523229599,\n",
              "  -0.15637993812561035,\n",
              "  0.5513615608215332,\n",
              "  -1.3229624032974243,\n",
              "  -0.4434990882873535,\n",
              "  -0.9862116575241089,\n",
              "  0.624785304069519,\n",
              "  -1.3537122011184692,\n",
              "  -1.0711840391159058,\n",
              "  -2.051382541656494,\n",
              "  1.0800706148147583,\n",
              "  2.911416530609131,\n",
              "  -0.31238144636154175,\n",
              "  -1.0113142728805542,\n",
              "  0.21128202974796295,\n",
              "  -0.9090519547462463,\n",
              "  -0.4746934175491333,\n",
              "  -0.9932407140731812,\n",
              "  0.5505593419075012,\n",
              "  2.1726300716400146,\n",
              "  -1.6359716653823853,\n",
              "  -0.5917351841926575,\n",
              "  1.9402576684951782,\n",
              "  -0.46308383345603943,\n",
              "  -3.1741976737976074,\n",
              "  0.09506198018789291,\n",
              "  -1.2540596723556519,\n",
              "  0.3284166753292084,\n",
              "  1.8665138483047485,\n",
              "  0.9895747303962708,\n",
              "  2.4738729000091553,\n",
              "  1.6974459886550903,\n",
              "  -1.404462218284607,\n",
              "  1.0958261489868164,\n",
              "  0.8221498131752014,\n",
              "  0.2522182762622833,\n",
              "  1.047548770904541,\n",
              "  0.29330921173095703,\n",
              "  -8.267326354980469,\n",
              "  1.0973539352416992,\n",
              "  2.080470561981201,\n",
              "  0.5420131087303162,\n",
              "  1.0700918436050415,\n",
              "  0.4080117642879486,\n",
              "  -0.4859836995601654,\n",
              "  -1.7449915409088135,\n",
              "  2.289616346359253,\n",
              "  0.673825204372406,\n",
              "  -1.4927077293395996,\n",
              "  -0.8019120097160339,\n",
              "  -0.6071041822433472,\n",
              "  2.05908203125,\n",
              "  -0.6171340942382812,\n",
              "  -1.6544517278671265,\n",
              "  -0.19424989819526672,\n",
              "  1.019086480140686,\n",
              "  0.5649580359458923,\n",
              "  -0.5691747665405273,\n",
              "  2.5536446571350098,\n",
              "  -1.195172667503357,\n",
              "  1.9413974285125732,\n",
              "  -1.2306474447250366,\n",
              "  -2.687143325805664,\n",
              "  7.551597595214844,\n",
              "  -0.7883296012878418,\n",
              "  -0.10980750620365143,\n",
              "  0.44523900747299194,\n",
              "  -1.8568212985992432,\n",
              "  -0.4675300717353821,\n",
              "  -1.8840664625167847,\n",
              "  0.9801761507987976,\n",
              "  -0.7559732794761658,\n",
              "  0.7410224080085754,\n",
              "  -2.4224042892456055,\n",
              "  -3.72253155708313,\n",
              "  2.085695743560791,\n",
              "  1.3050737380981445,\n",
              "  3.1008012294769287,\n",
              "  1.3738213777542114,\n",
              "  -1.6350395679473877,\n",
              "  -1.1469088792800903,\n",
              "  1.443881869316101,\n",
              "  1.8003642559051514,\n",
              "  0.615606963634491,\n",
              "  0.5672061443328857,\n",
              "  4.80271053314209,\n",
              "  2.2867560386657715,\n",
              "  1.102134346961975,\n",
              "  0.836176335811615,\n",
              "  -1.3704291582107544,\n",
              "  0.1282138228416443,\n",
              "  -1.5854480266571045,\n",
              "  0.8995501399040222,\n",
              "  -0.23427939414978027,\n",
              "  0.3514418303966522,\n",
              "  0.4768184423446655,\n",
              "  -0.9906538724899292,\n",
              "  -0.7607870697975159,\n",
              "  0.39788517355918884,\n",
              "  1.0311342477798462,\n",
              "  -3.106656074523926,\n",
              "  -0.14116284251213074,\n",
              "  1.4384558200836182,\n",
              "  -0.4714965522289276,\n",
              "  -0.07483625411987305,\n",
              "  -0.5687156915664673,\n",
              "  0.03204282745718956,\n",
              "  1.2429993152618408,\n",
              "  0.46718111634254456,\n",
              "  2.8290634155273438,\n",
              "  2.5322935581207275,\n",
              "  -0.03950655087828636,\n",
              "  -1.4508905410766602,\n",
              "  1.5979924201965332,\n",
              "  1.7407348155975342,\n",
              "  -0.5943335294723511,\n",
              "  -0.5472474694252014,\n",
              "  2.0978593826293945,\n",
              "  -1.747360110282898,\n",
              "  -0.5710184574127197,\n",
              "  -3.712629795074463,\n",
              "  -0.07935626059770584,\n",
              "  -0.13314774632453918,\n",
              "  -0.08950083702802658,\n",
              "  0.9937382340431213,\n",
              "  0.6839537620544434,\n",
              "  0.47034093737602234,\n",
              "  0.07495380938053131,\n",
              "  -1.0905811786651611,\n",
              "  -1.4113547801971436,\n",
              "  -1.0916208028793335,\n",
              "  -0.6135702729225159,\n",
              "  -0.4742008149623871,\n",
              "  1.2425484657287598,\n",
              "  0.6689245104789734,\n",
              "  -0.24441741406917572,\n",
              "  1.1693830490112305,\n",
              "  -1.138951063156128,\n",
              "  -0.35274970531463623,\n",
              "  1.094813585281372,\n",
              "  -2.349006414413452,\n",
              "  -0.020801151171326637,\n",
              "  -1.1057696342468262,\n",
              "  -0.5631526112556458,\n",
              "  -2.4707024097442627,\n",
              "  -2.0195415019989014,\n",
              "  0.44787511229515076,\n",
              "  0.05305032059550285,\n",
              "  -2.2994866371154785,\n",
              "  1.8324486017227173,\n",
              "  0.7304924726486206,\n",
              "  -2.6607229709625244,\n",
              "  0.6590056419372559,\n",
              "  2.2719335556030273,\n",
              "  1.374784231185913,\n",
              "  -0.44627001881599426,\n",
              "  -0.4201720356941223,\n",
              "  0.14302638173103333,\n",
              "  -1.226130485534668,\n",
              "  1.8550816774368286,\n",
              "  -0.46126651763916016,\n",
              "  0.4668731093406677,\n",
              "  -0.3753398656845093,\n",
              "  0.31057101488113403,\n",
              "  0.058656949549913406,\n",
              "  -0.7443937063217163,\n",
              "  1.8298040628433228,\n",
              "  0.5196792483329773,\n",
              "  0.5015272498130798,\n",
              "  0.46950796246528625,\n",
              "  -3.0306241512298584,\n",
              "  0.3093340992927551,\n",
              "  0.7078964710235596,\n",
              "  0.4628888964653015,\n",
              "  -1.097412109375,\n",
              "  -2.1784846782684326,\n",
              "  -0.20387159287929535,\n",
              "  -0.9311813712120056,\n",
              "  -0.1153487116098404,\n",
              "  1.6051857471466064,\n",
              "  0.3711329996585846,\n",
              "  1.5163317918777466,\n",
              "  0.2872464656829834,\n",
              "  0.03480127826333046,\n",
              "  -1.615684986114502,\n",
              "  -1.124645709991455,\n",
              "  -1.879930019378662,\n",
              "  2.458345651626587,\n",
              "  -0.8202900886535645,\n",
              "  -0.709574282169342,\n",
              "  0.47820335626602173,\n",
              "  -0.7562860250473022,\n",
              "  2.7544665336608887,\n",
              "  -0.396475225687027,\n",
              "  -1.1777007579803467,\n",
              "  1.3405958414077759,\n",
              "  1.7952685356140137,\n",
              "  0.6328452825546265,\n",
              "  25.81253433227539,\n",
              "  -0.3039158880710602,\n",
              "  2.9169600009918213,\n",
              "  0.12416693568229675,\n",
              "  -0.018170978873968124,\n",
              "  -1.5199145078659058,\n",
              "  1.2888915538787842,\n",
              "  -1.0175552368164062,\n",
              "  -0.6295901536941528,\n",
              "  0.3284722566604614,\n",
              "  -1.0552833080291748,\n",
              "  -0.4585735499858856,\n",
              "  -0.8168249726295471,\n",
              "  -0.9605154395103455,\n",
              "  -0.4528319835662842,\n",
              "  0.6260700225830078,\n",
              "  -3.2801918983459473,\n",
              "  0.9790307283401489,\n",
              "  -2.012053966522217,\n",
              "  -0.2184537649154663,\n",
              "  -0.6150680184364319,\n",
              "  2.5149006843566895,\n",
              "  -3.000929117202759,\n",
              "  -2.1178603172302246,\n",
              "  -1.2515853643417358,\n",
              "  0.7285371422767639,\n",
              "  0.3836139142513275,\n",
              "  -0.7519338726997375,\n",
              "  1.4903172254562378,\n",
              "  1.0574554204940796,\n",
              "  -0.7591674327850342,\n",
              "  -1.1878482103347778,\n",
              "  1.3660972118377686,\n",
              "  -0.4193587303161621,\n",
              "  -0.648749828338623,\n",
              "  -0.9639283418655396,\n",
              "  0.25961774587631226,\n",
              "  -0.3907255232334137,\n",
              "  -0.0717523917555809,\n",
              "  -1.24253249168396,\n",
              "  -1.3965164422988892,\n",
              "  -0.5199379324913025,\n",
              "  -2.8234899044036865,\n",
              "  0.8556361794471741,\n",
              "  1.0717089176177979,\n",
              "  0.48070913553237915,\n",
              "  0.2407689243555069,\n",
              "  0.3617277145385742,\n",
              "  4.739007949829102,\n",
              "  2.261281967163086,\n",
              "  -0.8864825367927551,\n",
              "  0.2335100620985031,\n",
              "  2.7295587062835693,\n",
              "  0.36590659618377686,\n",
              "  -0.0875573381781578,\n",
              "  1.9989583492279053,\n",
              "  -21.43684959411621,\n",
              "  0.45683059096336365,\n",
              "  0.40217024087905884,\n",
              "  1.7417349815368652,\n",
              "  -1.2491518259048462,\n",
              "  0.7562472224235535,\n",
              "  -0.36146631836891174,\n",
              "  0.8349575996398926,\n",
              "  0.5518986582756042,\n",
              "  -0.38308626413345337,\n",
              "  -0.1226244866847992,\n",
              "  0.8829072713851929,\n",
              "  -0.20516502857208252,\n",
              "  0.5227361917495728,\n",
              "  -0.2469441443681717,\n",
              "  -2.045534610748291,\n",
              "  1.1613715887069702,\n",
              "  0.4433746337890625,\n",
              "  -0.29991579055786133,\n",
              "  0.2572294771671295,\n",
              "  2.889232635498047,\n",
              "  -1.4512425661087036,\n",
              "  1.9498999118804932,\n",
              "  -0.47649893164634705,\n",
              "  -1.2308017015457153,\n",
              "  0.9929490089416504,\n",
              "  0.8691283464431763,\n",
              "  -1.584925651550293,\n",
              "  2.065574884414673,\n",
              "  1.3056788444519043,\n",
              "  -1.9240412712097168,\n",
              "  -4.5486555099487305,\n",
              "  0.8711625933647156,\n",
              "  -1.6469249725341797,\n",
              "  -0.831863284111023,\n",
              "  -0.4994739890098572,\n",
              "  0.9007549285888672,\n",
              "  -0.6159451603889465,\n",
              "  -0.7948305010795593,\n",
              "  1.8598946332931519,\n",
              "  0.48330679535865784,\n",
              "  -1.250693917274475,\n",
              "  1.1413542032241821,\n",
              "  0.5514236688613892,\n",
              "  -1.6266118288040161,\n",
              "  0.5862234234809875,\n",
              "  0.17548784613609314,\n",
              "  -0.9623898863792419,\n",
              "  -3.0476269721984863,\n",
              "  0.38308632373809814,\n",
              "  1.3647093772888184,\n",
              "  -1.127995491027832,\n",
              "  1.0608526468276978,\n",
              "  0.8020412921905518,\n",
              "  0.11961270868778229,\n",
              "  -1.269442081451416,\n",
              "  0.5965395569801331,\n",
              "  -1.3163155317306519,\n",
              "  -2.423762321472168,\n",
              "  -1.3107554912567139,\n",
              "  1.9769827127456665,\n",
              "  -0.5232436060905457,\n",
              "  2.9372198581695557,\n",
              "  0.08366471529006958,\n",
              "  0.2027536928653717,\n",
              "  -0.19212013483047485,\n",
              "  -0.5585529208183289,\n",
              "  0.01981365866959095,\n",
              "  1.1141245365142822,\n",
              "  0.6298859715461731,\n",
              "  1.8032892942428589,\n",
              "  -0.2384156882762909,\n",
              "  -0.5232967138290405,\n",
              "  -1.3601007461547852,\n",
              "  -0.9081411957740784,\n",
              "  -0.5675757527351379,\n",
              "  0.724030613899231,\n",
              "  1.755256175994873,\n",
              "  -0.08663415908813477,\n",
              "  -0.6609247326850891,\n",
              "  -0.7414504885673523,\n",
              "  0.25818178057670593,\n",
              "  -0.8499050736427307,\n",
              "  -1.4442108869552612,\n",
              "  -0.6333433389663696,\n",
              "  -0.5667002201080322,\n",
              "  -1.762223482131958,\n",
              "  -0.23750342428684235,\n",
              "  -0.7174802422523499,\n",
              "  1.7199987173080444,\n",
              "  0.009287163615226746,\n",
              "  0.5835373401641846,\n",
              "  -1.9026036262512207,\n",
              "  -1.4273823499679565,\n",
              "  -0.12374341487884521,\n",
              "  0.3333241939544678,\n",
              "  2.7220969200134277,\n",
              "  1.9459601640701294,\n",
              "  0.11900173872709274,\n",
              "  -2.832702159881592,\n",
              "  1.1822057962417603,\n",
              "  0.323138028383255,\n",
              "  0.31688427925109863,\n",
              "  1.4724180698394775,\n",
              "  0.5491759181022644,\n",
              "  -0.2627948522567749,\n",
              "  -1.0741292238235474,\n",
              "  -0.769076943397522,\n",
              "  -1.269852876663208,\n",
              "  1.853975772857666,\n",
              "  1.5442020893096924,\n",
              "  -0.04020633548498154,\n",
              "  0.006021967623382807,\n",
              "  1.4345109462738037,\n",
              "  0.44146251678466797,\n",
              "  -0.8369640111923218,\n",
              "  -0.1274396926164627,\n",
              "  -0.8054476380348206,\n",
              "  -1.2552106380462646,\n",
              "  0.16368062794208527,\n",
              "  -3.399717330932617,\n",
              "  -0.8328437805175781,\n",
              "  1.9587836265563965,\n",
              "  1.040406584739685,\n",
              "  -2.059788942337036,\n",
              "  0.18105024099349976,\n",
              "  0.880933403968811,\n",
              "  1.3153902292251587,\n",
              "  2.862372636795044,\n",
              "  1.4206509590148926,\n",
              "  0.7699079513549805,\n",
              "  -0.3353751301765442,\n",
              "  0.41567206382751465,\n",
              "  3.0111796855926514,\n",
              "  -3.777495861053467,\n",
              "  0.018639760091900826,\n",
              "  1.1928977966308594,\n",
              "  -0.9451574683189392,\n",
              "  -2.8837215900421143,\n",
              "  0.5317342877388,\n",
              "  -0.21290218830108643,\n",
              "  -0.49220913648605347,\n",
              "  0.7815716862678528,\n",
              "  1.5166518688201904,\n",
              "  1.5288883447647095,\n",
              "  -1.3752226829528809,\n",
              "  1.9749681949615479,\n",
              "  -2.6213300228118896,\n",
              "  1.0054720640182495,\n",
              "  0.10718157887458801,\n",
              "  -0.781961977481842,\n",
              "  0.37072208523750305,\n",
              "  2.0608785152435303,\n",
              "  -0.688119113445282,\n",
              "  -1.0304168462753296,\n",
              "  2.298255681991577,\n",
              "  0.8301690816879272,\n",
              "  1.5813473463058472,\n",
              "  -2.469775438308716,\n",
              "  -0.12854169309139252,\n",
              "  -0.17254449427127838,\n",
              "  1.1264601945877075,\n",
              "  0.010955755598843098,\n",
              "  0.5926648378372192,\n",
              "  -2.912813425064087,\n",
              "  -1.9326139688491821,\n",
              "  1.1262614727020264,\n",
              "  -1.7006111145019531,\n",
              "  -0.53209388256073,\n",
              "  -0.32575705647468567,\n",
              "  0.5546339750289917,\n",
              "  -1.5531576871871948,\n",
              "  1.262603759765625,\n",
              "  1.3053853511810303,\n",
              "  0.21600157022476196,\n",
              "  0.1974797546863556,\n",
              "  0.6648992896080017,\n",
              "  -0.3151615858078003,\n",
              "  -0.6934568881988525,\n",
              "  -1.5315213203430176,\n",
              "  -0.2675120234489441,\n",
              "  -2.7666115760803223,\n",
              "  -0.04858484864234924,\n",
              "  -0.6806522607803345,\n",
              "  0.3984490633010864,\n",
              "  0.1388411819934845,\n",
              "  -0.7498975992202759,\n",
              "  -0.9545157551765442,\n",
              "  -0.7849770188331604,\n",
              "  -0.909969687461853,\n",
              "  1.042902946472168,\n",
              "  0.3707340955734253,\n",
              "  1.2112988233566284,\n",
              "  -0.29876843094825745,\n",
              "  0.5960658192634583,\n",
              "  1.569029688835144,\n",
              "  1.3537734746932983,\n",
              "  2.4148848056793213,\n",
              "  1.2725502252578735,\n",
              "  1.6549736261367798,\n",
              "  0.24797727167606354,\n",
              "  0.011722961440682411,\n",
              "  -0.10938338190317154,\n",
              "  0.16699768602848053,\n",
              "  -0.13390056788921356,\n",
              "  -0.49573948979377747,\n",
              "  1.3864514827728271,\n",
              "  0.231450617313385,\n",
              "  -0.7903928160667419,\n",
              "  0.8497854471206665,\n",
              "  1.0632284879684448,\n",
              "  -0.9662132263183594,\n",
              "  0.6803798675537109,\n",
              "  -1.36782968044281,\n",
              "  1.2345302104949951,\n",
              "  -1.065807580947876,\n",
              "  0.854124128818512,\n",
              "  -0.35286062955856323,\n",
              "  0.014897528104484081,\n",
              "  -0.8375101089477539,\n",
              "  -0.2973625063896179,\n",
              "  0.42479991912841797,\n",
              "  0.7552686333656311,\n",
              "  0.9835461974143982,\n",
              "  0.10491321980953217,\n",
              "  -0.866593062877655,\n",
              "  1.841444730758667,\n",
              "  0.413480281829834,\n",
              "  -0.667768657207489,\n",
              "  -0.6786423325538635,\n",
              "  -0.09543173015117645,\n",
              "  0.19432900846004486,\n",
              "  0.21040566265583038,\n",
              "  2.5537445545196533,\n",
              "  1.7295160293579102,\n",
              "  -4.133350849151611,\n",
              "  0.30605462193489075,\n",
              "  -0.6550928950309753,\n",
              "  -0.3480660319328308,\n",
              "  0.4020465910434723,\n",
              "  1.009965181350708,\n",
              "  -0.07534702867269516,\n",
              "  -0.7841103672981262,\n",
              "  -0.6635414361953735,\n",
              "  -0.4426127076148987,\n",
              "  -0.5550556182861328,\n",
              "  1.1303967237472534,\n",
              "  0.4736328423023224,\n",
              "  0.31016281247138977,\n",
              "  -0.8855865597724915,\n",
              "  2.5764474868774414,\n",
              "  -0.1933838427066803,\n",
              "  0.5227330327033997,\n",
              "  0.5568040013313293,\n",
              "  -0.6156020760536194,\n",
              "  -0.8702425956726074,\n",
              "  0.2755291759967804,\n",
              "  1.4068559408187866,\n",
              "  -4.124837398529053,\n",
              "  1.1651721000671387,\n",
              "  -0.4425865113735199,\n",
              "  0.4321928918361664,\n",
              "  0.4747496545314789,\n",
              "  1.9750559329986572,\n",
              "  0.6411281824111938,\n",
              "  0.8443694710731506,\n",
              "  1.3801238536834717,\n",
              "  -0.30073925852775574,\n",
              "  -0.38505157828330994,\n",
              "  -1.3990850448608398,\n",
              "  1.983101725578308,\n",
              "  -3.137850284576416,\n",
              "  -0.5580804347991943,\n",
              "  -1.070676565170288,\n",
              "  1.319103479385376,\n",
              "  -0.8687194585800171,\n",
              "  0.12254562228918076,\n",
              "  0.8441124558448792,\n",
              "  1.789727807044983,\n",
              "  -1.9052337408065796,\n",
              "  0.7938135266304016,\n",
              "  -0.5480608344078064,\n",
              "  -3.2324275970458984,\n",
              "  -0.5598875284194946,\n",
              "  1.4403302669525146,\n",
              "  3.3761355876922607,\n",
              "  -0.7062720060348511,\n",
              "  -1.2038793563842773,\n",
              "  1.7997597455978394,\n",
              "  -1.5086807012557983,\n",
              "  -0.015118020586669445,\n",
              "  -0.1568741649389267,\n",
              "  1.7247499227523804,\n",
              "  2.1465067863464355,\n",
              "  1.9942524433135986,\n",
              "  -0.4590812623500824,\n",
              "  1.3784350156784058,\n",
              "  2.058103561401367,\n",
              "  1.6506729125976562,\n",
              "  -0.41483020782470703,\n",
              "  -0.29359710216522217,\n",
              "  0.9972429275512695,\n",
              "  -0.2982299327850342,\n",
              "  -0.6238768696784973,\n",
              "  0.6328985691070557,\n",
              "  0.08954665809869766,\n",
              "  -2.267606735229492,\n",
              "  -0.9446114897727966,\n",
              "  0.9550196528434753,\n",
              "  -0.344547301530838,\n",
              "  -0.36355480551719666,\n",
              "  -0.7616029977798462,\n",
              "  1.7784500122070312,\n",
              "  0.009242149069905281,\n",
              "  -1.6355146169662476,\n",
              "  0.4737579822540283,\n",
              "  0.4049946665763855,\n",
              "  1.57429039478302,\n",
              "  0.2979661524295807,\n",
              "  1.057819128036499,\n",
              "  -0.609542965888977,\n",
              "  0.8918911218643188,\n",
              "  0.31745651364326477,\n",
              "  0.27225831151008606,\n",
              "  -9.413117408752441,\n",
              "  1.4414091110229492,\n",
              "  -1.4469069242477417,\n",
              "  1.1861622333526611,\n",
              "  -1.8020185232162476,\n",
              "  2.099611759185791,\n",
              "  0.1664312481880188,\n",
              "  -1.8481160402297974,\n",
              "  0.24888324737548828,\n",
              "  -2.2374744415283203,\n",
              "  1.4988341331481934,\n",
              "  1.2795617580413818,\n",
              "  -0.3722746670246124,\n",
              "  -0.8517810106277466,\n",
              "  0.7989022135734558,\n",
              "  0.2254655361175537,\n",
              "  0.09092534333467484,\n",
              "  -0.5904693007469177,\n",
              "  -0.9689571857452393,\n",
              "  1.292504906654358,\n",
              "  0.2539753317832947,\n",
              "  0.19563575088977814,\n",
              "  -0.5448123216629028,\n",
              "  0.17929738759994507,\n",
              "  -1.3930609226226807,\n",
              "  0.9396321177482605,\n",
              "  -1.832406997680664,\n",
              "  -0.5314680337905884,\n",
              "  0.03467555716633797,\n",
              "  0.611728847026825,\n",
              "  -3.844594955444336,\n",
              "  -0.2940867841243744,\n",
              "  1.262180209159851,\n",
              "  -2.687544107437134,\n",
              "  -2.4671757221221924,\n",
              "  0.6291791796684265,\n",
              "  -0.8831721544265747,\n",
              "  -0.5275293588638306,\n",
              "  -0.15538233518600464,\n",
              "  -6.381649494171143,\n",
              "  0.42449748516082764,\n",
              "  1.0013360977172852,\n",
              "  -2.066033363342285,\n",
              "  -1.2175406217575073,\n",
              "  -2.0457279682159424,\n",
              "  0.11667534708976746,\n",
              "  -0.6864181160926819,\n",
              "  -1.0544121265411377,\n",
              "  -2.692896604537964,\n",
              "  -1.5416680574417114,\n",
              "  -0.015991169959306717,\n",
              "  1.086803674697876,\n",
              "  -0.6339408755302429,\n",
              "  -1.848923921585083,\n",
              "  -0.5497400760650635,\n",
              "  0.39572080969810486,\n",
              "  0.3561171591281891,\n",
              "  2.3783767223358154,\n",
              "  -2.6299450397491455,\n",
              "  -0.5785922408103943,\n",
              "  -1.5112508535385132,\n",
              "  1.3314778804779053,\n",
              "  0.35848987102508545,\n",
              "  0.3832104504108429,\n",
              "  -0.5337986946105957,\n",
              "  -3.3836259841918945,\n",
              "  2.2692506313323975,\n",
              "  -0.23846592009067535,\n",
              "  -0.0160019900649786,\n",
              "  0.3009432554244995,\n",
              "  0.4048221707344055,\n",
              "  -0.000400631659431383,\n",
              "  -0.0710521787405014,\n",
              "  -0.5602123141288757,\n",
              "  0.9307812452316284,\n",
              "  0.6577795147895813,\n",
              "  2.3676016330718994,\n",
              "  -0.5529537200927734,\n",
              "  -0.9675779342651367,\n",
              "  -0.291532427072525,\n",
              "  0.8271292448043823,\n",
              "  0.19558854401111603,\n",
              "  -0.35149282217025757,\n",
              "  0.5925694108009338,\n",
              "  1.688002347946167,\n",
              "  -0.6296778917312622,\n",
              "  -1.0231192111968994,\n",
              "  1.1029599905014038,\n",
              "  0.5257787704467773,\n",
              "  1.044047236442566,\n",
              "  0.22985178232192993,\n",
              "  0.33076241612434387,\n",
              "  0.29741936922073364,\n",
              "  2.114300489425659,\n",
              "  1.433566927909851,\n",
              "  0.9132606387138367,\n",
              "  1.5379908084869385,\n",
              "  0.602863073348999,\n",
              "  -0.3503805100917816,\n",
              "  1.7242428064346313,\n",
              "  0.3056914508342743,\n",
              "  -1.1099004745483398,\n",
              "  -0.008291414007544518,\n",
              "  -0.4944322109222412,\n",
              "  0.5511381030082703,\n",
              "  1.9133007526397705,\n",
              "  1.5949336290359497,\n",
              "  -1.48082435131073,\n",
              "  -2.043302059173584,\n",
              "  -1.788140058517456,\n",
              "  -1.1245280504226685,\n",
              "  2.473734140396118,\n",
              "  -2.906033515930176,\n",
              "  -2.2315421104431152,\n",
              "  -0.471035897731781,\n",
              "  -1.1318212747573853,\n",
              "  0.19701482355594635,\n",
              "  0.08684205263853073,\n",
              "  -1.8198025226593018,\n",
              "  0.820776104927063,\n",
              "  1.1958141326904297,\n",
              "  1.4898126125335693,\n",
              "  2.0253846645355225,\n",
              "  1.4243334531784058,\n",
              "  -1.9358571767807007,\n",
              "  0.22298453748226166,\n",
              "  -1.1039589643478394,\n",
              "  -0.9752095937728882,\n",
              "  2.72360897064209,\n",
              "  0.8671569228172302,\n",
              "  -2.217294216156006,\n",
              "  -0.2797800302505493,\n",
              "  1.314219355583191,\n",
              "  -0.897031307220459,\n",
              "  -1.1248242855072021,\n",
              "  2.8772377967834473,\n",
              "  0.9727669954299927,\n",
              "  0.8699054718017578,\n",
              "  -0.45151400566101074,\n",
              "  -0.07572639733552933,\n",
              "  -1.1348685026168823,\n",
              "  0.26462993025779724,\n",
              "  -1.0443556308746338,\n",
              "  1.1596370935440063,\n",
              "  -0.036587152630090714,\n",
              "  1.2230329513549805,\n",
              "  -0.7695503234863281,\n",
              "  -0.3023483455181122,\n",
              "  0.7329835891723633,\n",
              "  0.03313572332262993,\n",
              "  -1.9839816093444824,\n",
              "  1.0635067224502563,\n",
              "  0.6184365153312683,\n",
              "  0.36663946509361267,\n",
              "  -1.5783940553665161,\n",
              "  -0.5486170649528503,\n",
              "  -2.567223310470581,\n",
              "  -1.7859067916870117,\n",
              "  -19.548059463500977,\n",
              "  0.5434678196907043,\n",
              "  0.266592413187027,\n",
              "  -0.07020341604948044,\n",
              "  -0.6404789090156555,\n",
              "  1.9849437475204468,\n",
              "  -2.3069870471954346,\n",
              "  1.0154235363006592,\n",
              "  -0.2234334945678711,\n",
              "  -0.15599022805690765,\n",
              "  0.40154850482940674,\n",
              "  3.170546293258667,\n",
              "  -1.6357841491699219,\n",
              "  -0.43106529116630554,\n",
              "  -1.9634038209915161,\n",
              "  0.03557674586772919,\n",
              "  -0.9595608115196228,\n",
              "  -1.1251988410949707,\n",
              "  -0.623552143573761,\n",
              "  0.24502556025981903,\n",
              "  -0.7211562395095825,\n",
              "  -0.40986910462379456,\n",
              "  1.8830522298812866,\n",
              "  -0.09341458976268768,\n",
              "  1.5284247398376465,\n",
              "  2.832251787185669,\n",
              "  0.5091185569763184,\n",
              "  2.6668245792388916,\n",
              "  -1.2344622611999512,\n",
              "  -1.152944803237915,\n",
              "  -2.1308226585388184,\n",
              "  0.8384192585945129,\n",
              "  0.9396420121192932,\n",
              "  -0.4899575710296631,\n",
              "  1.083852767944336,\n",
              "  2.5843734741210938,\n",
              "  0.1574879288673401,\n",
              "  -8.304296493530273,\n",
              "  -0.9152215719223022,\n",
              "  -0.4192616939544678,\n",
              "  -0.9310230016708374,\n",
              "  -0.1468094140291214,\n",
              "  0.015141543932259083,\n",
              "  -0.0030406813602894545,\n",
              "  0.1945071965456009,\n",
              "  -1.207196831703186,\n",
              "  -0.6035565137863159,\n",
              "  -0.7428411245346069,\n",
              "  -0.8047745823860168,\n",
              "  1.4604870080947876,\n",
              "  0.9474225640296936,\n",
              "  -0.2239917367696762,\n",
              "  -1.860542893409729,\n",
              "  -0.7535161972045898,\n",
              "  -0.19207999110221863,\n",
              "  2.669492721557617,\n",
              "  -0.7918730974197388,\n",
              "  0.6857725381851196,\n",
              "  0.4273712635040283,\n",
              "  0.3105297386646271,\n",
              "  ...]]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ollama는 4096 차원\n",
        "embedding = OllamaEmbeddings(model='llama3.1')\n",
        "result = embedding.embed_documents(['안녕하세요?'])\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPhWnzE6ezHY",
        "outputId": "626bba9e-759c-4df8-91f1-6fa92866944d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_SgbOjJe0is",
        "outputId": "ebe58623-31bc-45cd-afaa-d4d260bba60a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4096"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(result[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2sYW1V4e6CB"
      },
      "source": [
        "### 쪼개놓은 문서"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T94Pgk551X_T",
        "outputId": "e875ca75-7205-4bfd-d443-08bf777647f5"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './서브웨이.txt'}, page_content='▲서브웨이 에그마요 꿀조합\\n\\n-서브웨이 빵: 플랫 브래드\\n\\n-서브웨이 토핑: 베이컨 추가, 더블치즈, 야채 골고루\\n\\n-서브웨이 소스: 어니언+홀스래디쉬+스위트 칠리\\n\\n\\n▲서브웨이 참치 꿀조합\\n\\n-서브웨이 빵: 허니 오트\\n\\n-서브웨이 토핑: 슈레트 치즈, 야채 골고루\\n\\n-서브웨이 소스: 렌치+스위트 칠리\\n\\n\\n▲서브웨이 이탈리안 비엠티 꿀조합'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='▲서브웨이 이탈리안 비엠티 꿀조합\\n\\n-서브웨이 빵: 허니오트\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채 골고루\\n\\n-서브웨이 소스: 스위트 어니언+렌치소스\\n\\n\\n▲서브웨이 치킨 데리야끼 꿀조합\\n\\n-서브웨이 빵: 플랫 브래드 또는 허니오트\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채 골고루\\n\\n-서브웨이 소스: 후추+렌치\\n\\n\\n▲서브웨이 미트볼 꿀조합'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='-서브웨이 소스: 후추+렌치\\n\\n\\n▲서브웨이 미트볼 꿀조합\\n\\n-서브웨이 빵: 허니오트 또는 플랫브래드\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채는 양파, 피망, 올리브, 할라피뇨\\n\\n-서브웨이 소스: 렌치+후추\\n\\n\\n▲서브웨이 베지 꿀조합\\n\\n-서브웨이 빵: 위트\\n\\n-서브웨이 토핑: 야채 골고루\\n\\n-서브웨이 소스: 소금+후추+올리브 오일'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='-서브웨이 소스: 소금+후추+올리브 오일\\n\\n\\n▲서브웨이 스테이크 &\\u3000치즈 꿀조합\\n\\n-서브웨이 빵: 플랫브래드\\n\\n-서브웨이 토핑: 더블치즈, 야채 골고루\\n\\n-서브웨이 소스: 랜치+스위트 어니언+후추\\n\\n\\n▲서브웨이 이탈리안 BMT 꿀조합\\n\\n-서브웨이 빵: 플랫브래드\\n\\n-서브웨이 토핑: 더블치즈, 파마산오레가노, 올리브와 할라피뇨 많이'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='-서브웨이 토핑: 더블치즈, 파마산오레가노, 올리브와 할라피뇨 많이\\n\\n-서브웨이 소스: 렌치+스위트 어니언\\n\\n\\n▲서브웨이 클럽 꿀조합\\n\\n-서브웨이 빵: 화이트\\n\\n-서브웨이 토핑: 야채 골고루\\n\\n-서브웨이 소스: 랜치+후추+허니 머스타드'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='-서브웨이 소스: 랜치+후추+허니 머스타드\\n\\n\\n▲서브웨이 다이어트, 서브웨이 메뉴 + 서브웨이 샐러드 TOP 3(사진=ⓒ픽사베이)\\n서브웨이 다이어트, 서브웨이 메뉴 + 서브웨이 샐러드 TOP 3\\n서브웨이 다이어트를 하는 사람이 많다. 이에 다이어트 음식으로 제격인 칼로리 낮은 서브웨이 메뉴와 서브웨이 샐러드를 추천하며, 서브웨이 칼로리도 소개한다.'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='먼저, 서브웨이 다이어트로 제격인 서브웨이 메뉴를 추천한다. 서브웨이 15cm 기준으로, ▲참치 샌드위치/서브웨이 칼로리: 480 ▲미트볼 샌드위치/서브웨이 칼로리: 480 ▲햄 샌드위치/서브웨이 칼로리: 290 등이다.'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='다음, 서브웨이 다이어트로 딱인 서브웨이 샐러드는 ▲쉬림프/서브웨이 칼로리: 108 ▲림프 아보카도/서브웨이 칼로리: 163 ▲서브웨이 베지/서브웨이 칼로리: 60 등이다.\\n\\n출처 : 공감신문(https://www.gokorea.kr)'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='출처 : 공감신문(https://www.gokorea.kr)\\n\\n\\n서브웨이(써브웨이) 소스 종류 및 칼로리\\n미국에서 넘어온 샌드위치 전문 브랜드인 서브웨이는 국내에서도 많은 인기를 얻고 있습니다.'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='샌드위치 하나를 주문하기 위해 고객이 선택해야 될 것이 많아 조금 번거롭기는 하지만, 조합을 잘 한다면 (또는 이미 잘 많이 알려진 최적의 조합법으로 주문한다면) 정말 맛있는 샌드위치를 먹을 수 있습니다.'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='고객이 선택해야 될 것중에는 빵이나 토핑도 있지만, 맛에 많은 영향을 주는 것중의 하나가 바로 소스입니다. 서브웨이에서 주문을 하면 소스는 가장 마지막에 선택하게 됩니다.\\n\\n보통 2개의 소스를 고르라고 안내하며, 1개의 소스만 선택해도 무방합니다. (설령 소스를 선택하지 않아도 되겠지만, 소스가 없다면 좀 밋밋하겠지요?)\\n\\n서브웨이 샌드위치 소스 종류'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='서브웨이 샌드위치 소스 종류\\n\\n여기서는 서브웨이에서 선택 가능한 소스의 종류와 각 소스가 가지고 있는 특징 밀 칼로리 정보를 안내해 드리겠습니다.\\n\\n \\n\\n1) 랜치 (Ranch)\\n\\n마요네즈와 레몬즙을 섞어 만든 소스\\n특징 : 고소함\\n칼로리 : 116 kcal\\n \\n\\n2) 스윗 어니언 (Sweet Onion)'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='2) 스윗 어니언 (Sweet Onion)\\n\\n이름에서 알 수 있듯이 달콤한 양파 소스인데, 서브웨이의 특제 레시피로 만듦.\\n특징 : 달콤한 양파맛 (?)\\n칼로리 : 40.1 kcal\\n \\n\\n3) 사우스 웨스트 치폴레 (Southwest Chipotle)'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='3) 사우스 웨스트 치폴레 (Southwest Chipotle)\\n\\n치폴레는 조미료로 일반적으로 할라피뇨 칠리 페퍼를 뜻함. 보통 미국 남서부나 멕시코 쪽 요리에 사용됨.\\n특징 : 매콤하면서도 고소한 마요네즈 맛(?)\\n칼로리 : 96.4 kcal\\n \\n\\n4) 스윗 칠리 (Sweet Chilli)'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='4) 스윗 칠리 (Sweet Chilli)\\n\\n칠리가 이름에 들어가 있는 것에서 알 수 있듯이 매콤한 칠리 고추에 달콤함이 더해진 맛.\\n특징 : 달콤하면서도 약간 매콤한 맛.\\n칼로리 : 40 kcal\\n \\n\\n5) 핫 칠리 (Hot Chilli)\\n\\n매운 칠리 고추…\\n특징: 매움. 맵찔이 주의!\\n칼로리 : 41.8 kcal'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='6) 스모크 바베큐 (Smoke BBQ)\\n\\n스모크 향이 나는 바베큐 맛이 달콤하게 어우러진 소스\\n특징 : 훈제 향이 느껴지는 달콤한 바베큐 맛\\n칼로리 : 32.8 kcal\\n \\n\\n7) 홀스래디쉬 (Horseradish)'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='7) 홀스래디쉬 (Horseradish)\\n\\n홀스래디쉬는 우리말로 겨자무(배추과의 식물). 서양 고추냉이라고 생각하면 되는데 보통 매운 향이 강함.\\n특징 : 고추냉이와 마요네즈가 섞여 고소하면서도 매운 맛? 매니아층이 있다고 하네요.\\n칼로리 : 106 kcal\\n8) 머스타드 (Yellow Mustard)'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='이름에서 알 수 있듯이 겨자씨로 만든 오리지널 소스\\n특징 : 그 특유의 겨자 향과 맛. 호불호가 있지 않을까 하는 맛.\\n칼로리 : 15.3 kcal\\n \\n\\n9) 허니 머스타드 (Honey Mustard)\\n\\n머스타드에 달콤함을 더했다고 할까요?\\n특징 : 머스타드 + 달콤함.\\n칼로리 : 38.4 kcal\\n \\n\\n10) 올리브 오일 (Olive Oil)'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='10) 올리브 오일 (Olive Oil)\\n\\n그냥 올리브 오일… 요즘은 올리브 오일을 접할 수 있는 기회가 많을 듯…\\n특징 : 담백하면서도 깔끔한 맛?\\n칼로리 : 124 kcal\\n \\n\\n11) 마요네즈 (Mayonnaise)\\n\\n설명이 필요 없겠지요? 바로 그 마요네즈입니다.\\n특징 : 마요네즈 맛… 약간 고소함…\\n칼로리 : 158 kcal'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='12) 레드 와인 식초 (Red Wine Vinaigrette)\\n\\n레드와인을 발효시켜 만든 식초라고 하네요. 비네그레트는 기름에 식초나 레몬 즙을 섞어 만든 소스입니다.\\n특징 : 식초 맛보다는 상큼한 맛! 칼로리 엄청 낮음!\\n칼로리 : 0.7 kcal\\n \\n\\n13) 소금 (Salt)\\n\\n그냥 소금\\n \\n\\n14) 후추 (Pepper)\\n\\n그냥 후추')]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BweodJDjfuoa"
      },
      "source": [
        "# 벡터 DB에 넣기\n",
        "벡터디비에 들어갈 때는 json 형태로 들어간다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 쪼개놓은 문서 임베딩"
      ],
      "metadata": {
        "id": "s5HfU9sP2oXW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "I6Lgd9wWf1id",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f231f02-d671-4f22-b397-6fc6eb6487cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "# document를 임베딩으로 바꾼다 langchain.embeddings가 알아서 해줌\n",
        "from langchain.embeddings import OllamaEmbeddings\n",
        "\n",
        "embeddings = OllamaEmbeddings(model='llama3.1') # 어떤 임베딩(llama, chatgpt)을 쓰겠다\n",
        "\n",
        "# 오프라인 폴더 설정\n",
        "persist_directory = './subwayDB'\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=texts, # 잘린 텍스트\n",
        "    embedding=embeddings, # 임베딩 모델\n",
        "    persist_directory=persist_directory # 저장할 디렉토리\n",
        ")\n",
        "\n",
        "vectordb.persist() # 오프라인에 파일로 저장해라"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 불러오기"
      ],
      "metadata": {
        "id": "mnxTDSAb2v6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = './subwayDB'\n",
        "embeddings = OllamaEmbeddings(model='llama3.1')\n",
        "\n",
        "swDB = Chroma(\n",
        "    persist_directory=persist_directory,\n",
        "    embedding_function=embeddings\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf8F8KOx2vg2",
        "outputId": "35a5b7c1-85ad-470a-9a39-ba1ffc074967"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 0.4. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 유사 벡터 검색\n",
        "retriever = swDB.as_retriever()\n",
        "\n",
        "# 확인차\n",
        "docs = retriever.get_relevant_documents(\"쉬림프/서브웨이 칼로리?\") # 질문을 벡터로 바꿈 기존 DB 벡터들의 코사인 유사도 비교. 가장 큰 유사도를 가진 벡터들을 텍스트로 가져와\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA3Mo2cF3G6I",
        "outputId": "752dcf64-3a5f-4980-cbf0-d5236269da11"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './서브웨이.txt'}, page_content='먼저, 서브웨이 다이어트로 제격인 서브웨이 메뉴를 추천한다. 서브웨이 15cm 기준으로, ▲참치 샌드위치/서브웨이 칼로리: 480 ▲미트볼 샌드위치/서브웨이 칼로리: 480 ▲햄 샌드위치/서브웨이 칼로리: 290 등이다.'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='샌드위치 하나를 주문하기 위해 고객이 선택해야 될 것이 많아 조금 번거롭기는 하지만, 조합을 잘 한다면 (또는 이미 잘 많이 알려진 최적의 조합법으로 주문한다면) 정말 맛있는 샌드위치를 먹을 수 있습니다.'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='-서브웨이 소스: 랜치+후추+허니 머스타드\\n\\n\\n▲서브웨이 다이어트, 서브웨이 메뉴 + 서브웨이 샐러드 TOP 3(사진=ⓒ픽사베이)\\n서브웨이 다이어트, 서브웨이 메뉴 + 서브웨이 샐러드 TOP 3\\n서브웨이 다이어트를 하는 사람이 많다. 이에 다이어트 음식으로 제격인 칼로리 낮은 서브웨이 메뉴와 서브웨이 샐러드를 추천하며, 서브웨이 칼로리도 소개한다.'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='다음, 서브웨이 다이어트로 딱인 서브웨이 샐러드는 ▲쉬림프/서브웨이 칼로리: 108 ▲림프 아보카도/서브웨이 칼로리: 163 ▲서브웨이 베지/서브웨이 칼로리: 60 등이다.\\n\\n출처 : 공감신문(https://www.gokorea.kr)')]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 내가 검색할 개수 조정 가능(너무 적으면 성능 안좋음 너무 많으면 비용 문제)\n",
        "# 유사 벡터 검색\n",
        "retriever = swDB.as_retriever(search_kwargs={'k':5}) # 3개의 document 가져와라(default=4)\n",
        "docs = retriever.get_relevant_documents(\"서브웨이 이탈리안 비엠티 꿀조합\") # 질문을 벡터로 바꿈 기존 DB 벡터들의 코사인 유사도 비교. 가장 큰 유사도를 가진 벡터들을 텍스트로 가져와\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPZmWWrN3OjS",
        "outputId": "1a405b6b-e947-4538-d1bf-2ccbefab2fd5"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': './서브웨이.txt'}, page_content='▲서브웨이 이탈리안 비엠티 꿀조합\\n\\n-서브웨이 빵: 허니오트\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채 골고루\\n\\n-서브웨이 소스: 스위트 어니언+렌치소스\\n\\n\\n▲서브웨이 치킨 데리야끼 꿀조합\\n\\n-서브웨이 빵: 플랫 브래드 또는 허니오트\\n\\n-서브웨이 토핑: 아메리칸 치즈, 야채 골고루\\n\\n-서브웨이 소스: 후추+렌치\\n\\n\\n▲서브웨이 미트볼 꿀조합'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='▲서브웨이 에그마요 꿀조합\\n\\n-서브웨이 빵: 플랫 브래드\\n\\n-서브웨이 토핑: 베이컨 추가, 더블치즈, 야채 골고루\\n\\n-서브웨이 소스: 어니언+홀스래디쉬+스위트 칠리\\n\\n\\n▲서브웨이 참치 꿀조합\\n\\n-서브웨이 빵: 허니 오트\\n\\n-서브웨이 토핑: 슈레트 치즈, 야채 골고루\\n\\n-서브웨이 소스: 렌치+스위트 칠리\\n\\n\\n▲서브웨이 이탈리안 비엠티 꿀조합'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='12) 레드 와인 식초 (Red Wine Vinaigrette)\\n\\n레드와인을 발효시켜 만든 식초라고 하네요. 비네그레트는 기름에 식초나 레몬 즙을 섞어 만든 소스입니다.\\n특징 : 식초 맛보다는 상큼한 맛! 칼로리 엄청 낮음!\\n칼로리 : 0.7 kcal\\n \\n\\n13) 소금 (Salt)\\n\\n그냥 소금\\n \\n\\n14) 후추 (Pepper)\\n\\n그냥 후추'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='고객이 선택해야 될 것중에는 빵이나 토핑도 있지만, 맛에 많은 영향을 주는 것중의 하나가 바로 소스입니다. 서브웨이에서 주문을 하면 소스는 가장 마지막에 선택하게 됩니다.\\n\\n보통 2개의 소스를 고르라고 안내하며, 1개의 소스만 선택해도 무방합니다. (설령 소스를 선택하지 않아도 되겠지만, 소스가 없다면 좀 밋밋하겠지요?)\\n\\n서브웨이 샌드위치 소스 종류'),\n",
              " Document(metadata={'source': './서브웨이.txt'}, page_content='-서브웨이 토핑: 더블치즈, 파마산오레가노, 올리브와 할라피뇨 많이\\n\\n-서브웨이 소스: 렌치+스위트 어니언\\n\\n\\n▲서브웨이 클럽 꿀조합\\n\\n-서브웨이 빵: 화이트\\n\\n-서브웨이 토핑: 야채 골고루\\n\\n-서브웨이 소스: 랜치+후추+허니 머스타드')]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 유사하게 나온 텍스트를 LLM에 넣기\n",
        "이 데이터들을 LLM에 던져주고 답변"
      ],
      "metadata": {
        "id": "G-7L1q9q3uoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Ollama\n",
        "from langchain.schema.runnable import RunnablePassthrough # 질문을 그대로 집어넣어라\n",
        "\n",
        "llm = Ollama(model='llama3.1')\n",
        "retriever = swDB.as_retriever(search_kwargs={'k':5}) # 3개의 document 가져와라(default=4)\n",
        "rag_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Given the following context:\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Answer the following question:\n",
        "\n",
        "    {question}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()} # retriever 문서 참조하겠다. question은 들어온 그대로 그대로 입력을 준비하는 역할\n",
        "    | rag_prompt # question이 그대로 들어가서 프롬프트를 생성\n",
        "    | llm # Ollama 모델 써라 최종 답변을 생성\n",
        ")\n",
        "\n",
        "res = rag_chain.invoke(\"서브웨이 이탈리안 비엠티 꿀조합\") # 질문이 위로 그대로 들어간다\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXKeZcIT4GhH",
        "outputId": "abd5d219-bce5-499d-f296-f13bf596638f"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▲서브웨이 이탈리안 비엠티 꿀조합\n",
            "\n",
            "-서브웨이 빵: 허니오트\n",
            "\n",
            "-서브웨이 토핑: 아메리칸 치즈, 야채 골고루\n",
            "\n",
            "-서브웨이 소스: 스위트 어니언+렌치소\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = rag_chain.invoke(\"쉬림프/서브웨이 칼로리?\") # 질문이 위로 그대로 들어간다\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NoblYcT4Gdj",
        "outputId": "fc041d6f-71b3-451f-852b-5467ee5afbfc"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWaG0_Mthwqs"
      },
      "source": [
        "# +판다스로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMUEwTuBeiAa",
        "outputId": "8ffbc755-9937-4758-90e8-a4304bed69a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.64-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: langchain-community<0.3.0,>=0.2.10 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_experimental) (0.2.11)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\nlp\\nlp\\lib\\site-packages (from langchain_experimental) (0.2.29)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.12)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.1.98)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-community<0.3.0,>=0.2.10->langchain_experimental) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\nlp\\nlp\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_experimental) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\nlp\\nlp\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\nlp\\nlp\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\nlp\\nlp\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\nlp\\nlp\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\nlp\\nlp\\lib\\site-packages (from langchain<0.3.0,>=0.2.12->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (0.2.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\nlp\\nlp\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\nlp\\nlp\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in c:\\nlp\\nlp\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3.0,>=0.2.27->langchain_experimental) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\nlp\\nlp\\lib\\site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\nlp\\nlp\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\nlp\\nlp\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.10->langchain_experimental) (1.0.0)\n",
            "Downloading langchain_experimental-0.0.64-py3-none-any.whl (204 kB)\n",
            "   ---------------------------------------- 0.0/204.3 kB ? eta -:--:--\n",
            "   ------------ --------------------------- 61.4/204.3 kB 1.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 204.3/204.3 kB 4.2 MB/s eta 0:00:00\n",
            "Installing collected packages: langchain_experimental\n",
            "Successfully installed langchain_experimental-0.0.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32JFYPobhv-a",
        "outputId": "774cdc43-3fe4-4b3d-d69e-3b0af0dcd44c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tabulate\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: tabulate\n",
            "Successfully installed tabulate-0.9.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6wclCn8h01U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# df 참조해서 답변할 수 있다\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "av1z2WAPiDfi",
        "outputId": "3d6dafa7-ac05-4e90-c15c-d3e8da204c17"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>식당</th>\n",
              "      <th>리뷰</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>정식당</td>\n",
              "      <td>저의 개인적 취향을 두고 볼 때에는\\n소스가 전체적으로 오일리하고 무거운\\n느낌이 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>정식당</td>\n",
              "      <td>이정도 가격대의 식당을 방문하시는분이라면\\n식사에 대한 기준이 높을꺼라 생각합니다....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>정식당</td>\n",
              "      <td>맛만 보면 4.5, 모든걸 더하면 5\\n\\n배를 채우러 가기 보다는 음식이라는 하나...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>정식당</td>\n",
              "      <td>금액이 좀 비싸지만 미슐렝가이드 레스토랑을 제대로 즐길 수 있어요. 모든 음식은 한...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>정식당</td>\n",
              "      <td>정말 세상에서 제일 맛있는 음식과 친절한 직원들 ❤️\\n파인다이닝인데 큰 기교를 부...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    식당                                                 리뷰\n",
              "0  정식당  저의 개인적 취향을 두고 볼 때에는\\n소스가 전체적으로 오일리하고 무거운\\n느낌이 ...\n",
              "1  정식당  이정도 가격대의 식당을 방문하시는분이라면\\n식사에 대한 기준이 높을꺼라 생각합니다....\n",
              "2  정식당  맛만 보면 4.5, 모든걸 더하면 5\\n\\n배를 채우러 가기 보다는 음식이라는 하나...\n",
              "3  정식당  금액이 좀 비싸지만 미슐렝가이드 레스토랑을 제대로 즐길 수 있어요. 모든 음식은 한...\n",
              "4  정식당  정말 세상에서 제일 맛있는 음식과 친절한 직원들 ❤️\\n파인다이닝인데 큰 기교를 부..."
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"review.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crPiFbH2idrz"
      },
      "outputs": [],
      "source": [
        "llm = Ollama(model=\"llama3.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIRylHAqiUpB",
        "outputId": "96acbf76-9cad-4710-cdab-857ece9da9f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(641, 2)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['식당']=='정식당'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nAWfPkTaiMkj",
        "outputId": "65869ffe-fdd3-438e-950a-efb342bcb492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: The review is in the form of a table, and I need to find the count of reviews.\n",
            "Action: Use the `df.shape` command to get the total number of rows.\n",
            "Action Input: None\u001b[0mUse the `df.shape` command to get the total number of rows. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mAction: python_repl_ast\n",
            "Action Input: df.shape\u001b[0m\u001b[36;1m\u001b[1;3m(169366, 2)\u001b[0m\u001b[32;1m\u001b[1;3mYou are correct that `df.shape` is the correct way to get the total number of rows in a pandas DataFrame. However, since we are looking for the count of reviews for \"정식당\", we should filter the dataframe first.\n",
            "\n",
            "Action: Use the `python_repl_ast` tool with input `df[df['식당'] == '정식당'].shape[0]`.\n",
            "Action Input: df[df['식당'] == '정식당'].shape[0\u001b[0mUse the `python_repl_ast` tool with input `df[df['식당'] == '정식당'].shape[0]`. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mThought: The review count for \"정식당\" can be found by filtering the dataframe to only include rows where \"식당\" equals \"정식당\", and then getting the shape of that filtered dataframe.\n",
            "\n",
            "Action: Use the `python_repl_ast` tool with input `df[df['식당'] == '정식당'].shape[0]`.\n",
            "Action Input: df[df['식당'] == '정식당'].shape[0\u001b[0mUse the `python_repl_ast` tool with input `df[df['식당'] == '정식당'].shape[0]`. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mAction: python_repl_ast\n",
            "Action Input: df[df['식당'] == '정식당'].shape[0\u001b[0m\u001b[36;1m\u001b[1;3mSyntaxError: '[' was never closed (<unknown>, line 1)\u001b[0m\u001b[32;1m\u001b[1;3mI see what's going on!\n",
            "\n",
            "You are trying to use the `python_repl_ast` tool with an input that is not a valid Python command.\n",
            "\n",
            "Let me try again:\n",
            "\n",
            "Action: Use the `python_repl_ast` tool with input `df[df['식당'] == '정식당'].shape[0]`.\n",
            "Action Input: df[df['식당'] == '정식당'].shape[0\u001b[0mUse the `python_repl_ast` tool with input `df[df['식당'] == '정식당'].shape[0]`. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mAction: Use the `python_repl_ast` tool with input `len(df.loc[df['식당'] == '정식당'])`.\n",
            "Action Input: len(df.loc[df['식당'] == '정식당\u001b[0mUse the `python_repl_ast` tool with input `len(df.loc[df['식당'] == '정식당'])`. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mYou are trying to count the number of reviews for \"정식당\".\n",
            "\n",
            "Here's how you can do it:\n",
            "\n",
            "Action: Use the `len(df.loc[df['식당'] == '정식당'])` command to get the count.\n",
            "Action Input: None\u001b[0mUse the `len(df.loc[df['식당'] == '정식당'])` command to get the count. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mYou are trying to find the review count for \"정식당\".\n",
            "\n",
            "Here's how you can do it:\n",
            "\n",
            "Action: Use the `len(df.loc[df['식당'] == '정식당'])` command to get the count.\n",
            "Action Input: None\u001b[0mUse the `len(df.loc[df['식당'] == '정식당'])` command to get the count. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mYou are trying to find the review count for \"정식당\".\n",
            "\n",
            "Here's how you can do it:\n",
            "\n",
            "Action: Use the `len(df.loc[df['식당'] == '정식당'])` command to get the count.\n",
            "Action Input: None\u001b[0mUse the `len(df.loc[df['식당'] == '정식당'])` command to get the count. is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mThe review count for \"정식당\" can be found by filtering the dataframe to only include rows where \"식당\" equals \"정식당\", and then getting the length of that filtered dataframe.\n",
            "\n",
            "Action: Use the `len(df.loc[df['식당'] == '정식당'])` command.\n",
            "Action Input: None\u001b[0mUse the `len(df.loc[df['식당'] == '정식당'])` command. is not a valid tool, try one of [python_repl_ast]."
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `It looks like you're trying to use the `python_repl_ast` tool to get the review count for \"정식당\". However, it seems that there's an issue with the input.\n\nTo fix this, you can simply use the following command:\n\n```python\nlen(df.loc[df['식당'] == '정식당'])\n```\n\nThis will filter the dataframe to only include rows where \"식당\" equals \"정식당\", and then return the length of that filtered dataframe, which is the review count.\n\nIf you want to use the `python_repl_ast` tool, you can try again with this input:\n\n```python\nlen(df.loc[df['식당'] == '정식당'])\n```\n\nLet me know if this works!`",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\agents\\agent.py:1346\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1346\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1349\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1350\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\agents\\agent.py:463\u001b[0m, in \u001b[0;36mRunnableAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m--> 463\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3262\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   3257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3258\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   3259\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3260\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3262\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3249\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   3244\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3245\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[0;32m   3246\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3247\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3248\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3249\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   3250\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   3252\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   3253\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3254\u001b[0m     )\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2054\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   2053\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 2054\u001b[0m     chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2055\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3211\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3209\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 3211\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_pipeline\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3212\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1290\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1290\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\runnables\\base.py:855\u001b[0m, in \u001b[0;36mRunnable.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;124;03mDefault implementation of stream, which calls invoke.\u001b[39;00m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;124;03mSubclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;124;03m    The output of the Runnable.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:192\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1785\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1783\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1784\u001b[0m         Output,\n\u001b[1;32m-> 1785\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1793\u001b[0m     )\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\runnables\\config.py:427\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:193\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[1;34m(inner_input)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m--> 193\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    195\u001b[0m         config,\n\u001b[0;32m    196\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m     )\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\output_parsers\\base.py:237\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mThe return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m    Structured output.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\agents\\output_parsers\\react_single_input.py:75\u001b[0m, in \u001b[0;36mReActSingleInputOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*?)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL):\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     77\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_AFTER_THOUGHT_ERROR_MESSAGE,\n\u001b[0;32m     78\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m     79\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     80\u001b[0m     )\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[0;32m     83\u001b[0m ):\n",
            "\u001b[1;31mOutputParserException\u001b[0m: Could not parse LLM output: `It looks like you're trying to use the `python_repl_ast` tool to get the review count for \"정식당\". However, it seems that there's an issue with the input.\n\nTo fix this, you can simply use the following command:\n\n```python\nlen(df.loc[df['식당'] == '정식당'])\n```\n\nThis will filter the dataframe to only include rows where \"식당\" equals \"정식당\", and then return the length of that filtered dataframe, which is the review count.\n\nIf you want to use the `python_repl_ast` tool, you can try again with this input:\n\n```python\nlen(df.loc[df['식당'] == '정식당'])\n```\n\nLet me know if this works!`",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m  create_pandas_dataframe_agent(llm, df, allow_dangerous_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m정식당의 리뷰 수는?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\chains\\base.py:600\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    601\u001b[0m         _output_key\n\u001b[0;32m    602\u001b[0m     ]\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    606\u001b[0m         _output_key\n\u001b[0;32m    607\u001b[0m     ]\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     emit_warning()\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\chains\\base.py:383\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    376\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    381\u001b[0m }\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\chains\\base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    159\u001b[0m     )\n\u001b[0;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\agents\\agent.py:1612\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1610\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1612\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1621\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1622\u001b[0m         )\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\agents\\agent.py:1318\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1311\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1316\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1318\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1328\u001b[0m     )\n",
            "File \u001b[1;32mC:\\NLP\\nlp\\Lib\\site-packages\\langchain\\agents\\agent.py:1357\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m-> 1357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn output parsing error occurred. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1361\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1362\u001b[0m     )\n\u001b[0;32m   1363\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[0;32m   1364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "\u001b[1;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `It looks like you're trying to use the `python_repl_ast` tool to get the review count for \"정식당\". However, it seems that there's an issue with the input.\n\nTo fix this, you can simply use the following command:\n\n```python\nlen(df.loc[df['식당'] == '정식당'])\n```\n\nThis will filter the dataframe to only include rows where \"식당\" equals \"정식당\", and then return the length of that filtered dataframe, which is the review count.\n\nIf you want to use the `python_repl_ast` tool, you can try again with this input:\n\n```python\nlen(df.loc[df['식당'] == '정식당'])\n```\n\nLet me know if this works!`"
          ]
        }
      ],
      "source": [
        "agent =  create_pandas_dataframe_agent(llm, df, allow_dangerous_code=True, verbose=True)\n",
        "agent.run(\"정식당의 리뷰 수는?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAw8acXuia7w",
        "outputId": "8c8115bb-8062-4a03-f6e0-85892a300b3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "641"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.loc[df['식당'] == '정식당'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}